@inproceedings{pu2018push,
  title={A push-pull gradient method for distributed optimization in networks},
  author={Pu, Shi and Shi, Wei and Xu, Jinming and Nedi{\'c}, Angelia},
  booktitle={2018 IEEE Conference on Decision and Control (CDC)},
  pages={3385--3390},
  year={2018},
  organization={IEEE}
}

@misc{pu2018distributed,
    title={Distributed Stochastic Gradient Tracking Methods},
    author={Shi Pu and Angelia Nedić},
    year={2018},
    eprint={1805.11454},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@misc{olshevsky2019nonasymptotic,
    title={A Non-Asymptotic Analysis of Network Independence for Distributed Stochastic Gradient Descent},
    author={Alex Olshevsky and Ioannis Ch. Paschalidis and Shi Pu},
    year={2019},
    eprint={1906.02702},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@article{nedic2018network,
  title={Network topology and communication-computation tradeoffs in decentralized optimization},
  author={Nedi{\'c}, Angelia and Olshevsky, Alex and Rabbat, Michael G},
  journal={Proceedings of the IEEE},
  volume={106},
  number={5},
  pages={953--976},
  year={2018},
  publisher={IEEE}
}

@inproceedings{ram2009asynchronous,
  title={Asynchronous gossip algorithms for stochastic optimization},
  author={Ram, S Sundhar and Nedi{\'c}, A and Veeravalli, Venugopal V},
  booktitle={Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference},
  pages={3581--3586},
  year={2009},
  organization={IEEE}
}

@misc{pu2019asymptotic,
    title={Asymptotic Network Independence in Distributed Stochastic Optimization for Machine Learning},
    author={Shi Pu and Alex Olshevsky and Ioannis Ch. Paschalidis},
    year={2019},
    eprint={1906.12345},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@misc{pu2019sharp,
    title={A Sharp Estimate on the Transient Time of Distributed Stochastic Gradient Descent},
    author={Shi Pu and Alex Olshevsky and Ioannis Ch. Paschalidis},
    year={2019},
    eprint={1906.02702},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@article{koloskova2019decentralized,
  title={Decentralized stochastic optimization and gossip algorithms with compressed communication},
  author={Koloskova, Anastasia and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:1902.00340},
  year={2019}
}

@inproceedings{stich2018sparsified,
  title={Sparsified SGD with memory},
  author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4447--4458},
  year={2018}
}

@article{assran2018stochastic,
  title={Stochastic gradient push for distributed deep learning},
  author={Assran, Mahmoud and Loizou, Nicolas and Ballas, Nicolas and Rabbat, Michael},
  journal={arXiv preprint arXiv:1811.10792},
  year={2018}
}

@inproceedings{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5330--5340},
  year={2017}
}

@article{tang2018d,
  title={D $\^{} 2$: Decentralized Training over Decentralized Data},
  author={Tang, Hanlin and Lian, Xiangru and Yan, Ming and Zhang, Ce and Liu, Ji},
  journal={arXiv preprint arXiv:1803.07068},
  year={2018}
}

@phdthesis{chen2012fast,
  title={Fast distributed first-order methods},
  author={Chen, Annie I-An},
  year={2012},
  school={Massachusetts Institute of Technology}
}

@article{li2019decentralized,
  title={A decentralized proximal-gradient method with network independent step-sizes and separated convergence rates},
  author={Li, Zhi and Shi, Wei and Yan, Ming},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={17},
  pages={4494--4506},
  year={2019},
  publisher={IEEE}
}

@article{shi2015extra,
  title={Extra: An exact first-order algorithm for decentralized consensus optimization},
  author={Shi, Wei and Ling, Qing and Wu, Gang and Yin, Wotao},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={2},
  pages={944--966},
  year={2015},
  publisher={SIAM}
}

@inproceedings{yuan2019performance,
  title={On the performance of exact diffusion over adaptive networks},
  author={Yuan, Kun and Alghunaim, Sulaiman A and Ying, Bicheng and Sayed, Ali H},
  booktitle={2019 IEEE 58th Conference on Decision and Control (CDC)},
  pages={4898--4903},
  year={2019},
  organization={IEEE}
}

@misc{alghunaim2019decentralized,
    title={Decentralized Proximal Gradient Algorithms with Linear Convergence Rates},
    author={Sulaiman A. Alghunaim and Ernest K. Ryu and Kun Yuan and Ali H. Sayed},
    year={2019},
    eprint={1909.06479},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}
@article{yuan2018exact,
  title={Exact diffusion for distributed optimization and learning—Part II: Convergence analysis},
  author={Yuan, Kun and Ying, Bicheng and Zhao, Xiaochuan and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={3},
  pages={724--739},
  year={2018},
  publisher={IEEE}
}