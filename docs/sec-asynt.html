<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Asymptotic network independence | Notes about Distributed Optimization</title>
  <meta name="description" content="These are some notes about distributed optimization, including some algorithms, their analysis of convergence, and some understandings of my own. Although the authors of those literature already provide proofs, I complement some details and try to figure out why should we prove in such a way. Hence they could be more easy to understand, especially for myself." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Asymptotic network independence | Notes about Distributed Optimization" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are some notes about distributed optimization, including some algorithms, their analysis of convergence, and some understandings of my own. Although the authors of those literature already provide proofs, I complement some details and try to figure out why should we prove in such a way. Hence they could be more easy to understand, especially for myself." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Asymptotic network independence | Notes about Distributed Optimization" />
  
  <meta name="twitter:description" content="These are some notes about distributed optimization, including some algorithms, their analysis of convergence, and some understandings of my own. Although the authors of those literature already provide proofs, I complement some details and try to figure out why should we prove in such a way. Hence they could be more easy to understand, especially for myself." />
  

<meta name="author" content="Kun Huang" />


<meta name="date" content="2020-03-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="gossip-like-push-pull-and-dsgt.html"/>
<link rel="next" href="sec-sharp.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="orgnization-of-the-notes.html"><a href="orgnization-of-the-notes.html"><i class="fa fa-check"></i><b>2</b> Orgnization of the Notes</a></li>
<li class="chapter" data-level="3" data-path="the-push-pull-method.html"><a href="the-push-pull-method.html"><i class="fa fa-check"></i><b>3</b> The Push-Pull Method</a><ul>
<li class="chapter" data-level="3.1" data-path="the-push-pull-method.html"><a href="the-push-pull-method.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="the-push-pull-method.html"><a href="the-push-pull-method.html#analysis-of-convergence"><i class="fa fa-check"></i><b>3.2</b> Analysis of Convergence</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-push-pull-method.html"><a href="the-push-pull-method.html#relationship-between-two-iteration-steps"><i class="fa fa-check"></i><b>3.2.1</b> Relationship between two iteration steps</a></li>
<li class="chapter" data-level="3.2.2" data-path="the-push-pull-method.html"><a href="the-push-pull-method.html#inequalities"><i class="fa fa-check"></i><b>3.2.2</b> Inequalities</a></li>
<li class="chapter" data-level="3.2.3" data-path="the-push-pull-method.html"><a href="the-push-pull-method.html#spectral-radius-of-a"><i class="fa fa-check"></i><b>3.2.3</b> Spectral radius of A</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sec-dsgt.html"><a href="sec-dsgt.html"><i class="fa fa-check"></i><b>4</b> Distributed Stochastic Gradient Tracking(DSGT) Method</a><ul>
<li class="chapter" data-level="4.1" data-path="sec-dsgt.html"><a href="sec-dsgt.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="sec-dsgt.html"><a href="sec-dsgt.html#analysis-of-convergence-1"><i class="fa fa-check"></i><b>4.2</b> Analysis of Convergence</a><ul>
<li class="chapter" data-level="4.2.1" data-path="sec-dsgt.html"><a href="sec-dsgt.html#relationship-between-two-iteration-steps-1"><i class="fa fa-check"></i><b>4.2.1</b> Relationship between two iteration steps</a></li>
<li class="chapter" data-level="4.2.2" data-path="sec-dsgt.html"><a href="sec-dsgt.html#inequalities-1"><i class="fa fa-check"></i><b>4.2.2</b> Inequalities</a></li>
<li class="chapter" data-level="4.2.3" data-path="sec-dsgt.html"><a href="sec-dsgt.html#spectral-radius-of-a_dsgt"><i class="fa fa-check"></i><b>4.2.3</b> Spectral radius of <span class="math inline">\(A_{dsgt}\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="summary-of-push-pull-and-dsgt.html"><a href="summary-of-push-pull-and-dsgt.html"><i class="fa fa-check"></i><b>5</b> Summary of PuSh-Pull and DSGT</a><ul>
<li class="chapter" data-level="5.1" data-path="summary-of-push-pull-and-dsgt.html"><a href="summary-of-push-pull-and-dsgt.html#questions"><i class="fa fa-check"></i><b>5.1</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gossip-like-push-pull-and-dsgt.html"><a href="gossip-like-push-pull-and-dsgt.html"><i class="fa fa-check"></i><b>6</b> Gossip-like Push-Pull and DSGT</a><ul>
<li class="chapter" data-level="6.1" data-path="gossip-like-push-pull-and-dsgt.html"><a href="gossip-like-push-pull-and-dsgt.html#g-push-pull"><i class="fa fa-check"></i><b>6.1</b> G-Push-Pull</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sec-asynt.html"><a href="sec-asynt.html"><i class="fa fa-check"></i><b>7</b> Asymptotic network independence</a><ul>
<li class="chapter" data-level="7.1" data-path="sec-asynt.html"><a href="sec-asynt.html#sgd-and-dsgd"><i class="fa fa-check"></i><b>7.1</b> SGD and DSGD</a></li>
<li class="chapter" data-level="7.2" data-path="sec-asynt.html"><a href="sec-asynt.html#bounds"><i class="fa fa-check"></i><b>7.2</b> Bounds</a></li>
<li class="chapter" data-level="7.3" data-path="sec-asynt.html"><a href="sec-asynt.html#possible-ways-to-achieve-asymptotic-network-independece"><i class="fa fa-check"></i><b>7.3</b> Possible ways to achieve asymptotic network independece</a><ul>
<li class="chapter" data-level="7.3.1" data-path="sec-asynt.html"><a href="sec-asynt.html#compressed-communication"><i class="fa fa-check"></i><b>7.3.1</b> Compressed Communication</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sec-sharp.html"><a href="sec-sharp.html"><i class="fa fa-check"></i><b>8</b> A sharp estimate of the transient time of DSGD</a><ul>
<li class="chapter" data-level="8.1" data-path="sec-sharp.html"><a href="sec-sharp.html#uk-and-vk"><i class="fa fa-check"></i><b>8.1</b> <span class="math inline">\(U(k)\)</span> and <span class="math inline">\(V(k)\)</span></a></li>
<li class="chapter" data-level="8.2" data-path="sec-sharp.html"><a href="sec-sharp.html#asymptotic-network-independence-of-dsgd"><i class="fa fa-check"></i><b>8.2</b> Asymptotic network independence of DSGD</a><ul>
<li class="chapter" data-level="8.2.1" data-path="sec-sharp.html"><a href="sec-sharp.html#sublinear-rate"><i class="fa fa-check"></i><b>8.2.1</b> Sublinear rate</a></li>
<li class="chapter" data-level="8.2.2" data-path="sec-sharp.html"><a href="sec-sharp.html#asymptotic-network-independence"><i class="fa fa-check"></i><b>8.2.2</b> Asymptotic network independence</a></li>
<li class="chapter" data-level="8.2.3" data-path="sec-sharp.html"><a href="sec-sharp.html#improved-bound"><i class="fa fa-check"></i><b>8.2.3</b> Improved Bound</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="sec-sharp.html"><a href="sec-sharp.html#transient-time"><i class="fa fa-check"></i><b>8.3</b> Transient time</a></li>
<li class="chapter" data-level="8.4" data-path="sec-sharp.html"><a href="sec-sharp.html#sharpness"><i class="fa fa-check"></i><b>8.4</b> Sharpness</a></li>
<li class="chapter" data-level="8.5" data-path="sec-sharp.html"><a href="sec-sharp.html#summary"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>9</b> Final Words</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes about Distributed Optimization</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec:asynt" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Asymptotic network independence</h1>
<p>An undesirable property of distributed optimization method is that the increasing number of nodes may result in a large increase in the time to reach the same <span class="math inline">\(\varepsilon\)</span> accuracy(error <span class="math inline">\(&lt;\varepsilon\)</span>) under the centralized version. <span class="citation">Pu, Olshevsky, and Paschalidis (<a href="#ref-pu2019asymptotic">2019</a><a href="#ref-pu2019asymptotic">b</a>)</span> discuss this phenomenon under the following scenario</p>
<span class="math display" id="eq:tscen">\[\begin{equation}
\text { Time }_{n, \varepsilon} \text { (decentralized) } \leq p(\mathcal{G}) \text { Time }_{n, \varepsilon} \text { (centralized) }
\tag{7.1}
\end{equation}\]</span>
<p>where <span class="math inline">\(\text { Time }_{n, \varepsilon} \text { (decentralized) }\)</span> denotes the time for the decentralized algorithm on n nodes to reach <span class="math inline">\(\varepsilon\)</span> accuracy, and <span class="math inline">\(\text { Time }_{n, \varepsilon} \text { (centralized) }\)</span> is the time for the centralized algorithm which can query <span class="math inline">\(n\)</span> gradients per time step to reach <span class="math inline">\(\varepsilon\)</span> accuracy.<span class="math inline">\(\mathcal{G}=(\mathcal{N},\mathcal{E})\)</span> denotes the graph. Typically, <span class="math inline">\(p(\mathcal{G})\)</span> is at least <span class="math inline">\(\mathcal{O}(n^2)\)</span><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>, which is inpractical to use. This is because, <span class="math inline">\(p(\mathcal{G})=\mathcal{O}(n^2)\)</span> implies the distributed version would be <span class="math inline">\(n^2\)</span> times slower than the centralized one with the same computational power.</p>
<p><span class="math inline">\(p(\mathcal{G})=\mathcal{O}(1)\)</span> is a desirable setting, which means a decentralized algorithm converge to the optimal at a comparable rate to a centralized algorithm with the same computational power<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>. Fortunately, it is possible for the iteration time <span class="math inline">\(k\)</span> to be large enough for some distributed stochastic optimization, which is the <strong>asymptotic network independence</strong> property: it is as if the network is not even there. In chapter <a href="sec-sharp.html#sec:sharp">8</a>, we summarize some notes showing the asymptotic network independence property of algorithm <a href="sec-asynt.html#exm:dsgd">7.1</a> with <span class="math inline">\(\alpha_k=\frac{\theta}{\mu(k+K)}\)</span><span class="citation">(Pu, Olshevsky, and Paschalidis <a href="#ref-pu2019sharp">2019</a><a href="#ref-pu2019sharp">a</a>)</span>.</p>
<div id="sgd-and-dsgd" class="section level2">
<h2><span class="header-section-number">7.1</span> SGD and DSGD</h2>
<p>We consider a distributed stochastic gradient descent(DSGD) method, see algorithm under assumptions <a href="index.html#exr:muL">1.1</a>, <a href="sec-dsgt.html#exr:estg">4.1</a>,<a href="sec-dsgt.html#exr:dsgtgraph">4.2</a>,and <a href="sec-dsgt.html#exr:dsw">4.3</a> plus symmetric<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>, the similar settings as we discuss in chapter <a href="sec-dsgt.html#sec:dsgt">4</a>. By assumption <a href="index.html#exr:muL">1.1</a>, there exist a unique solution <span class="math inline">\(x^*\in\mathbb{R}^p\)</span> to the problem <a href="index.html#eq:obj">(1.1)</a>.</p>

<div class="example">
<p><span id="exm:dsgd" class="example"><strong>Algorithm7.1  (DSGD)  </strong></span>Each agent <span class="math inline">\(i\)</span> choose the same step size <span class="math inline">\(\alpha_k\)</span> at the <span class="math inline">\(k\)</span>th iteration and initilized with an arbitary <span class="math inline">\(x_i(0)\in\mathbb{R}^p\)</span></p>
<p>For k = 0, 1, …,</p>
<ul>
<li><p>For <span class="math inline">\(i\in\mathcal{N}\)</span>,</p>
<ul>
<li><span class="math inline">\(x_i(k+1) = \sum\limits_{j=1}^nw_{ij}(x_j(k+1)-\alpha_k g_j(x_j(k),\xi_j(k)))\)</span>
</div>
 <span class="math inline">\(\{\alpha_k\}\)</span> are a sequence of nonnegative non-increasing stepsizes. In the long run, <span class="math inline">\(x_{i,k}=x_{j,k},\forall i,j\in\mathcal{N}\)</span>, i.e. DSGD belongs to the class of consensus-based distributed optimization methods, which can be achieved under assumptions <a href="sec-dsgt.html#exr:dsgtgraph">4.2</a> and <a href="sec-dsgt.html#exr:dsw">4.3</a> plus <span class="math inline">\(W\)</span> is symmetric.</li>
</ul></li>
</ul>
Let <span class="math inline">\(X(k)=(x_1(k),...,x_n(k))^T\in\mathbb{R^{n\times p}}, G(k)=(g_1(x_1(k),\xi_1(k)),...,g_n(x_n(k),\xi_n(k)))^T\in\mathbb{R}^{n\times p}\)</span>, and <span class="math inline">\(W=(w_{ij})\in\mathbb{R}^{n\times n}\)</span>, then we can rewrite <a href="sec-asynt.html#exm:dsgd">7.1</a> as
<span class="math display" id="eq:dsgdc">\[\begin{equation}
X(k+1)=W(X(k)-\alpha_kG(k))
\tag{7.2}
\end{equation}\]</span>
<p><strong>Todo:<span class="math inline">\(x_{i,k}\stackrel{?}=x_{j,k},\forall i,j\in\mathcal{N}\)</span></strong></p>
<p>We compare DSGD with centralized stochastic gradient descent(SGD) which can query <span class="math inline">\(n\)</span> gradients at each iteration,</p>

<div class="example">
<p><span id="exm:sgd" class="example"><strong>Algorithm7.2  (SGD)  </strong></span>Initialize arbitrary <span class="math inline">\(x_{0}\in\mathbb{R}^{p}\)</span> and choose stepsize <span class="math inline">\(\alpha_k\)</span> for each step</p>
<p>For k=0,1,…,</p>
<ul>
<li><span class="math inline">\(x(k+1)=x(k)-\alpha_k\bar g(k)\)</span>
</div>
</li>
</ul>
<p>where <span class="math inline">\(\bar g(k)=\frac{1}{n}\sum\limits_{i=1}^n g_i(x(k),\xi_i(k)),\alpha_k=\frac{1}{\mu k}\)</span>, we use <span class="math inline">\(\bar g(k)\)</span> here to make the gradient comparable to that in DSGD, i.e., <span class="math inline">\(\sum\limits_{j=1}^n w_{ij} g_j(x_j(k),\xi_j(k))\)</span>.</p>
Choose <span class="math inline">\(2-\)</span>norm as the loss function, the distance between <span class="math inline">\(x(k)\)</span> and <span class="math inline">\(x^*\)</span> at the <span class="math inline">\(k\)</span>th step is
<span class="math display" id="eq:risksgd">\[\begin{equation}
R(k)=E  \left[\Vert x(k)-x^*\Vert^2\right]=\frac{1}{n}\sum\limits_{i=1}^nE  \left[\Vert x(k)-x^*\Vert^2\right]
\tag{7.3}
\end{equation}\]</span>
which hints us to evaluate the similar distance of DSGD by
<span class="math display" id="eq:riskdsgd">\[\begin{equation}
R&#39;(k)=\frac{1}{n}\sum\limits_{i=1}^n E\left[\Vert x_i(k)-x^*\Vert^2\right]
\tag{7.4}
\end{equation}\]</span>
Additonnally, <a href="sec-asynt.html#eq:riskdsgd">(7.4)</a> can be divided into two sources, one from the optimization error, and one from the consensus error, i.e.,
<span class="math display" id="eq:drdsgd">\[\begin{equation}
R&#39;(K)=\underbrace{E  \left[\Vert \bar x(k)-x^*\Vert^2\right]}_{\text{expected optimization error}} + 
\underbrace{\frac{1}{n}\sum_{i=1}^nE  \left[\Vert  x_i(k)-\bar x(k)^*\Vert^2\right]}_{\text{expected consensus error}}
\tag{7.5}
\end{equation}\]</span>
This is because
<span class="math display">\[\begin{align}
\frac{1}{n}\sum_{i=1}^n E\left[\langle x_i(k)-\bar x, \bar x - x^*\rangle\right]&amp;=E\left[\langle \frac{1}{n}\sum_{i=1}^nx_i(k)-\bar x, \bar x - x^*\rangle\right]\\
&amp;=0
\end{align}\]</span>
</div>
<div id="bounds" class="section level2">
<h2><span class="header-section-number">7.2</span> Bounds</h2>
<p>We next compare SGD and DSGD by analyzing their error bounds.</p>

<div class="lemma">
<span id="lem:risksgd" class="lemma"><strong>Lemma 7.1  </strong></span>Let assumptions <a href="index.html#exr:muL">1.1</a>, <a href="sec-dsgt.html#exr:estg">4.1</a>, <a href="sec-dsgt.html#exr:dsgtgraph">4.2</a>,and <a href="sec-dsgt.html#exr:dsw">4.3</a> plus <span class="math inline">\(W\)</span> is symmetric hold, for SGD <a href="sec-asynt.html#exm:sgd">7.2</a>, we have <span class="math display">\[
R(k+1) \leq\left(1-\alpha_{k} \mu\right)^{2} R(k)+\frac{\alpha_{k}^{2} \sigma^{2}}{n}
\]</span>
</div>

<p>Denote <span class="math inline">\(U(k)=E \left[\Vert \bar x(k)-x^*\Vert^2\right]\)</span> and <span class="math inline">\(V(k)=\sum\limits_{i=1}^nE \left[\Vert x_i(k)-\bar x(k)\right]\)</span>, we have</p>

<div class="lemma">
<span id="lem:riskdsgd" class="lemma"><strong>Lemma 7.2  </strong></span>Let the same assumptions in <a href="sec-asynt.html#lem:risksgd">7.1</a> hold, <span class="math display">\[
U(k+1) \leq\left(1-\frac{1}{k}\right)^{2} U(k)+\frac{2 L}{\sqrt{n} \mu} \frac{\sqrt{U(k) V(k)}}{k}+\frac{L^{2}}{n \mu^{2}} \frac{V(k)}{k^{2}}+\frac{\sigma^{2}}{n \mu^{2}} \frac{1}{k^{2}}
\]</span>
</div>

<p>In chapter <a href="sec-sharp.html#sec:sharp">8</a>, lemma <a href="sec-sharp.html#lem:sublrdsgd">8.7</a> shows that <span class="math inline">\(\exists K_0, s.t.\)</span> when <span class="math inline">\(k&gt;K_0, R&#39;(k)\leq \frac{\hat W}{\tilde k}+\frac{\hat V}{\tilde k^2}\)</span>, where <span class="math inline">\(\tilde k\)</span> is some shift of <span class="math inline">\(k\)</span> with a choice of step size <span class="math inline">\(\alpha_k=\frac{\theta}{\mu(k+K)},K:=\left\lceil\frac{2 \theta L^{2}}{\mu^{2}}\right\rceil\)</span>.</p>

<div class="remark">
<p> <span class="remark"><em>Remark. </em></span> \</p>
<ul>
<li><p>In a view that <span class="math inline">\(R(k)\)</span> and <span class="math inline">\(R&#39;(k)\)</span> are both risk functions, if <span class="math inline">\(V(k)\)</span> decays fast enough compared to <span class="math inline">\(U(k)\)</span>, we then have <span class="math inline">\(R(k)\approx R&#39;(k)\)</span> for large <span class="math inline">\(k\)</span>.</p></li>
<li>the asymptotic network independence phenomenon: after a transient, DSGD performs comparably to a centralized stochastic gradient descent method with the same computational power.</li>
</ul>
</div>

</div>
<div id="possible-ways-to-achieve-asymptotic-network-independece" class="section level2">
<h2><span class="header-section-number">7.3</span> Possible ways to achieve asymptotic network independece</h2>
<ul>
<li><p>Considering nonconvex objective functions(distributed training of deep neural networks);</p></li>
<li><p>Explore communication reduction techniques that do not sacrifice the asymptotic network independece property;</p></li>
<li><p>Redcing the transient time;</p></li>
</ul>
<p>Additionnally, an unsolving question is can distributed methods compete with the centralized ones when the exact gradient is available?</p>
<p><strong>Todo: related reference</strong></p>
<div id="compressed-communication" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Compressed Communication</h3>
<span class="citation">Koloskova, Stich, and Jaggi (<a href="#ref-koloskova2019decentralized">2019</a>)</span> proposed a decentralized stochastic method Choco-SGD(see algorithm <a href="sec-asynt.html#exm:chocosgd">7.3</a>) that converges at rate
<span class="math display">\[\begin{equation}
\mathcal{O}(\frac{1}{nk}+\frac{1}{(\delta^2w^k)^2})
\end{equation}\]</span>
<p>where <span class="math inline">\(\delta=1-|\lambda_2(W)|\)</span> denotes the spectral gap of mixing matrix <span class="math inline">\(W\)</span>, <span class="math inline">\(w\leq1\)</span> is the compression quality factor. This method conserve the asymptotic network independence and can be applied to a network where the nodes compress their model update with quality <span class="math inline">\(0&lt;w\leq1\)</span>. Addtionnally, the noise introduced by compression operator vanishes as <span class="math inline">\(k\to\infty\)</span>.</p>
<p>Different from DSGD, Choco-SGD <a href="sec-asynt.html#exm:chocosgd">7.3</a> use the averaged iterate <span class="math inline">\(x_{\mathrm{avg}}=\frac{1}{S}\sum\limits_{k=1}^{k_{\mathrm{stop}}}w_k\bar x(k)\)</span>, i.e., theorem <a href="sec-asynt.html#thm:chocorate">7.1</a>,</p>

<div class="theorem">
<span id="thm:chocorate" class="theorem"><strong>Theorem 7.1  </strong></span>Let assumptions <a href="index.html#exr:muL">1.1</a> and <a href="sec-asynt.html#exr:chocoF">7.2</a> hold, algorithm <a href="sec-asynt.html#exm:chocosgd">7.3</a> with SGD stepsize <span class="math inline">\(\alpha_k=\frac{4}{\mu(a+k)}\)</span>, <span class="math inline">\(a\geq\max\{\frac{410}{\delta^2w},16\kappa\}\)</span> for <span class="math inline">\(\kappa=\frac{L}{\mu}\)</span>, and consensus stepsize <span class="math inline">\(\gamma=\frac{\delta^{2} \omega}{16 \delta+\delta^{2}+4 \beta^{2}+2 \delta \beta^{2}-8 \delta \omega}\)</span> converges with the rate <span class="math display">\[
\mathbb{E} \left[f(x_{\mathrm{avg}})-f(x^*)\right]=\mathcal{O}\left(\frac{\bar{\sigma}^{2}}{\mu n T}\right)+\mathcal{O}\left(\frac{\kappa G^{2}}{\mu \omega^{2} \delta^{4} T^{2}}\right)+\mathcal{O}\left(\frac{G^{2}}{\mu \omega^{3} \delta^{6} T^{3}}\right)
\]</span> where <span class="math inline">\(x_{\mathrm{avg}}=\frac{1}{S}\sum\limits_{k=0}^{k_{\mathrm{stop}}}w_k\bar x(k)\)</span> with weight <span class="math inline">\(w_k=(a+k)^2\)</span> and <span class="math inline">\(S=\sum\limits_{k=0}^{k_{\mathrm{stop}}}w_k\)</span>
</div>

<p>In the proof of theorem <a href="sec-asynt.html#thm:chocorate">7.1</a>, the difference is that the author <span class="citation">Koloskova, Stich, and Jaggi (<a href="#ref-koloskova2019decentralized">2019</a>)</span> deal the term <span class="math display">\[
\bar x(k)-\alpha_k h(\bar x(k))-x^* 
\]</span> differently. They estimate <span class="math inline">\(\Vert h(\bar x(k))\Vert^2\)</span> and <span class="math inline">\(\langle\bar x(k)-x^*,h(\bar x(k))\rangle\)</span>(from lemma <a href="sec-asynt.html#lem:Lmini">7.3</a>, we have <span class="math inline">\(f(\bar x(k))-f(x^*)\)</span>), while in DSGD, we use lemma <a href="sec-sharp.html#lem:contraction2L">8.2</a>. Then based on a lemma from <span class="citation">Stich, Cordonnier, and Jaggi (<a href="#ref-stich2018sparsified">2018</a>)</span>, they finish the proof.</p>

<div class="lemma">
<span id="lem:Lmini" class="lemma"><strong>Lemma 7.3  </strong></span>If <span class="math inline">\(f\)</span> has <span class="math inline">\(L-\)</span>Lipschitz gradient with minimizer <span class="math inline">\(x^*,s.t.\nabla f(x^*)=\mathbf{0}\)</span>, then <span class="math display">\[
  \|\nabla f(x)\|^{2}=\left\|\nabla f(x)-\nabla f\left(x^{\star}\right)\right\|^{2} \leq 2 L\left(f(x)-f\left(x^{\star}\right)\right)
\]</span>
</div>

<p>Let <span class="math inline">\(Q(\cdot):\mathbb{R}^{p}\to\mathbb{R}^p\)</span> be a specific compression operator, which is known and satisfy assumption <a href="sec-asynt.html#exr:contractionEQ">7.1</a>. <span class="math inline">\(f_i(x):=E_{\xi_i\sim\mathcal{D}_i} F_i(x,\xi_i)\)</span> for a loss function <span class="math inline">\(F_i:\mathcal{R}^p\times \Omega_\boldsymbol\xi\)</span>, <span class="math inline">\(f_i\)</span> satisfy assumption <a href="index.html#exr:muL">1.1</a> and distribution <span class="math inline">\(\mathcal{D_1},...,\mathcal{D_n}\)</span> can be different on every node.</p>

<div class="exercise">
<span id="exr:contractionEQ" class="exercise"><strong>Assumption7.1  </strong></span>The compression operator <span class="math inline">\(Q(\cdot):\mathbb{R}^{p}\to\mathbb{R}^p\)</span> satisfies, <span class="math display">\[
  E_{Q}\|Q(x)-x\|^{2} \leq(1-\omega)\|x\|^{2}, x\in\mathbb{R}^p,
\]</span> for a parameter <span class="math inline">\(w&gt;0\)</span>. <span class="math inline">\(E_Q\)</span> denotes the expectation over the internal randomness of operator <span class="math inline">\(Q\)</span>
</div>

The CHOCO-SGD method can be seen in algorithm <a href="sec-asynt.html#exm:chocosgd">7.3</a>, 
<div class="example">
<p><span id="exm:chocosgd" class="example"><strong>Algorithm7.3  (CHOCO-SGD)  </strong></span>Initialize <span class="math inline">\(x_i(0)\in \mathbb{R}^{p}, \hat x_i(0)=\mathbf{0}\in\mathbb{R}^{p}\)</span> for <span class="math inline">\(i\in\mathcal{N}\)</span>, consensus stepsize <span class="math inline">\(\gamma\)</span>, SGD stepsize <span class="math inline">\(\alpha_k\geq0\)</span>,and mixing matrix <span class="math inline">\(W=(w_{ij})\in\mathbb{R}^{n\times n}\)</span></p>
<p>For <span class="math inline">\(k=0,1,...\)</span> do in parallel for all agents <span class="math inline">\(i\in\mathcal{N}\)</span>,</p>
<ul>
<li><p>Sample <span class="math inline">\(\xi_i(k)\)</span>, compute <span class="math inline">\(g_i(k)=\nabla F_i(x_i(k),\xi_i(k))\)</span></p></li>
<li><p><span class="math inline">\(x_i(k+\frac{1}{2})=x_i(k)-\alpha_kg_i(k)\)</span> (stochastic gradient)</p></li>
<li><p><span class="math inline">\(q_i(k)=Q(x_i(k)-\hat x_i(k))\)</span> (compression operator)</p></li>
<li><p>For all the neighbor <span class="math inline">\(j\)</span> of agents <span class="math inline">\(i\)</span>, i.e., <span class="math inline">\((i,j)\in\mathcal{E}\)</span>,</p>
<ul>
<li><p>Send <span class="math inline">\(q_i(k)\)</span> and receive <span class="math inline">\(q_j(k)\)</span></p></li>
<li><p><span class="math inline">\(\hat x_j(k+1)=\hat x_j(k)+q_j(k)\)</span></p></li>
</ul></li>
<li><span class="math inline">\(x_i(k+1)=x_i(k+\frac{1}{2})+\gamma \sum_{j:(i,j)\in\mathcal{E}} w_{ij}(\hat x_j(k+1)-\hat x_i(k+1))\)</span></li>
</ul>
</div>

<p>When the compression quality <span class="math inline">\(w=1\)</span>,i.e. no communication compression, and consensus stepsize <span class="math inline">\(\gamma=1\)</span>, the updation in algorithm <a href="sec-asynt.html#exm:chocosgd">7.3</a> becomes <span class="math display">\[
x_i(k+1)=\sum\limits_{i=1}^nw_{ij}(x_i(k)-\alpha_kg_i(k))
\]</span> which is the DSGD algorithm <a href="sec-asynt.html#exm:sgd">7.2</a>. From the setting <span class="math display">\[f_i(x):=E_{\xi_i\sim\mathcal{D}_i} F_i(x,\xi_i)\]</span> <span class="math inline">\(g_i(k)\)</span> satisify the unbiased property in assumption <a href="sec-dsgt.html#exr:estg">4.1</a> automatically when <span class="math inline">\(\nabla\)</span> and expectation on <span class="math inline">\(F_i\)</span> can be interchanged. Despite the second property in assumption <a href="sec-dsgt.html#exr:estg">4.1</a>, we need to assum the second moment of <span class="math inline">\(\nabla F_i(x,\xi_i)\)</span> is finite,i.e., assumption <a href="sec-asynt.html#exr:chocoF">7.2</a>. A little difference is that <span class="math inline">\(\sigma\)</span> can be different for each agent.</p>

<div class="exercise">
<span id="exr:chocoF" class="exercise"><strong>Assumption7.2  </strong></span>
<span class="math display">\[\begin{align}
E_{\xi_{i}}\left\|\nabla F_{i}\left(x, \xi_{i}\right)-\nabla f_{i}(x)\right\|^{2} &amp;\leq \sigma_{i}^{2}, \quad \forall x \in \mathbb{R}^{d}, i \in\mathcal{N}\\
E_{\xi_{i}}\left\|\nabla F_{i}\left(x, \xi_{i}\right)\right\|^{2} &amp;\leq G^{2},\quad\forall x \in \mathbb{R}^{d}, i \in\mathcal{N}
\end{align}\]</span>
</div>


</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-koloskova2019decentralized">
<p>Koloskova, Anastasia, Sebastian U Stich, and Martin Jaggi. 2019. “Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication.” <em>arXiv Preprint arXiv:1902.00340</em>.</p>
</div>
<div id="ref-pu2019sharp">
<p>Pu, Shi, Alex Olshevsky, and Ioannis Ch. Paschalidis. 2019a. “A Sharp Estimate on the Transient Time of Distributed Stochastic Gradient Descent.”</p>
</div>
<div id="ref-pu2019asymptotic">
<p>Pu, Shi, Alex Olshevsky, and Ioannis Ch. 2019b. “Asymptotic Network Independence in Distributed Stochastic Optimization for Machine Learning.”</p>
</div>
<div id="ref-stich2018sparsified">
<p>Stich, Sebastian U, Jean-Baptiste Cordonnier, and Martin Jaggi. 2018. “Sparsified Sgd with Memory.” In <em>Advances in Neural Information Processing Systems</em>, 4447–58.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>smaller <span class="math inline">\(p(\mathcal{G})\)</span> is possible for some special cases<a href="sec-asynt.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Computing Power: Two processors have the same computing power if they can run the same programs (after translation into each processor’s machine language) and produce the same results<a href="sec-asynt.html#fnref4">↩</a></p></li>
<li id="fn5"><p>It seems <span class="math inline">\(W\)</span> in DSGT is also symmetric?<a href="sec-asynt.html#fnref5">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="gossip-like-push-pull-and-dsgt.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec-sharp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["DistributedOpt.pdf", "DistributedOpt.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
