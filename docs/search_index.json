[
["index.html", "Notes about Distributed Optimization Chapter 1 Introduction", " Notes about Distributed Optimization Kun Huang 2020-04-16 Chapter 1 Introduction These are some notes about distributed optimization, including some algorithms, their analysis of convergence, and some understandings of my own. Although the authors of those literature already provide proofs, I complement some details and try to figure out why should we prove in such a way. Hence they could be more easy to understand, especially for myself. We summarize some distributed gradient based algorithms solving the problem (1.1), namely Push-Pull Gradient Method1 (Pu et al. 2018), and Distributed Stochastic Gradient Tracking Methods(DSGT) (Pu and Nedić 2018). \\[\\begin{equation} \\underset{x\\in\\mathbb{R}^p}{\\min} f(x):=\\frac{1}{n}\\sum_{i=1}^n f_i(x) \\tag{1.1} \\end{equation}\\] Where \\(f_i:\\mathbb{R}^p\\to \\mathbb{R}\\) is known by agent \\(i\\) only, and all the agents communicate and exchange information over a network. In general, these two methods use a decision variable \\(x\\in \\mathbb{R}^p\\) and an auxiliary variable \\(y\\in\\mathbb{R}^p\\) and have a form of (1.2) for the \\((k+1)\\)th iteration. \\[\\begin{align} X_{k+1} &amp;= S_1(X_k-\\boldsymbol\\alpha Y_k)\\\\ Y_{k+1} &amp;= S_2Y_k + T(X_{k+1}) - T(X_k) \\tag{1.2} \\end{align}\\] Where \\(S_1\\) and \\(S_2\\) are the matrices inducing the graphs, \\(T(\\cdot)\\) is the estimate of gradient, and \\(\\boldsymbol\\alpha = \\text{diag}(\\alpha_1,...,\\alpha_n)\\in\\mathbb{R}^{n\\times n}\\), \\(\\alpha_i\\) is the step size initialized for agent \\(i\\). \\[\\begin{align*} X_k &amp;= \\left(x_{1,k},x_{2,k},...,x_{n,k}\\right)^T\\in\\mathbb{R}^{n\\times p}\\\\ Y_k &amp;= \\left(y_{1,k},y_{2,k},...,y_{n,k}\\right)^T\\in\\mathbb{R}^{n\\times p}\\\\ \\end{align*}\\] \\(x_{i,k}\\in\\mathbb{R}^p\\) denotes the decision variable of agent \\(i\\) of the \\(k\\)th iteration, \\(y_{i,k}\\) represents the auxiliary variable of agent \\(i\\) of the \\(k\\)th iteration. Under assumption 1.1 , there exists an unique solution to (1.1) \\(x^*\\in\\mathbb{R}^{1\\times p}\\). To prove the convergence of those methods, the idea is to bound three quantities, namely \\(\\bar x_{k+1}-x^*\\), \\(X_{k+1}-\\mathbf{1}\\bar x_{k+1}\\), and \\(Y_{k+1}-\\mathbf{1}\\bar y_{k+1}\\) by the linear combination of their previous values under corresponding measurements. This will introduce a matrix \\(A\\). In order to make it converge, we need to make \\(\\rho(A)&lt;1\\), i.e. the spectral radius of \\(A\\) to be less than \\(1\\)(similar idea with contraction mapping), which will derive constraints to the stepsize \\(\\alpha\\). By doing so, the authors prove the convergence and derive their convergence rate. Assumption1.1 Each \\(f_i\\) is \\(\\mu\\)-strongly convex and its gradient is \\(L-\\)Lipschitz continuous, i.e. \\(\\forall x,x&#39;\\in\\mathbb{R}^{p}\\) \\[ \\left\\langle\\nabla f_{i}(x)-\\nabla f_{i}\\left(x^{\\prime}\\right), x-x^{\\prime}\\right\\rangle \\geq \\mu\\left\\|x-x^{\\prime}\\right\\|_{2}^{2} \\] \\[ \\left\\|\\nabla f_{i}(x)-\\nabla f_{i}\\left(x^{\\prime}\\right)\\right\\|_{2} \\leq L\\left\\|x-x^{\\prime}\\right\\|_{2} \\] We also use the following notation, \\[\\begin{equation*} F(X) = \\sum_{i=1}^n f_i(x_i), X\\in\\mathbb{R}^{n\\times p} \\end{equation*}\\] \\[\\begin{equation*} \\nabla F(X) = \\left(\\nabla f_1(x_1), ..., \\nabla f_n(x_n)\\right)^T\\in\\mathbb{R}^{n\\times p} \\end{equation*}\\] If not stated otherwise, we use the capital letter to denote a matrix, and use column vectors. The appendix in (Koloskova, Stich, and Jaggi 2019) includes some inequalities we repeatedly use in the proof or deravation. References "],
["orgnization-of-the-notes.html", "Chapter 2 Orgnization of the Notes", " Chapter 2 Orgnization of the Notes Currently contents include The Push-Pull method (Pu et al. 2018) The distributed stochastic gradient tracking method(DSGT)(Pu and Nedić 2018) References "],
["the-push-pull-method.html", "Chapter 3 The Push-Pull Method 3.1 Introduction 3.2 Analysis of Convergence", " Chapter 3 The Push-Pull Method 3.1 Introduction Suppose we have two nonnegative matrices \\(R,C^T\\in\\mathbb{R}^{n\\times n}\\) and two induced digraph \\(\\mathcal{G}_R, \\mathcal{G}_{C^T}\\). Suppose each agent \\(i\\in\\mathcal{N}\\) can actively and reliably push information out to its neighbor \\(l\\in\\mathcal{N}^{out}_{C,i}\\subset\\mathcal{N}\\) and pull information from its neighbor \\(j\\in\\mathcal{N}^{in}_{R,i}\\subset\\mathcal{N}\\). Matrix \\(R=(r_{ij})\\in\\mathbb{R}^{n\\times n}\\) denotes the pulling weights that agent \\(i\\) pulls information from agent \\(j\\). Thus the row sum of \\(R\\) should be \\(1\\), i.e. \\(R\\boldsymbol 1 = \\boldsymbol 1\\) and \\(r_{ij}\\geq 0\\). That is to say, matrix \\(R\\) is row-stochastic. Similarly, \\(C = (c_{ij})\\in\\mathbb{R}^{n\\times n}\\) denotes the pushing weights that agent \\(i\\) pushes information to agent \\(j\\). In other words, it denotes the pulling weights that agent \\(j\\) pulls information from agent \\(i\\). Hence \\(C^T\\boldsymbol 1=\\boldsymbol 1\\), i.e. \\(\\boldsymbol 1^T C=\\boldsymbol 1^T, c_{ji}\\geq 0\\). Moreover, for agent \\(i\\), it will have no problem getting information from itself, hence \\(r_{ii}&gt;0, c_{ii}&gt;0\\). Assumption 3.1 will gurantee this. Remark. In a digraph induced by a nonnegative matrix \\(M=(m_{ij})\\in\\mathbb{R}^{n\\times n},\\exists\\) a path from node \\(j\\) to node \\(i\\) iff \\(m_{ij}&gt;0\\). Assumption3.1 The matrix \\(R\\in\\mathbb{R}^{n\\times n}\\) is nonnegative row-stochastic and \\(C\\in\\mathbb{R}^{n\\times n}\\) is nonnegative column-stochastic, i.e., \\(R\\mathbf{1}=\\mathbf{1}\\) and \\(\\mathbf{1}^TC=\\mathbf{1}\\). \\(r_{ii}&gt;0,c_{ii}&gt;0,\\forall i\\). Assumption3.2 The graphs \\(\\mathcal{G}_R\\) and \\(\\mathcal{G}_{C^T}\\) each contain at least one spaning tree. Moreover, there exists at least one node that is a root of spanning trees for both \\(\\mathcal{G}_{R}\\) and \\(\\mathcal{G}_{C^T}\\), i.e. \\(\\mathcal{R}_{R} \\cap \\mathcal{R}_{\\mathbf{C}^{\\top}} \\neq \\emptyset\\), where \\(\\mathcal{R}_R\\) is the set of roots of all possible spanning trees in the graph \\(\\mathcal{G}_R\\). \\ Assumption 3.2 is to say that at least one agent is connected to all other agents in this system(thus they should be both “pulled” and “pushed”), which is weaker to assume that the system is connected. Hence these agents are significant and we must assume at least one of them contribute to the update, i.e. assumption 3.3. Figure 3.12 shows the master-workers architecture in distributed optimization, which fits the assumption 3.2 when \\(\\mathcal{R}_{R} \\cap \\mathcal{R}_{\\mathbf{C}^{\\top}}=\\{\\text{master node}\\}\\). Figure 3.1: Master-Workers Architecture Assumption3.3 \\(\\exists i\\in \\mathcal{R}_{R} \\cap \\mathcal{R}_{\\mathbf{C}^{\\top}}\\) whose step size \\(\\alpha_i&gt;0\\). Assumption 3.2 and 3.1 would lead to the following lemma 3.1, Lemma 3.1 Under assumptions 3.1 and 3.2, the matrix \\(R\\) has a unique nonnegative left eigenvector \\(u^T\\)(w.r.t. eigenvalue 1) with \\(u^T\\boldsymbol1 = n\\), and the matrix \\(C\\) has a unique nonnegative right eigenvector \\(v\\) (w.r.t. eigenvalue 1) with \\(\\boldsymbol1^T v = n\\), i.e., \\[ u^T R = 1\\cdot u^T \\] \\[ Cv = 1\\cdot v \\] Moreover, \\(u^T\\) (resp., \\(v\\)) is nonzero only on the entries associated with agents \\(i\\in\\mathcal{R}_R\\)(resp., \\(j\\in\\mathcal{R}_{C^T}\\)), and \\(u^Tv&gt;0\\). The idea of Push-Pull Gradient Methods is that, at each iteration step \\(k\\), agent \\(i\\) updates its local copy of decision variable \\(x_{i,k+1}\\in\\mathbb R^p\\) according to the information it pulls from its nearby agents based on the corresponding pulling weights \\((r_{i1},r_{i2},...,r_{in})\\). Then it will also update the information stored in an auxiliary variable \\(y_{i, k+1}\\in\\mathbb{R}^p\\) Algorithm3.1 (Push-Pull Method) Each agent \\(i\\) chooses its local step size \\(\\alpha_i\\geq0\\) and initilized with an arbitary \\(x_{i,0}\\in\\mathbb{R}^p, y_{i,0}=\\nabla f_i(x_{i,0})\\). For k = 0, 1, …, For \\(i\\in\\mathcal{N}\\), \\(x_{i, k+1} = \\sum\\limits_{j=1}^nr_{ij}(x_{j, k}-\\alpha_j y_{j, k})\\) (Pull) \\(y_{i, k+1} = \\sum\\limits_{j=1}^nc_{ij}y_{j,k}+\\nabla f_i(x_{i,k+1})-\\nabla f_i(x_{i,k})\\)(Push) Or in matrix form using \\(R=(r_{ij})\\in\\mathbb{R}^{n\\times n}, C=(c_{ij})\\in\\mathbb{R}^{n\\times n}, X_k\\in\\mathbb{R}^{n\\times p}, Y_k\\in\\mathbb{R}^{n\\times p}, \\boldsymbol\\alpha = \\text{diag}(\\alpha_1,...,\\alpha_n)\\). \\[\\begin{align} X_{k+1} &amp;= R(X_{k}-\\boldsymbol\\alpha Y_k),\\\\ Y_{k+1} &amp;= CY_k+\\nabla F(X_{k+1})-\\nabla F(X_k) \\tag{3.1} \\end{align}\\] Remark. In the initialization of algorithm 3.1, \\(y_{i,0}=\\nabla f_i(x_{i,0}),i=1,2,...,n\\),i.e., \\(Y_0=\\nabla F(X_0)\\) is important since \\[\\begin{align*} \\mathbf{1}^T Y_{1} &amp;= \\mathbf{1}^T(CY_0+\\nabla F(X_1)-\\nabla F(X_0))\\\\ &amp;= \\mathbf{1}^T\\nabla F(X_1)+Y_0-\\nabla F(X_0)\\\\ &amp;= \\mathbf{1}^T\\nabla F(X_1) \\end{align*}\\] Then by induction, we can have \\[\\begin{equation} \\frac{1}{n} \\mathbf{1}^{\\top} Y_{k}=\\frac{1}{n} \\mathbf{1}^{\\top} \\nabla F\\left(X_{k}\\right), \\quad \\forall k \\tag{3.2} \\end{equation}\\] which says the auxiliary variable \\(Y_{k}\\) is to track the average gradient. 3.2 Analysis of Convergence we first bound \\((\\Vert\\bar x_{k+1}-x^*\\Vert_2, \\Vert X_{k+1}-\\boldsymbol1\\bar x_{k+1}\\Vert_R,\\Vert Y_{k+1}-v\\bar y_{k+1}\\Vert_C)^T\\) by a linear combination in terms of their previous values. Then based on lemma 3.2, we derive how should we choose the step sizes \\(\\alpha_i,i=1,2,...,n\\) so that \\(\\rho(A)&lt;1\\). Lemma 3.2 Given a nonnegative, irreducible matrix \\(M=(m_{ij})\\in \\mathbb{R}^{n\\times n}\\) with \\(m_{ii}&lt;\\lambda, i=1,2,3\\) for some \\(\\lambda&gt;0\\). \\(\\rho(M)&lt;\\lambda\\Leftrightarrow \\text{det}(\\lambda I-M)&gt;0\\) In this chapter, we define the matrix norm of \\(X\\in\\mathbb R^{n\\times p }\\) using definition 3.1. Definition 3.1 Given an arbitary vector norm \\(\\Vert\\cdot\\Vert\\) on \\(\\mathbb{R}^n\\), \\(\\forall X\\in\\mathbb{R}^{n\\times p }, \\Vert X\\Vert:= \\left\\|\\left[\\left\\|\\mathbf{x}^{(1)}\\right\\|,\\left\\|\\mathbf{x}^{(2)}\\right\\|, \\ldots,\\left\\|\\mathbf{x}^{(p)}\\right\\|\\right]\\right\\|_{2}\\), where \\(x^{(j)},j=1,2,...,p\\) denote the \\(j\\)th column of \\(X\\), \\(\\Vert \\cdot\\Vert_2\\) denotes \\(2-\\)norm. For example, when \\(\\Vert\\cdot\\Vert\\) is the \\(2-\\)norm, then the matrix norm under definition 3.1 is the Frobenius norm. While in the chapter of distributed stochastic gradient tracking method, we use Frobenius norm as matrix norm. 3.2.1 Relationship between two iteration steps We first give definition of \\(\\bar x_k\\) and \\(\\bar y_k\\). \\[\\begin{equation} \\bar x_k := \\frac{1}{n}u^TX_k\\in\\mathbb{R}^{1\\times p},\\quad \\bar y_k:= \\frac{1}{n}\\boldsymbol 1 \\nabla F(X_k)\\in\\mathbb{R}^{1\\times p} \\tag{3.3} \\end{equation}\\] The authors do not define \\(\\bar x_k\\) as \\(\\frac{1}{n}\\boldsymbol 1^TX_k\\) is because the pulling information is subject to the graph \\(\\mathcal{G}_R\\), which may not be strongly connected. Thus agent \\(i\\) could never use information from agent \\(j\\not\\in N^{in}_{R,i}\\). For the pull step, \\[\\begin{equation} \\bar x_{k+1} = \\frac{1}{n}u^TX_{k+1}\\stackrel{\\text{pull step}}{=}\\frac{1}{n}u^TR(X_k-\\boldsymbol\\alpha Y_k)=\\bar x_k-\\frac{1}{n}u^T\\boldsymbol\\alpha Y_k \\tag{3.4} \\end{equation}\\] Hence, \\[\\begin{align} X_{k+1}-\\boldsymbol1\\bar x_{k+1}&amp;= R(X_k-\\boldsymbol\\alpha Y_k)-\\boldsymbol1(\\bar x_k-\\frac{1}{n}u^T\\boldsymbol\\alpha Y_k)\\\\ &amp;=(R-\\frac{\\boldsymbol 1 u^T}{n})(X_k-\\boldsymbol 1\\bar x_k)- (R-\\frac{\\boldsymbol 1 u^T}{n})\\boldsymbol\\alpha Y_k+\\frac{\\boldsymbol 1 u^T}{n}(X_k-\\boldsymbol 1\\bar x_k)\\\\ &amp;=(R-\\frac{\\boldsymbol 1 u^T}{n})(X_k-\\boldsymbol 1\\bar x_k)- (R-\\frac{\\boldsymbol 1 u^T}{n})\\boldsymbol\\alpha Y_k \\tag{3.5} \\end{align}\\] This is because \\(\\frac{\\boldsymbol 1 u^T}{n}(X_k-\\boldsymbol 1\\bar x_k)=\\bar x_k-\\frac{u^T\\boldsymbol1}{n}\\bar x_k=0\\) according to lemma 3.1. To see what does this difference mean, we rewrite \\(X_{k+1}-\\boldsymbol1\\bar x_{k+1}\\) as \\[\\begin{equation} (x_1-\\frac{1}{n}\\sum_{i=1}^n u_i x_i,...,x_n-\\frac{1}{n}\\sum_{i=1}^n u_i x_i)^T\\in\\mathbb{R}^{n\\times p} \\end{equation}\\] where \\(u=(u_1,...,u_n)^T\\in\\mathbb{R}^n,x_i\\in\\mathbb{R}^p\\). It denotes the difference between each agent \\(i\\)’s decision variable and the overall weighted mean. Remark. The interpretation of \\(R-\\frac{\\boldsymbol 1 u^T}{n}\\)? For the push step, \\[\\begin{align} Y_{k+1}-v\\bar y_{k+1}&amp;\\stackrel{\\text{push step}}=CY_k+\\nabla F(X_{k+1})-\\\\ &amp;\\nabla F(X_k)-v[\\frac{1}{n}\\boldsymbol1(CY_k+\\nabla F(X_{k+1})-\\nabla F(X_k))]\\\\ &amp;=CY_k-v\\bar y_k+(I-\\frac{v\\boldsymbol1^T}{n})(\\nabla F(X_{k+1})-\\nabla F(X_k))\\\\ &amp;=(C-\\frac{v\\boldsymbol1^T}{n})(Y_k-v\\bar y_k)+(I-\\frac{v\\boldsymbol1^T}{n})(\\nabla F(X_{k+1})-\\nabla F(X_k))+\\\\ &amp;Cv\\bar y_k+\\frac{v\\boldsymbol1^T}{n}Y_k-\\frac{v\\boldsymbol1^Tv}{n}\\bar y_k-v\\bar y_k\\\\ &amp;=(C-\\frac{v\\boldsymbol1^T}{n})(Y_k-v\\bar y_k)+(I-\\frac{v\\boldsymbol1^T}{n})(\\nabla F(X_{k+1})-\\nabla F(X_k)) \\tag{3.6} \\end{align}\\] where \\[ \\frac{1}{n}v\\boldsymbol1^TCY_k=v\\bar y_k \\] \\[ Cv\\bar y_k+\\frac{v\\boldsymbol1^T}{n}Y_k-\\frac{v\\boldsymbol1^Tv}{n}\\bar y_k-v\\bar y_k=v\\bar y_k+v\\bar y_k-v\\bar y_k-v\\bar y_k=0 \\] This is because the column-stochastic of \\(C\\), i.e. \\(\\mathbf{1}^TC=\\mathbf{1}^T\\) and lemma 3.1. Similarly, we can rewrite \\(Y_{k+1}-v\\bar y_{k+1}\\) as \\[\\begin{equation} (y_1-\\frac{1}{n}v_1\\sum_{i=1}^ny_i,...,y_n-\\frac{1}{n}v_n\\sum_{i=1}^ny_i)^T \\end{equation}\\] Where \\(v=(v_1,...,v_n)^T\\in\\mathbb{R}^n,y_i\\in\\mathbb R^p\\). Additionally, recall our goal is to bound those three distance, from (3.4), we separate \\(Y_k\\) as \\(Y_k-v\\bar y_k\\) and \\(v\\bar y_k\\), then \\[\\begin{align} \\bar x_{k+1} &amp;=\\bar x_k -\\underbrace{\\frac{1}{n}u^T\\boldsymbol\\alpha v}_{\\alpha&#39;}\\bar y_k-\\frac{1}{n}u^T\\boldsymbol \\alpha(Y_k-v\\bar y_k)\\\\ &amp;=\\bar x_k-\\alpha&#39;(\\bar y_k-\\underbrace{\\frac{1}{n}\\boldsymbol 1^T\\nabla F(\\boldsymbol 1\\bar x_k)}_{g_k})-\\frac{1}{n}\\alpha&#39;\\boldsymbol 1^T\\nabla F(\\boldsymbol 1\\bar x_k)-\\frac{1}{n}u^T\\boldsymbol\\alpha(Y_k-v\\bar y_k)\\\\ &amp;=\\bar x_k-\\alpha&#39;(\\bar y_k-g_k)-\\alpha&#39;g_k-\\frac{1}{n}u^T\\boldsymbol\\alpha(Y_k-v\\bar y_k) \\tag{3.7} \\end{align}\\] The auther introduce \\(g_k=\\frac{1}{n}\\boldsymbol 1^T\\nabla F(\\boldsymbol 1\\bar x_k)\\) is because \\(\\bar y_k =\\frac{1}{n}\\boldsymbol 1^T \\nabla F(X_k)\\), i.e, equation (3.2). It is the gradient of the obejective function at \\(\\bar x_k\\). 3.2.2 Inequalities we then bound \\((\\Vert\\bar x_{k+1}-x^*\\Vert_2, \\Vert X_{k+1}-\\boldsymbol1\\bar x_{k+1}\\Vert_R,\\Vert Y_{k+1}-v\\bar y_{k+1}\\Vert_C)^T\\). Lemma 3.3 Let the assumption 1.1, 3.1, and 3.2 hold and \\(\\alpha&#39;\\leq \\frac{2}{\\mu+L}\\), then \\(\\exists A\\in \\mathbb R^{3\\times 3}, s.t.\\) \\[\\begin{equation} \\left( \\begin{array}{c} \\Vert\\bar x_{k+1}-x^*\\Vert_2,\\\\ \\Vert X_{k+1}-\\boldsymbol1\\bar x_{k+1}\\Vert_R,\\\\ \\Vert Y_{k+1}-v\\bar y_{k+1}\\Vert_C)^T \\end{array} \\right) \\leq A \\left( \\begin{array}{c} \\Vert\\bar x_{k}-x^*\\Vert_2,\\\\ \\Vert X_{k}-\\boldsymbol1\\bar x_{k}\\Vert_R,\\\\ \\Vert Y_{k}-v\\bar y_{k}\\Vert_C \\end{array} \\right) \\tag{3.8} \\end{equation}\\] In general, assumption 3.1 and 3.2 is used to derive the relationships in (3.5), (3.6), and (3.7). Assumption 1.1 is needed for lemma 3.4. Next we derive the elements of \\(A\\), which can be seen in (3.13). We add supported lemmas during derivation. First, for \\(\\Vert\\bar x_{k+1}-x^*\\Vert_2\\), substitute \\(\\bar x_{k+1}\\) using (3.7), we have \\[\\begin{align} \\Vert\\bar x_{k+1}-x^*\\Vert_2&amp;\\leq \\left\\|\\bar{x}_{k}-\\alpha^{\\prime} g_{k}-x^{*}\\right\\|_{2}+\\alpha^{\\prime}\\left\\|\\bar{y}_{k}-g_{k}\\right\\|_{2}+\\frac{1}{n}\\left\\|u^{\\top} \\boldsymbol{\\alpha}\\left(Y_{k}-v \\bar{y}_{k}\\right)\\right\\|_{2} \\tag{3.9} \\end{align}\\] On the right hand side, \\(\\Vert \\bar{x}_{k}-\\alpha^{\\prime} g_{k}-x^{*}\\Vert_2\\) is the distance between the optimal and the next iterated value, \\(\\vert \\bar{y}_{k}-g_{k}\\Vert_2\\) is the distance between average gradient and gradient of iterated value. Lemma 3.4 connects them with \\(\\Vert X_{k}-\\boldsymbol1\\bar x_{k}\\Vert_2\\) and \\(\\Vert\\bar x_{k+1}-x^*\\Vert_2\\) and add conditions on \\(f_i\\) and \\(\\alpha&#39;\\). Lemma 3.4 Let assumption 1.1 hold, \\[ \\left\\|\\bar{y}_{k}-g_{k}\\right\\|_{2} \\leq \\frac{L}{\\sqrt{n}}\\left\\|X_{k}-\\mathbf{1} \\bar{x}_{k}\\right\\|_{2}, \\quad\\left\\|g_{k}\\right\\|_{2} \\leq L\\left\\|\\bar{x}_{k}-x^{*}\\right\\|_{2} \\] In addition, when \\(\\alpha&#39;\\leq \\frac{2}{\\mu+L}\\), we have \\[ \\left\\|\\bar{x}_{k}-\\alpha^{\\prime} g_{k}-x^{*}\\right\\|_{2} \\leq\\left(1-\\alpha^{\\prime} \\mu\\right)\\left\\|\\bar{x}_{k}-x^{*}\\right\\|_{2}, \\quad \\forall k \\] However, notice that our final goal involves norm \\(\\Vert\\cdot\\Vert_R\\) and \\(\\Vert\\cdot\\Vert_C\\). We need to transform them, which is ensured from the equivalence of norms. To make the notation more easily, the author gives lemma 3.5. Lemma 3.5 \\(\\exists \\delta_{\\mathrm{C}, \\mathrm{R}}, \\delta_{\\mathrm{C}, 2}, \\delta_{\\mathrm{R}, \\mathrm{C}}, \\delta_{\\mathrm{R}, 2}&gt;0,s.t. \\forall X\\in\\mathbb{R}^{n\\times p}\\), we have \\(\\Vert X\\Vert_{\\mathrm{C}} \\leq \\delta_{\\mathrm{C}, \\mathrm{R}}\\Vert X\\Vert_{\\mathrm{R}},\\Vert X\\Vert_{\\mathrm{C}} \\leq \\delta_{\\mathrm{C}, 2}\\Vert X\\Vert_{2},\\Vert X\\Vert_{\\mathrm{R}} \\leq \\delta_{\\mathrm{R}, \\mathrm{C}}\\Vert X\\Vert_{\\mathrm{C}}\\), and \\(\\|X\\|_{\\mathrm{R}} \\leq\\delta_{\\mathrm{R}, 2}\\Vert X\\Vert_{2}\\). In addition, with a proper rescaling of the norms \\(\\Vert\\cdot\\Vert_R\\) and \\(\\Vert\\cdot\\Vert_C\\), we have \\(\\Vert X\\Vert_{2} \\leq\\Vert X\\Vert_{\\mathrm{R}} \\text { and }\\Vert X\\Vert_{2} \\leq\\Vert X\\Vert_{\\mathrm{C}}\\) On the other hand, \\(\\boldsymbol\\alpha=\\text{diag}(\\alpha_1,...,\\alpha_n)\\in \\mathbb{R}^{n\\times n}\\), then \\(\\Vert \\boldsymbol\\alpha\\Vert_2=\\sigma_{\\max}(\\boldsymbol\\alpha)=\\underset{i}{\\max}\\alpha_i:=\\hat\\alpha\\),since \\(\\alpha_i\\in\\mathbb{R}^+,i=1,2,...,n\\). \\(\\sigma(A)\\) denotes the singular value of \\(A\\). Finally, (3.9) can be written as \\[\\begin{align} \\Vert\\bar x_{k+1}-x^*\\Vert_2&amp;\\leq \\left(1-\\alpha^{\\prime} \\mu\\right)\\left\\|\\bar{x}_{k}-x^{*}\\right\\|_{2}+\\frac{\\alpha^{\\prime} L}{\\sqrt{n}}\\left\\|X_{k}-\\mathbf{1} \\bar{x}_{k}\\right\\|_{\\mathrm{R}}+\\\\ &amp;\\frac{\\hat{\\alpha}\\|u\\|_{2}}{n}\\left\\|Y_{k}-v \\bar{y}_{k}\\right\\|_{\\mathrm{C}} \\tag{3.10} \\end{align}\\] Where the first and second parts come from lemma 3.4, which adds constraints on \\(f_i\\) and \\(\\alpha&#39;\\). The second part also uses lemma 3.5 in transforming different norms, as well as the last part. Additionally, the last part uses lemma 3.6 when separating \\(u,\\boldsymbol\\alpha\\) out of norm, which can be seen as a further result of consistency of norms. Lemma 3.6 Given an arbitrary norm \\(\\Vert\\cdot\\Vert\\), \\(\\forall W\\in\\mathbb{R}^{n\\times n}\\) and \\(X\\in\\mathbb{R}^{n\\times p}\\), we have \\(\\Vert WX\\Vert\\leq\\Vert W\\vert\\Vert X\\Vert\\). \\(\\forall w\\in\\mathbb{R}^{n\\times 1},x\\in\\mathbb{R}^{1\\times p},\\Vert wx\\Vert = \\Vert w\\Vert \\Vert x\\Vert_2\\) \\ For \\(\\Vert X_{k+1}-\\boldsymbol1\\bar x_{k+1}\\Vert_R\\), from (3.5), we have \\[\\begin{align} \\Vert X_{k+1}-\\boldsymbol1\\bar x_{k+1}\\Vert_R&amp;\\leq \\underbrace{\\Vert R-\\frac{\\mathbf{1} u^{T}}{n}\\Vert_R}_{\\sigma_R}\\cdot\\Vert X_{k}-\\mathbf{1} \\bar{x}_{k}\\Vert_R+\\Vert R-\\frac{\\mathbf{1} u^{T}}{n}\\Vert_R\\cdot \\Vert\\boldsymbol{\\alpha}\\Vert_R\\cdot\\Vert Y_{k}-v\\bar y_k+v\\bar y_k\\Vert_R\\\\ &amp;\\leq \\sigma_R\\Vert X_{k}-\\mathbf{1} \\bar{x}_{k}\\Vert_R + \\sigma_R\\Vert \\boldsymbol\\alpha\\Vert_2(\\delta_{R,C}\\Vert Y_{k}-v\\bar y_k\\Vert_C + \\Vert v\\Vert_R\\cdot \\Vert \\bar y_k\\Vert_2)\\\\ &amp;\\leq \\sigma_R\\Vert X_{k}-\\mathbf{1} \\bar{x}_{k}\\Vert_R + \\sigma_R\\hat\\alpha[\\delta_{R,C}\\Vert Y_{k}-v\\bar y_k\\Vert_C + \\\\ &amp;\\Vert v\\Vert_R (\\frac{L}{\\sqrt{n}}\\left\\|X_{k}-\\mathbf{1} \\bar{x}_{k}\\right\\|_{2}+L\\left\\|\\bar{x}_{k}-x^{*}\\right\\|_{2})]\\\\ &amp;\\leq \\sigma_R\\left(1+\\hat{\\alpha}\\|v\\|_{\\mathrm{R}} \\frac{L}{\\sqrt{n}}\\right)\\left\\|X_{k}-\\mathbf{1} \\bar{x}_{k}\\right\\|_{\\mathrm{R}} + \\hat{\\alpha} \\sigma_{\\mathrm{R}} \\delta_{\\mathrm{R}, \\mathrm{C}}\\left\\|Y_{k}-v \\bar{y}_{k}\\right\\|_{\\mathrm{C}}+\\\\ &amp;\\hat{\\alpha} \\sigma_{\\mathrm{R}}\\|v\\|_{\\mathrm{R}} L\\left\\|\\bar{x}_{k}-x^{*}\\right\\|_{2} \\tag{3.11} \\end{align}\\] Where the second inquality is derived from lemma 3.8 in transforming \\(\\Vert\\boldsymbol\\alpha\\Vert_R=\\Vert\\boldsymbol\\alpha\\Vert_2=\\hat\\alpha\\) since \\(\\boldsymbol\\alpha\\) is diagonal and lemma 3.5 in transforming \\(\\Vert\\cdot\\Vert_R\\) into \\(\\Vert\\cdot\\Vert_C\\). Next we use lemma 3.6 and 3.4 to transform \\(\\Vert \\bar y_k\\Vert_R\\) into the two parts. Finally, we choose a proper rescaling of the norm \\(\\Vert\\cdot\\Vert_R\\) to derive \\(\\Vert X_{k}-\\mathbf{1} \\bar{x}_{k}\\Vert_2\\leq\\Vert X_{k}-\\mathbf{1} \\bar{x}_{k}\\Vert_R\\). Lemma 3.7 Let assumptions 3.1 and 3.2 hold. Then the spectral radii of \\((R-\\frac{\\mathbf{1}u^T}{n})\\) and \\((C-\\frac{v\\mathbf{1}^T}{n})\\), denoted as \\(\\rho_R\\) and \\(\\rho_C\\) respectively are both less than 1. \\ Lemma 3.8 There exist matrix norms \\(\\Vert\\cdot\\Vert_R\\) and \\(\\Vert\\cdot\\Vert_C\\) such that \\(\\sigma_R:=\\Vert R-\\frac{\\mathbf1u^T}{n}\\Vert_R&lt;1,\\sigma_{\\mathrm{C}}:=\\left\\|\\mathbf{C}-\\frac{v \\mathbf{1}^{\\mathrm{T}}}{n}\\right\\|_{\\mathrm{C}}&lt;1\\), and \\(\\sigma_R\\) and \\(\\sigma_C\\) are arbitrarily close to \\(\\rho_R\\) and \\(\\rho_C\\), respectively. In addition, given any diagnal matrix \\(W\\in\\mathbb{R}^{n\\times n}\\), we have \\(\\|W\\|_{\\mathrm{R}}=\\|W\\|_{\\mathrm{C}}=\\|W\\|_{2}\\). \\ For \\(\\Vert Y_{k+1}-v\\bar y_{k+1}\\Vert_C\\), denote \\(\\sigma_{\\mathrm{C}}:=\\left\\|\\mathbf{C}-\\frac{v \\mathbf{1}^{\\mathrm{T}}}{n}\\right\\|_{\\mathrm{C}}\\) and \\(c_0 :=\\Vert I-\\frac{v\\boldsymbol1^T}{n}\\Vert_C\\), from (3.6), we have \\[\\begin{align} \\Vert Y_{k+1}-v\\bar y_{k+1}\\Vert_C&amp;\\leq \\sigma_C\\Vert Y_k-v\\bar y_k\\Vert_C+c_0\\Vert\\nabla F(X_{k+1})-\\nabla F(X_k)\\Vert_C\\\\ &amp;\\leq \\sigma_C \\Vert Y_k-v\\bar y_k\\Vert_C + c_0L\\delta_{C,2}\\Vert X_{k+1} - X_k\\Vert_2 \\end{align}\\] For \\(\\Vert X_{k+1}-X_k\\Vert_2\\), we have \\[\\begin{align} \\Vert X_{k+1}-X_k\\Vert_2 &amp;=\\Vert R(X_k-\\boldsymbol\\alpha Y_k)-X_k\\Vert_2\\\\ &amp;=\\Vert (R-I)(X_k-\\mathbf 1\\bar x_k)+R\\boldsymbol\\alpha (Y_k-v\\bar y_k+v\\bar y_k)\\Vert_2\\\\ &amp;\\leq \\Vert R- I\\Vert_2\\cdot \\Vert X_k-\\mathbf 1\\bar x_k\\Vert_R + \\Vert R\\Vert_2\\hat\\alpha(\\Vert Y_k-v\\bar y_k+v\\bar y_k\\Vert_2)\\\\ \\end{align}\\] The inequality is based on lemma 3.5 by choosing a proper rescaling of \\(\\Vert \\cdot\\Vert_R\\). Then by lemma 3.4 and combine like terms, we have \\[\\begin{align} \\Vert Y_{k+1}-v\\bar y_{k+1}\\Vert_C&amp;\\leq \\left(\\sigma_{\\mathrm{C}}+\\hat{\\alpha} c_{0} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2} L\\right)\\left\\|Y_{k}-v \\bar{y}_{k}\\right\\|_{\\mathrm{C}} +\\\\ &amp;c_{0} \\delta_{\\mathrm{C}, 2} L\\left(\\|R-I\\|_{2}+\\hat{\\alpha}\\|R\\|_{2}\\|v\\|_{2} \\frac{L}{\\sqrt{n}}\\right)\\left\\|X_{k}-\\mathbf{1} \\bar{x}_{k}\\right\\|_{\\mathrm{R}} +\\\\ &amp;\\hat{\\alpha} c_{0} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2}\\|v\\|_{2} L^{2}\\left\\|\\bar{x}_{k}-x^{*}\\right\\|_{2} \\tag{3.12} \\end{align}\\] In short, \\(A\\) can be written as \\[\\begin{equation} A_{pp} = \\left( \\begin{array}{ccc} 1-\\alpha&#39;\\mu &amp; \\frac{\\alpha&#39;L}{\\sqrt{n}} &amp; \\frac{\\hat\\alpha\\Vert \\mu\\Vert_2}{n}\\\\ \\hat{\\alpha} \\sigma_{\\mathrm{R}}\\|v\\|_{\\mathrm{R}} L &amp; \\sigma_{\\mathrm{R}}\\left(1+\\hat{\\alpha}\\|v\\|_{\\mathrm{R}} \\frac{L}{\\sqrt{n}}\\right) &amp; \\hat{\\alpha} \\sigma_{\\mathrm{R}} \\delta_{\\mathrm{R}, \\mathrm{C}}\\\\ \\hat{\\alpha} c_{0} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2}\\|v\\|_{2} L^{2} &amp; c_{0} \\delta_{\\mathrm{C}, 2} L\\left(\\|R-\\mathbf{I}\\|_{2}+\\hat{\\alpha}\\|R\\|_{2}\\|v\\|_{2} \\frac{L}{\\sqrt{n}}\\right) &amp; \\sigma_{\\mathrm{C}}+\\hat{\\alpha} c_{0} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2} L \\end{array} \\right) \\tag{3.13} \\end{equation}\\] 3.2.3 Spectral radius of A Lemma 3.2 lead us to give conditions on \\(A\\) so that \\(\\rho(A_{pp})&lt;1\\). Hence we need to make \\(a_{ii}&lt;1,i=1,2,3\\) and \\(\\det(I-A_{pp})&gt;0\\). From 3.8, \\(\\sigma_R&lt;1\\), so it is sufficient to have \\(a_{22}\\leq\\frac{1+\\sigma_R}{2}\\) so that \\(a_{22}&lt;1\\). Similar for \\(a_{33}&lt;1\\), we let \\(a_{33}\\leq\\frac{1+\\sigma_C}{2}\\). This may explain why the authors let \\(1-a_{22}\\geq \\frac{1-\\sigma_R}{2}\\) and \\(1-a_{33}\\geq\\frac{1-\\sigma_C}{2}\\). For \\(a_{11}&lt;1\\), i.e. \\(\\alpha&#39;\\mu&gt;0\\), we have \\[\\begin{equation} \\alpha&#39; = \\frac{1}{n}u^T\\boldsymbol{\\alpha}v =\\frac{1}{n}\\sum_{i=1}^n\\alpha_iu_iv_i&gt;0 \\tag{3.14} \\end{equation}\\] Which can be seen from lemma 3.1 that \\(u,v\\in\\mathbb{R}^{n}\\) are nonnegative vectors and \\(\\alpha_i\\geq0\\). Remark. Lemma 3.2 also requires nonnegative matrix, so we also need \\(a_{11}=1-\\alpha&#39;\\mu\\geq 0\\), which is satisfied according to lemma 3.4 by requring \\(\\alpha&#39;\\leq \\frac{2}{\\mu+L}\\). Next we deive the sufficient conditions on \\(\\hat\\alpha:=\\underset{i}{\\max}\\alpha_i\\) so that \\(\\det{(I-A_{pp})}&gt;0\\). Additionally, since \\(\\alpha&#39;=\\frac{1}{n}\\sum\\limits_{i=1}^nu_iv_i\\alpha_i=\\frac{1}{n}\\sum\\limits_{i\\in\\mathcal{R}_R\\cap\\mathcal{R}_C}u_iv_i\\alpha_i\\) and \\(\\hat\\alpha=\\underset{i}{\\max}\\alpha_i\\), then \\(\\exists M,s.t.\\alpha&#39;=M\\hat\\alpha\\). \\(M\\) is determined once we know the graphs \\(\\mathcal{G}_R\\) and \\(\\mathcal{G}_C\\) and choose the step sizes for each agent. Then \\(\\det(I-A)\\) becomes a function of \\(\\hat\\alpha\\), thus we can derive the requirement for the step sizes \\(\\alpha_i\\) by letting \\(\\det(I-A)=f(\\hat\\alpha)&gt;0\\). \\[\\begin{align} \\det(I-A) &amp;= \\left(1-a_{11}\\right)\\left(1-a_{22}\\right)\\left(1-a_{33}\\right)-a_{12} a_{23} a_{31}\\\\ &amp;-a_{13} a_{21} a_{32}-a_{12} a_{23} a_{31}-a_{13} a_{21} a_{32}\\\\ &amp;-\\left(1-a_{22}\\right) a_{13} a_{31}-\\left(1-a_{11}\\right) a_{23} a_{32}\\\\ &amp;-\\left(1-a_{33}\\right) a_{12} a_{21}\\\\ &amp;\\geq \\alpha&#39;\\mu \\frac{(1-\\sigma_R)(1-\\sigma_C)}{4}\\\\ &amp;-a_{12} a_{23} a_{31}-a_{13} a_{21} a_{32}-a_{12} a_{23} a_{31}\\\\ &amp;-a_{13} a_{21} a_{32} -a_{13} a_{31}-a_{23} a_{32}- a_{12} a_{21}\\\\ &amp;:=\\hat\\alpha(c_3-c_2\\hat\\alpha-c_1\\hat\\alpha^2)&gt;0 \\tag{3.15} \\end{align}\\] Where the inequality holds for \\(1&gt;(1-a_{22})\\geq\\frac{1-\\sigma_R}{2}\\),and \\(1&gt;(1-a_{33})\\geq\\frac{1-\\sigma_C}{2}\\), which gives, \\[\\begin{equation} \\hat{\\alpha} \\leq \\min \\left\\{\\frac{\\left(1-\\sigma_{\\mathrm{R}}\\right) \\sqrt{n}}{2 \\sigma_{\\mathrm{R}}\\|v\\|_{\\mathrm{R}} L}, \\frac{\\left(1-\\sigma_{\\mathrm{C}}\\right)}{2 c_{0} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2} L}\\right\\} \\end{equation}\\] Since \\(\\hat\\alpha&gt;0\\), let (3.15) be positive is equivalent to have \\(c_3-c_2\\hat\\alpha-c_1\\hat\\alpha^2&gt;0\\). Hence, \\[\\begin{equation} \\hat\\alpha&lt; \\frac{\\sqrt{c_2^2+4c_1c_2}-c_2}{2c_1} =\\frac{2 c_{3}}{c_{2}+\\sqrt{c_{2}^{2}+4 c_{1} c_{3}}} \\end{equation}\\] So when \\[\\begin{equation} \\hat\\alpha\\leq \\min \\left\\{\\frac{2 c_{3}}{c_{2}+\\sqrt{c_{2}^{2}+4 c_{1} c_{3}}}, \\frac{\\left(1-\\sigma_{\\mathrm{C}}\\right)}{2 \\sigma_{\\mathrm{C}} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2} L},\\frac{2 c_{3}}{c_{2}+\\sqrt{c_{2}^{2}+4 c_{1} c_{3}}}\\right\\} \\end{equation}\\] \\(\\rho(A_{pp})&lt;1\\). Todo: \\(\\min \\left\\{\\frac{\\left(1-\\sigma_{\\mathrm{R}}\\right) \\sqrt{n}}{2 \\sigma_{\\mathrm{R}}\\|v\\|_{\\mathrm{R}} L}, \\frac{\\left(1-\\sigma_{\\mathrm{C}}\\right)}{2 c_{0} \\delta_{\\mathrm{C}, 2}\\|R\\|_{2} L}\\right\\}\\stackrel{?}=\\frac{\\left(1-\\sigma_{\\mathrm{C}}\\right)}{2 \\sigma_{\\mathrm{C}} \\delta_{\\mathrm{C}, 2}\\|\\mathbf{R}\\|_{2} L}\\) Remark. - If we do not use the inequality in (3.15), we can still have \\(b_3-b_2\\hat\\alpha-b_1\\hat\\alpha^2&gt;0\\). However, it is not easy to determine the sign of \\(b_i,i=1,2,3\\) for this situation. Todo:When \\(\\hat\\alpha\\) is sufficiently small, show \\(\\rho(A_{pp})\\approx 1-\\alpha&#39;\\mu\\) from Nedić, Olshevsky, and Rabbat (2018)↩ "],
["sec-dsgt.html", "Chapter 4 Distributed Stochastic Gradient Tracking(DSGT) Method 4.1 Introduction 4.2 Analysis of Convergence", " Chapter 4 Distributed Stochastic Gradient Tracking(DSGT) Method 4.1 Introduction The idea is similar to that in the Push-Pull method. However, since \\(Y_k\\in\\mathbb{R}^{n\\times p}\\) is used to track the average stochastic gradients in the \\(k\\)th iteration, i.e. \\(\\bar y_k = \\frac{1}{n}\\mathbf{1}^T Y_k=\\frac{1}{n}\\sum\\limits_{i=1}^ng_i(x_{i,k},\\xi_{i,k})\\) provided \\(y_{i,0}=g(x_{i,0},\\xi_{i,0})\\), which is random. Hence we now bound \\(E\\left[\\left\\|\\bar{x}_{k+1}-x^{*}\\right\\|^{2}\\right]\\), \\(E\\left[\\left\\|X_{k+1}-\\mathbf1 \\bar{x}_{k+1}\\right\\|^{2}\\right]\\), and \\(E\\left[\\left\\|Y_{k+1}-\\mathbf{1} \\bar{y}_{k+1}\\right\\|^{2}\\right]\\), which can be seen as variances of \\(\\bar x_k, X_k\\), and \\(Y_k\\). Thus we need to assume \\(g_i(x,\\xi_i),i\\in\\mathcal{N}\\) have the finite variances and also assume they are good estimates of \\(\\nabla f_i(x), i\\in\\mathcal{N}\\),i.e. assumption 4.1. Assumption4.1 \\(\\forall i\\in\\mathcal{N},x\\in\\mathbb{R}^p\\), eahc random vector \\(\\xi_i\\in\\mathbb{R}^m\\) is independent, and \\[\\begin{align} E[g_i(x,\\xi_i)|x]&amp;=\\nabla f_i(x)\\\\ E[\\Vert g_i(x,\\xi_i)-\\nabla f_i(x)\\Vert^2 |x]&amp;\\leq \\sigma^2, \\exists \\sigma \\tag{4.1} \\end{align}\\] Additionnally, we assume the graph in DSGT is undirected and connected, i.e. assumption 4.2. Assumption4.2 The graph \\(\\mathcal{G}\\) corresponding to the network of agents is undirected and connected. The distributed stochastic gradient tracking method is as follows, Algorithm4.1 (DSGT) Each agent \\(i\\) choose the same step size \\(\\alpha\\) and initilized with an arbitary \\(x_{i,0}\\in\\mathbb{R}^p, y_{i,0}=g_i(x_{i,0},\\xi_{i,0})\\). For k = 0, 1, …, For \\(i\\in\\mathcal{N}\\), \\(x_{i, k+1} = \\sum\\limits_{j=1}^nw_{ij}(x_{j, k}-\\alpha_j y_{j, k})\\) \\(y_{i, k+1} = \\sum\\limits_{j=1}^nw_{ij}y_{j,k}+g_i(x_{i,k+1},\\xi_{i,k+1})-g_i(x_{i,k},\\xi_{i,k})\\) Where \\(W=(w_{ij})\\in\\mathbb{R}^{n\\times n}\\) denotes the coupling matrix of agents,satisfying assumption 4.3.The above algorithm can be written as the matrix form, \\[\\begin{align} X_{k+1}&amp;=\\mathbf{W}\\left(X_{k}-\\alpha Y_{k}\\right)\\\\ Y_{k+1}&amp;=\\mathbf{W} Y_{k}+G\\left(X_{k+1}, \\xi_{k+1}\\right)-G\\left(X_{k}, \\xi_{k}\\right) \\tag{4.2} \\end{align}\\] Where \\(G(X_k,\\boldsymbol\\xi_k)=(g_1(x_{1,k},\\xi_{1,k}),...,g_n(x_{n,k},\\xi_{n,k}))^T\\in\\mathbb{R}^{n\\times p}\\). Assumption4.3 \\(W=(w_{ij})\\in\\mathbb{R}^{n\\times n}\\) is nonnegative and doubly stochastic,i.e. \\(W\\mathbf{1}=\\mathbf{1}\\) and \\(\\mathbf{1}^TW=\\mathbf{1}^T\\). In addition, \\(w_{ii}&gt;0\\) for some \\(i\\in\\mathcal{N}\\). Insead of the definition 3.1 used in the Push-Pull method, we denote \\(\\Vert\\cdot\\Vert\\) as the \\(2-\\)norm for vectors and as Frobenius norms for matrices. Hence they are consistent, the lemma 3.6 and 3.5 are satisfied accordingly. 4.2 Analysis of Convergence We would see that, for equal step size \\(\\alpha\\leq C,\\exists C\\), \\(\\sup _{l \\geq k} E\\left[\\left\\|\\bar{x}_{l}-x^{*}\\right\\|^{2}\\right], \\sup _{l \\geq k} E\\left[\\left\\|X_{l}-1 \\bar{x}_{l}\\right\\|^{2}\\right] \\text { and } \\sup _{l \\geq k} E\\left[\\left\\|Y_{l}-\\mathbf{1} \\bar{y}_{l}\\right\\|^{2}\\right]\\) converge at the linear rate \\(\\mathcal{O}(\\rho(A)^k)\\) to a neighborhood of \\(0\\). Denote \\(\\mathcal{F}_k\\) as the \\(\\sigma-\\)algebra generated by \\(\\{\\xi_0,...,\\xi_{k-1}\\}\\). We first reveal some properties of the introduced auxiliary variable \\(\\bar y_k=\\frac{1}{n}\\sum\\limits_{i=1}^ng_i(x_{i,k},\\xi_{i,k})\\) provided \\(y_{i,0}=g(x_{i,0},\\xi_{i,0})\\). Lemma 4.1 Under Assumption 4.1, \\(h(X)=\\frac{1}{n}\\mathbf{1}^T\\nabla F(X), X\\in\\mathbb{R}^{n\\times p},\\forall k\\geq0\\), we have \\[\\begin{align} E\\left[ \\bar y_k - h(X_k)|\\mathcal{F}_k\\right]&amp;=0\\\\ E\\left[\\left\\|\\bar{y}_{k}-h(X_k)\\right\\|^{2} | \\mathcal{F}_{k}\\right] &amp;\\leq \\frac{\\sigma^{2}}{n} \\end{align}\\] Lemma 4.1 is to say that \\(\\bar y_k\\) tracks the average gradient with finite variace and is unbiased. 4.2.1 Relationship between two iteration steps From (3.7), we make \\(\\alpha&#39;=\\frac{1}{n}\\mathbf{1}^T\\boldsymbol\\alpha\\mathbf{1}=\\alpha,\\boldsymbol\\alpha=\\text{diag}(\\alpha,\\alpha,...,\\alpha)\\) and \\(g_k=\\nabla f(\\bar x_k)=\\frac{1}{n}\\sum\\limits_{i=1}^n\\nabla f_i(\\bar x_k)=\\frac{1}{n}\\mathbf{1}^T\\nabla F(\\mathbf{1}\\bar x_k)\\), we have, \\[\\begin{equation} \\bar x_{k+1}-x^* = \\bar x_k - \\alpha(h(X_k)-\\nabla f(\\bar x_k))-\\alpha \\nabla f(\\bar x_k)-\\alpha (\\bar y_k-h(X_k))-x^* \\tag{4.3} \\end{equation}\\] Take norm at both sides, we have \\[\\begin{align} \\Vert \\bar x_{k+1}-x^*\\Vert^2&amp;=\\Vert (\\bar x_k-\\alpha \\nabla f(\\bar x_k)-x^*)-\\alpha(h(X_k)-\\nabla f(\\bar x_k))-\\alpha(\\bar y_k-h(X_k))\\Vert^2\\\\ &amp;=\\Vert \\bar x_k-\\alpha \\nabla f(\\bar x_k)-x^*\\Vert^2 + \\alpha^2\\Vert h(X_k)-\\nabla f(\\bar x_k)\\Vert ^2 + \\alpha^2\\Vert \\bar y_k-h(X_k)\\Vert^2\\\\ &amp;+ 2\\alpha\\left\\langle\\bar x_k-\\alpha \\nabla f(\\bar x_k)-x^*, \\nabla f(\\bar x_k)-h(X_k)\\right\\rangle\\\\&amp;-2\\alpha\\left\\langle\\bar x_k-\\alpha \\nabla f(\\bar x_k)-x^*, \\bar y_k-h(X_k)\\right\\rangle\\\\ &amp;+ 2\\alpha^2\\left\\langle h(X_k)-\\nabla f(\\bar x_k), \\bar y_k-h(X_k)\\right\\rangle \\tag{4.4} \\end{align}\\] Where \\(\\left\\langle\\cdot\\right\\rangle\\) denotes the Frobinus inner product. At both sides, take conditional expectation given \\(\\mathcal{F}_k\\), use lemma 3.4 and lemma 4.1, we have \\[\\begin{align} E\\left[\\Vert \\bar x_{k+1}-x^*\\Vert^2|\\mathcal{F}_k\\right]&amp;\\leq (1-\\alpha\\mu)^2\\Vert \\bar x_k - x^*\\Vert^2 + \\alpha^2\\frac{L^2}{n}\\Vert X_k-\\mathbf{1}\\bar x_k\\Vert^2+\\alpha^2\\frac{\\sigma^2}{n}\\\\&amp;+ 2\\alpha (1-\\alpha\\mu)\\Vert \\bar x_k-x^*\\Vert\\cdot\\frac{L}{\\sqrt{n}}\\Vert X_k-\\mathbf{1}\\bar x_k\\Vert\\\\ &amp;\\leq (1-\\alpha\\mu)^2\\Vert \\bar x_k - x^*\\Vert^2 + \\alpha^2\\frac{L^2}{n}\\Vert X_k-\\mathbf{1}\\bar x_k\\Vert^2+\\alpha^2\\frac{\\sigma^2}{n}\\\\ &amp;+ \\alpha\\left((1-\\alpha\\mu)^{2} \\mu\\left\\|\\bar{x}_{k}-x^{*}\\right\\|^{2}+\\frac{L^{2}}{\\mu n}\\left\\|X_{k}-1 \\bar{x}_{k}\\right\\|^{2}\\right)\\\\ &amp;=(1-\\alpha\\mu)(1-(\\alpha\\mu)^2)\\Vert \\bar x_k-x^*\\Vert^2+\\frac{\\alpha L^2}{\\mu n}(1+\\alpha\\mu)\\Vert X_k-\\mathbf{1}\\bar x_k\\Vert^2 + \\\\ &amp;\\frac{\\alpha^2\\sigma^2}{n}\\\\ &amp;\\leq (1-\\alpha\\mu)\\Vert \\bar x_k-x^*\\Vert^2+\\frac{\\alpha L^2}{\\mu n}(1+\\alpha\\mu)\\Vert X_k-\\mathbf{1}\\bar x_k\\Vert^2 +\\\\ &amp;\\frac{\\alpha^2\\sigma^2}{n} \\tag{4.5} \\end{align}\\] Remark. \\ When each agent \\(i\\) takes different step size \\(\\alpha_i,i\\in\\mathcal{N}\\), \\(\\alpha(\\bar y_k-h(\\bar x_k))\\) in (4.3) becomes \\(\\frac{1}{n}\\mathbf{1}^T\\boldsymbol\\alpha(Y_k-\\mathbf{1}h(\\bar x_k))\\), then we may use the following to continuou the steps in (4.5). \\[\\begin{align} \\frac{1}{n}\\mathbf{1}^T\\boldsymbol\\alpha(Y_k-\\mathbf{1}h(\\bar x_k))&amp;=\\frac{1}{n}\\mathbf{1}^T\\boldsymbol\\alpha\\left[(Y_k-\\mathbf{1}\\bar y_k)+\\mathbf{1}(\\bar y_k-h(\\bar x_k))\\right] \\end{align}\\] \\(0&lt;(1-(\\alpha\\mu)^2)&lt;1\\) will be guranteed by lemma 3.2. This also hints us how to separate \\(\\frac{2 \\alpha (1-\\alpha\\mu) L}{\\sqrt{n}}\\left\\|\\bar{x}_{k}-x^{*}\\right\\|\\left\\|X_{k}-1 \\bar{x}_{k}\\right\\|\\) In the Push-Pull method, we see matrices \\(R-\\frac{\\mathbf{1}u^T}{n}\\) and \\(C-\\frac{v\\mathbf{1}^T}{n}\\). Here for \\(W\\in\\mathbb{R}^{n\\times n}\\), \\(W-\\frac{\\mathbf{1}\\mathbf{1}^T}{n}\\) also has significant uses. \\(\\mathbf{1}\\) can be seen as left and right eigenvalue of \\(W\\), and from \\(W\\mathbf{1}=\\mathbf{1}\\) we have lemma 4.2, Lemma 4.2 Given the graph \\(\\mathcal{G}\\) corresponding to the network of agents is undirected and connected, and \\(W\\) is doubly stochastic and \\(w_{ii}&gt;0,\\exists i\\in\\mathcal{N}\\), we have the spectral norm \\(\\rho_w\\) of \\(W-\\frac{\\mathbf{1}\\mathbf{1}^T}{n}\\), \\(\\rho_W&lt;1\\), and \\[ \\|W \\omega-\\mathbf{1} \\bar{\\omega}\\| \\leq \\rho_{w}\\|\\omega-1 \\bar{\\omega}\\|, \\forall \\omega\\in\\mathbb{R}^{n\\times p}, \\bar\\omega = \\frac{1}{n}\\mathbf{1}\\omega \\] Remark. For lemma 4.2, a counter example for not assuming connected graph is that a graph \\(\\mathcal{G}\\) induced by the identity matrix \\(I\\), then the spectral norm of \\(I-\\frac{\\mathbf{1}\\mathbf{1}^T}{n}\\) is \\(\\rho_w = 1\\). Then, \\[\\begin{align} \\Vert X_{k+1}-\\mathbf{1}\\bar x_{k+1}\\Vert^2&amp;\\stackrel{\\text{iterate}}{=} \\Vert WX_k-\\alpha WY_k-\\mathbf{1}(\\bar x_k-\\alpha\\bar y_k)\\Vert^2\\\\ &amp;=\\left\\|W X_{k}-1 \\bar{x}_{k}\\right\\|^{2}-2 \\alpha\\left\\langle W X_{k}-1 \\bar{x}_{k}, W Y_{k}-1 \\bar{y}_{k}\\right\\rangle+\\alpha^{2}\\left\\|W Y_{k}-1 \\bar{y}_{k}\\right\\|^{2}\\\\ &amp;\\leq \\rho_{w}^{2}\\left\\|\\mathrm{x}_{k}-1 \\bar{x}_{k}\\right\\|^{2}+\\alpha \\rho_{w}^{2}\\left[\\frac{\\left(1-\\rho_{w}^{2}\\right)}{2 \\alpha \\rho_{w}^{2}}\\left\\|\\mathrm{x}_{k}-1 \\bar{x}_{k}\\right\\|^{2}+\\frac{2 \\alpha \\rho_{w}^{2}}{\\left(1-\\rho_{w}^{2}\\right)}\\left\\|\\mathrm{y}_{k}-1 \\bar{y}_{k}\\right\\|^{2}\\right]+\\\\ &amp;\\alpha^{2} \\rho_{w}^{2}\\left\\|\\mathrm{y}_{k}-1 \\bar{y}_{k}\\right\\|^{2}\\\\ &amp;= \\frac{\\left(1+\\rho_{w}^{2}\\right)}{2}\\left\\|X_{k}-1 \\bar{x}_{k}\\right\\|^{2}+\\\\ &amp;\\alpha^{2} \\frac{\\left(1+\\rho_{w}^{2}\\right) \\rho_{w}^{2}}{\\left(1-\\rho_{w}^{2}\\right)}\\left\\|Y_{k}-1 \\bar{y}_{k}\\right\\|^{2} \\tag{4.6} \\end{align}\\] For \\(E\\left[\\Vert Y_{k+1}-\\mathbf{1}\\bar y_{k+1}\\Vert^2|\\mathcal{F}_k\\right]\\). We write \\(G(X_k,\\xi_k):=G_k,\\nabla_k:=\\nabla F(X_k)\\) for simplicity, then we have, \\[\\begin{align} \\Vert Y_{k+1}-\\mathbf{1}\\bar y_{k+1}\\Vert^2&amp;= \\Vert WY_k + G_{k+1} - G_k -\\mathbf{1}\\bar y_k + \\mathbf{1}(\\bar y_k-\\bar y_{k+1})\\Vert^2\\\\ &amp;= \\Vert WY_k - \\mathbf{1}\\bar y_k\\Vert^2 + \\Vert G_{k+1} - G_k\\Vert^2 + \\Vert \\mathbf{1}(\\bar y_k-\\bar y_{k+1})\\Vert^2 + \\\\ &amp;2\\langle WY_k - \\mathbf{1}\\bar y_k, G_{k+1}-G_k\\rangle +\\\\ &amp;2\\langle WY_k-\\mathbf{1}\\bar y_k + G_{k+1}-G_k, \\mathbf{1}(\\bar y_k-\\bar y_{k+1})\\rangle \\\\ &amp;=\\Vert WY_k - \\mathbf{1}\\bar y_k\\Vert^2 + \\Vert G_{k+1} - G_k\\Vert^2 + \\Vert \\mathbf{1}(\\bar y_k-\\bar y_{k+1})\\Vert^2 + \\\\ &amp;2\\langle WY_k - \\mathbf{1}\\bar y_k, G_{k+1}-G_k\\rangle +\\\\ &amp;2\\langle Y_{k+1}-\\mathbf{1}\\bar y_{k+1}-\\mathbf{1}(\\bar y_k-\\bar y_{k+1}) , \\mathbf{1}(\\bar y_k-\\bar y_{k+1})\\rangle\\\\ &amp;\\stackrel{?}{=} \\Vert WY_k - \\mathbf{1}\\bar y_k\\Vert^2 + \\Vert G_{k+1} - G_k\\Vert^2 - n\\Vert \\bar y_k-\\bar y_{k+1}\\Vert^2 +\\\\ 2\\langle WY_k - \\mathbf{1}\\bar y_k, G_{k+1}-G_k\\rangle \\\\ &amp;\\leq \\rho^2_w\\Vert Y_k-\\mathbf{1}\\bar y_k\\Vert^2+\\Vert G_{k+1} - G_k\\Vert^2 + 2\\langle WY_k - \\mathbf{1}\\bar y_k, G_{k+1}-G_k\\rangle \\tag{4.7} \\end{align}\\] Todo: \\(\\Vert Y_{k+1}-\\mathbf{1}\\bar y_{k+1}\\Vert^2\\)? 4.2.2 Inequalities Lemma 4.3 \\[\\begin{equation} A_{dsgt}=\\left[\\begin{array}{ccc} {1-\\alpha \\mu} &amp; {\\frac{\\alpha L^{2}}{\\mu n}(1+\\alpha \\mu)} &amp; {0} \\\\ {0} &amp; {\\frac{1}{2}\\left(1+\\rho_{w}^{2}\\right)} &amp; {\\alpha^{2} \\frac{\\left(1+\\rho_{w}^{2}\\right) \\rho_{w}^{2}}{\\left(1-\\rho_{w}^{2}\\right)}} \\\\ 2 \\alpha n L^{3} &amp; \\left(\\frac{1}{\\beta}+2\\right) {\\|W-I\\|^{2} L^{2}+3 \\alpha L^{3}} &amp; {\\left(1+4 \\alpha L+2 \\alpha^{2} L^{2}+\\beta\\right) \\rho_{w}^{2}} \\end{array}\\right] \\end{equation}\\] where \\(\\beta=\\frac{1-\\rho_{w}^{2}}{2 \\rho_{w}^{2}}-4 \\alpha L-2 \\alpha^{2} L^{2}\\) After getting the element of the matrix \\(A\\) of \\(A_{dsgt}\\), we again use lemma 3.2 to build conditions on step size \\(\\alpha\\) so that the spectral radius of \\(A_{dsgt}\\), \\(\\rho(A_{dsgt})&lt;1\\). 4.2.3 Spectral radius of \\(A_{dsgt}\\) Next, we derive the conditions on \\(\\alpha\\) so that \\(\\rho(A_{dsgt})&lt;1\\) by computing \\(det(I-A_{dsgt})\\) and make it greater than 0. We expand \\(det(I-A_{dsgt})\\) according to the first column, \\[\\begin{align} det(I-A_{dsgt}) &amp;= (1-a_{11})[(1-a_{22})(1-a_{33})-a_{32}a_{23}]-a_{12}a_{23}a_{31} \\tag{4.8} \\end{align}\\] Remark. The choice of \\(\\beta\\) makes \\(1-a_{22}=1-a_{33}=(1-\\rho_w^2)/2\\). In Push-Pull method, we use \\(1-a_{22}\\geq (1-\\sigma_R)/2\\) and \\(1-a_{33}\\geq (1-\\sigma_C)/2\\) to derive a sufficient condition so that \\(\\det(I-A_{pp})&gt;0\\). Notice that in lemma 3.2, it requires \\(\\lambda-a_{ii}&gt;0, i=1,2,3\\) and in (4.8), we already have \\((1-a_{11})(1-a_{22})(1-a_{33})-C\\). Hence we may expect \\(C\\) to be bounded by the term of \\(c_0(1-a_{11})(1-a_{22})(1-a_{33})\\), where \\(c_0&lt;1\\) is a positive number. So when we make \\[\\begin{align} a_{23}a_{32}&amp;\\leq \\frac{1}{\\Gamma}(1-a_{22})(1-a_{33})=\\frac{1}{\\Gamma}(\\frac{1-\\rho_w^2}{2})^2,\\\\ \\tag{4.9} \\end{align}\\] \\[\\begin{align} a_{12}a_{23}a_{31}&amp;\\leq \\frac{1}{\\Gamma+1}(1-a_{11})[(1-a_{22})(1-a_{33})-a_{32}a_{23}] \\tag{4.10} \\end{align}\\] for some \\(\\Gamma &gt;1\\), we have \\[\\begin{equation} det(I-A_{dsgt}) \\geq \\frac{\\Gamma-1}{\\Gamma+1}(1-a_{11})(1-a_{22})(1-a_{33})&gt;0 \\end{equation}\\] Next, we derive what exactly conditions \\(\\alpha\\) should satisfy to make the inequalities (4.9) and (4.10) hold. Additionally, in the proof of building inequalities of \\(E\\left[\\Vert Y_{k+1}-\\mathbf{1}\\bar y_{k+1}\\Vert^2|\\mathcal{F}_k\\right]\\), the author uses \\[\\begin{align} 2\\|\\mathbf{W}-\\mathbf{I}\\| L \\rho_{w}\\left\\|Y_{k}-\\mathbf{1} \\bar{y}_{k}\\right\\|\\left\\|X_{k}-1 \\bar{x}_{k}\\right\\|\\leq \\beta \\rho_{w}^{2} \\left\\|Y_{k}-1 \\bar{y}_{k}\\right\\|^{2} | \\mathcal{F}_{k}+\\frac{1}{\\beta}\\|\\mathbf{W}-\\mathbf{I}\\|^{2} L^{2}\\left\\|X_{k}-1 \\bar{x}_{k}\\right\\|^{2} \\end{align}\\] Thus we also need \\(\\beta&gt;0\\). Since\\(\\beta\\) is quadratic about \\(\\alpha&gt;0\\), so a naive idea to ensure \\(\\beta&gt;0\\) is \\[\\begin{equation} 0&lt;\\alpha &lt; \\frac{\\sqrt{1+3\\rho_w^2}}{2\\rho_wL}-\\frac{1}{L} \\tag{4.11} \\end{equation}\\] However, the author uses \\(\\alpha\\leq \\frac{1-\\rho_w^2}{12\\rho_w^2L}\\) to gurantee \\(\\beta&gt;0\\) since \\(0&lt;\\rho_w&lt;1\\). \\[\\begin{align} \\beta \\geq \\frac{1-\\rho_{w}^{2}}{2 \\rho_{w}^{2}}-\\frac{1-\\rho_{w}^{2}}{3 \\rho_{w}}-\\frac{\\left(1-\\rho_{w}^{2}\\right)^{2}}{72 \\rho_{w}^{2}} \\geq \\frac{11\\left(1-\\rho_{w}^{2}\\right)}{72 \\rho_{w}^{2}} \\geq \\frac{1-\\rho_{w}^{2}}{8 \\rho_{w}^{2}}&gt;0 \\tag{4.12} \\end{align}\\] Based on this idea, we may derive a more accurate coefficient \\(C&gt;0\\) of \\(\\frac{1-\\rho_w^2}{C\\rho_w^2L}\\) can be chosen from \\((\\frac{2}{\\sqrt{5}-2}\\approx8.47,+\\infty)\\). Figure 4.1 plots the function \\(\\frac{\\sqrt{1+3\\rho_w^2}}{2\\rho_w}-1-\\frac{1-\\rho_w^2}{12\\rho_w^2}\\), which compares the above two idea to ensure \\(\\beta&gt;0\\). We see from figure 4.1 that the constraint in (4.12) is better than \\(\\alpha\\leq \\frac{1-\\rho_w^2}{12\\rho_w^2L}\\), especilly when \\(\\rho_w\\) is close to \\(0\\). Figure 4.1: The difference between two constraints We follow the author’s choice here, then the LHS of (4.9) is less than the following, \\[\\begin{equation} \\frac{\\left(1+\\rho_{w}^{2}\\right) \\rho_{w}^{2}}{\\left(1-\\rho_{w}^{2}\\right)}\\alpha^{2}\\left[\\frac{\\left(2+6 \\rho_{w}^{2}\\right)}{\\left(1-\\rho_{w}^{2}\\right)}\\|\\mathbf{W}-\\mathbf{I}\\|^{2} L^{2}+\\frac{\\left(1-\\rho_{w}^{2}\\right)}{4 \\rho_{w}^{2}} L^{2}\\right]\\leq RHS=\\frac{\\left(1-\\rho_{w}^{2}\\right)^{2}}{4 \\Gamma} \\tag{4.13} \\end{equation}\\] Hence, it suffice to make \\(\\alpha\\), \\[\\begin{equation} \\alpha\\leq \\frac{\\left(1-\\rho_{w}^{2}\\right)^{2}}{2 \\sqrt{\\Gamma} L \\max \\left(6 \\rho_{w}\\|\\mathbf{W}-\\mathbf{I}\\|, 1-\\rho_{w}^{2}\\right)}\\leq \\frac{\\left(1-\\rho_{w}^{2}\\right)^{2}}{L \\sqrt{\\Gamma\\left(1+\\rho_{w}^{2}\\right)} \\sqrt{4 \\rho_{w}^{2}\\left(2+6 \\rho_{w}^{2}\\right)\\|\\mathbf{W}-\\mathbf{I}\\|^{2}+\\left(1-\\rho_{w}^{2}\\right)^{2}}} \\end{equation}\\] The latter inequality comes from \\(\\rho_w^2&lt;1&lt;\\frac{7}{6}\\) and \\(a+b\\leq 2\\max(a,b)\\). For the inequality (4.10), from the inequality (4.9), it is sufficient to have \\[\\begin{equation} a_{12} a_{23} a_{31}\\leq \\frac{(\\Gamma-1)}{\\Gamma(\\Gamma+1)}\\left(1-a_{11}\\right)\\left(1-a_{22}\\right)\\left(1-a_{33}\\right) \\end{equation}\\] Thus, \\[\\begin{equation} \\alpha \\leq \\frac{\\left(1-\\rho_{w}^{2}\\right)}{3 \\rho_{w}^{2 / 3} L}\\left[\\frac{\\mu^{2}}{L^{2}} \\frac{(\\Gamma-1)}{\\Gamma(\\Gamma+1)}\\right]^{1 / 3} \\end{equation}\\] Then, when the step size \\(\\alpha\\) is chosen such that \\[\\begin{equation} \\alpha \\leq \\min \\left\\{\\frac{\\left(1-\\rho_{w}^{2}\\right)}{12 \\rho_{w} L}, \\frac{\\left(1-\\rho_{w}^{2}\\right)^{2}}{2 \\sqrt{\\Gamma} L \\max \\left\\{6 \\rho_{w}\\|\\mathbf{W}-\\mathbf{I}\\|, 1-\\rho_{w}^{2}\\right\\}}, \\frac{\\left(1-\\rho_{w}^{2}\\right)}{3 \\rho_{w}^{2 / 3} L}\\left[\\frac{\\mu^{2}}{L^{2}} \\frac{(\\Gamma-1)}{\\Gamma(\\Gamma+1)}\\right]^{1 / 3}\\right\\} \\tag{4.14} \\end{equation}\\] we have \\(\\rho(A_{dsgt})&lt;1\\). "],
["summary-of-push-pull-and-dsgt.html", "Chapter 5 Summary of PuSh-Pull and DSGT 5.1 Questions", " Chapter 5 Summary of PuSh-Pull and DSGT In the Push-Pull method, if we set graph \\(\\mathcal{G}\\) is connected and undirected, then \\(\\mathcal{G}=\\mathcal{G}_R=\\mathcal{G}_C\\),i.e.,\\(R=C:=W\\). The algorithm 3.1 becomes the form of \\[\\begin{align} X_{k+1} &amp;= W(X_{k}-\\boldsymbol\\alpha Y_k),\\\\ Y_{k+1} &amp;= WY_k+\\nabla F(X_{k+1})-\\nabla F(X_k) \\tag{3.1} \\end{align}\\] If we further assume we only have noisy estimates of \\(\\nabla F(X)\\), i.e. \\(G(X,\\boldsymbol\\xi)\\), we get DSGT 4.1. In the proof of \\(\\rho(A_{pp})&lt;1\\), the spectral radius of \\(A\\) of the linear system of inequalities in the Push-Pull method, the authors use \\(1&gt;(1-a_{22})\\geq\\frac{1-\\sigma_R}{2}\\),and \\(1&gt;(1-a_{33})\\geq\\frac{1-\\sigma_C}{2}\\) to build a sufficient condition for \\(\\hat\\alpha\\), which avoid discussing the sign of \\(c_i,i=1,2,3\\) in \\(c_{3}-c_{2} \\hat{\\alpha}-c_{1} \\hat{\\alpha}^{2}\\). 5.1 Questions In two methods, the matrices \\(R-\\frac{\\mathbf{1}u^T}{n}, C-\\frac{v\\mathbf{1^T}}{n}\\), and \\(W-\\frac{\\mathbf{1}\\mathbf{1}^T}{n}\\) and their (approximated) spectral radii seem important. How to interpretate them? Is it because the following relationships? \\[ \\lim _{k \\rightarrow \\infty} \\mathbf{R}^{k}=\\frac{1 u^{\\top}}{n}, \\lim _{k \\rightarrow \\infty} C^{k}=\\frac{v 1^{\\top}}{n} \\] In (4.7), \\(\\left\\langle Y_{k+1}-\\mathbf{1}\\bar y_{k+1},\\mathbf{1}(\\bar y_k-\\bar y_{k+1})\\right\\rangle\\stackrel{?}{=}0\\) In the following inequality, \\(2n\\sigma^2\\) seems come from 4.1, the others? \\[\\begin{align} 2 \\mathbb{E}\\left[\\left\\langle\\nabla_{k+1}-\\nabla_{k}, G_{k+1}-\\nabla_{k+1}-G_{k}+\\nabla_{k}\\right\\rangle | \\mathcal{F}_{k}\\right]&amp;+\\\\ &amp;\\mathbb{E}\\left[\\left\\|G_{k+1}-\\nabla_{k+1}-G_{k}+\\nabla_{k}\\right\\|^{2} | \\mathcal{F}_{k}\\right]\\\\ &amp;\\leq 2 \\mathbb{E}\\left[\\left\\langle\\nabla_{k+1},-G_{k}+\\nabla_{k}\\right\\rangle | \\mathcal{F}_{k}\\right]+2 n \\sigma^{2} \\end{align}\\] Todo: \\(E\\left[\\Vert Y_{k+1}-\\mathbf{1}\\bar y_{k+1}\\Vert^2|\\mathcal{F}_k\\right]\\leq?\\) Todo: \\(\\rho(A_{pp})\\approx1-\\alpha&#39;\\mu\\),when \\(\\hat\\alpha\\) is sufficiently small "],
["gossip-like-push-pull-and-dsgt.html", "Chapter 6 Gossip-like Push-Pull and DSGT 6.1 G-Push-Pull", " Chapter 6 Gossip-like Push-Pull and DSGT Todo:gossip algorithms Instead of iterating all the agents, at each time slot \\(k=0,1,...\\), a batch of agents may wake up randomly, and communicate with a subset of their nearby agents. 6.1 G-Push-Pull "],
["sec-asynt.html", "Chapter 7 Asymptotic network independence 7.1 SGD and DSGD 7.2 Bounds 7.3 Possible ways to achieve asymptotic network independece", " Chapter 7 Asymptotic network independence An undesirable property of distributed optimization method is that the increasing number of nodes may result in a large increase in the time to reach the same \\(\\varepsilon\\) accuracy(error \\(&lt;\\varepsilon\\)) under the centralized version. Pu, Olshevsky, and Paschalidis (2019b) discuss this phenomenon under the following scenario \\[\\begin{equation} \\text { Time }_{n, \\varepsilon} \\text { (decentralized) } \\leq p(\\mathcal{G}) \\text { Time }_{n, \\varepsilon} \\text { (centralized) } \\tag{7.1} \\end{equation}\\] where \\(\\text { Time }_{n, \\varepsilon} \\text { (decentralized) }\\) denotes the time for the decentralized algorithm on n nodes to reach \\(\\varepsilon\\) accuracy, and \\(\\text { Time }_{n, \\varepsilon} \\text { (centralized) }\\) is the time for the centralized algorithm which can query \\(n\\) gradients per time step to reach \\(\\varepsilon\\) accuracy.\\(\\mathcal{G}=(\\mathcal{N},\\mathcal{E})\\) denotes the graph. Typically, \\(p(\\mathcal{G})\\) is at least \\(\\mathcal{O}(n^2)\\)3, which is inpractical to use. This is because, \\(p(\\mathcal{G})=\\mathcal{O}(n^2)\\) implies the distributed version would be \\(n^2\\) times slower than the centralized one with the same computational power. \\(p(\\mathcal{G})=\\mathcal{O}(1)\\) is a desirable setting, which means a decentralized algorithm converge to the optimal at a comparable rate to a centralized algorithm with the same computational power4. Fortunately, it is possible for the iteration time \\(k\\) to be large enough for some distributed stochastic optimization, which is the asymptotic network independence property: it is as if the network is not even there. In chapter 9, we summarize some notes showing the asymptotic network independence property of algorithm 7.1 with \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\)(Pu, Olshevsky, and Paschalidis 2019a). 7.1 SGD and DSGD We consider a distributed stochastic gradient descent(DSGD) method, see algorithm under assumptions 1.1, 4.1,4.2,and 4.3 plus symmetric5, the similar settings as we discuss in chapter 4. By assumption 1.1, there exist a unique solution \\(x^*\\in\\mathbb{R}^p\\) to the problem (1.1). Algorithm7.1 (DSGD) Each agent \\(i\\) choose the same step size \\(\\alpha_k\\) at the \\(k\\)th iteration and initilized with an arbitary \\(x_i(0)\\in\\mathbb{R}^p\\) For k = 0, 1, …, For \\(i\\in\\mathcal{N}\\), \\(x_i(k+1) = \\sum\\limits_{j=1}^nw_{ij}(x_j(k+1)-\\alpha_k g_j(x_j(k),\\xi_j(k)))\\) \\(\\{\\alpha_k\\}\\) are a sequence of nonnegative non-increasing stepsizes. In the long run, \\(x_{i,k}=x_{j,k},\\forall i,j\\in\\mathcal{N}\\), i.e. DSGD belongs to the class of consensus-based distributed optimization methods, which can be achieved under assumptions 4.2 and 4.3 plus \\(W\\) is symmetric. Let \\(X(k)=(x_1(k),...,x_n(k))^T\\in\\mathbb{R^{n\\times p}}, G(k)=(g_1(x_1(k),\\xi_1(k)),...,g_n(x_n(k),\\xi_n(k)))^T\\in\\mathbb{R}^{n\\times p}\\), and \\(W=(w_{ij})\\in\\mathbb{R}^{n\\times n}\\), then we can rewrite 7.1 as \\[\\begin{equation} X(k+1)=W(X(k)-\\alpha_kG(k)) \\tag{7.2} \\end{equation}\\] Todo:\\(x_{i,k}\\stackrel{?}=x_{j,k},\\forall i,j\\in\\mathcal{N}\\) We compare DSGD with centralized stochastic gradient descent(SGD) which can query \\(n\\) gradients at each iteration, Algorithm7.2 (SGD) Initialize arbitrary \\(x_{0}\\in\\mathbb{R}^{p}\\) and choose stepsize \\(\\alpha_k\\) for each step For k=0,1,…, \\(x(k+1)=x(k)-\\alpha_k\\bar g(k)\\) where \\(\\bar g(k)=\\frac{1}{n}\\sum\\limits_{i=1}^n g_i(x(k),\\xi_i(k)),\\alpha_k=\\frac{1}{\\mu k}\\), we use \\(\\bar g(k)\\) here to make the gradient comparable to that in DSGD, i.e., \\(\\sum\\limits_{j=1}^n w_{ij} g_j(x_j(k),\\xi_j(k))\\). Choose \\(2-\\)norm as the loss function, the distance between \\(x(k)\\) and \\(x^*\\) at the \\(k\\)th step is \\[\\begin{equation} R(k)=E \\left[\\Vert x(k)-x^*\\Vert^2\\right]=\\frac{1}{n}\\sum\\limits_{i=1}^nE \\left[\\Vert x(k)-x^*\\Vert^2\\right] \\tag{7.3} \\end{equation}\\] which hints us to evaluate the similar distance of DSGD by \\[\\begin{equation} R&#39;(k)=\\frac{1}{n}\\sum\\limits_{i=1}^n E\\left[\\Vert x_i(k)-x^*\\Vert^2\\right] \\tag{7.4} \\end{equation}\\] Additonnally, (7.4) can be divided into two sources, one from the optimization error, and one from the consensus error, i.e., \\[\\begin{equation} R&#39;(K)=\\underbrace{E \\left[\\Vert \\bar x(k)-x^*\\Vert^2\\right]}_{\\text{expected optimization error}} + \\underbrace{\\frac{1}{n}\\sum_{i=1}^nE \\left[\\Vert x_i(k)-\\bar x(k)^*\\Vert^2\\right]}_{\\text{expected consensus error}} \\tag{7.5} \\end{equation}\\] This is because \\[\\begin{align} \\frac{1}{n}\\sum_{i=1}^n E\\left[\\langle x_i(k)-\\bar x, \\bar x - x^*\\rangle\\right]&amp;=E\\left[\\langle \\frac{1}{n}\\sum_{i=1}^nx_i(k)-\\bar x, \\bar x - x^*\\rangle\\right]\\\\ &amp;=0 \\end{align}\\] 7.2 Bounds We next compare SGD and DSGD by analyzing their error bounds. Lemma 7.1 Let assumptions 1.1, 4.1, 4.2,and 4.3 plus \\(W\\) is symmetric hold, for SGD 7.2, we have \\[ R(k+1) \\leq\\left(1-\\alpha_{k} \\mu\\right)^{2} R(k)+\\frac{\\alpha_{k}^{2} \\sigma^{2}}{n} \\] Denote \\(U(k)=E \\left[\\Vert \\bar x(k)-x^*\\Vert^2\\right]\\) and \\(V(k)=\\sum\\limits_{i=1}^nE \\left[\\Vert x_i(k)-\\bar x(k)\\right]\\), we have Lemma 7.2 Let the same assumptions in 7.1 hold, \\[ U(k+1) \\leq\\left(1-\\frac{1}{k}\\right)^{2} U(k)+\\frac{2 L}{\\sqrt{n} \\mu} \\frac{\\sqrt{U(k) V(k)}}{k}+\\frac{L^{2}}{n \\mu^{2}} \\frac{V(k)}{k^{2}}+\\frac{\\sigma^{2}}{n \\mu^{2}} \\frac{1}{k^{2}} \\] In chapter 9, lemma 9.7 shows that \\(\\exists K_0, s.t.\\) when \\(k&gt;K_0, R&#39;(k)\\leq \\frac{\\hat W}{\\tilde k}+\\frac{\\hat V}{\\tilde k^2}\\), where \\(\\tilde k\\) is some shift of \\(k\\) with a choice of step size \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)},K:=\\left\\lceil\\frac{2 \\theta L^{2}}{\\mu^{2}}\\right\\rceil\\). Remark. \\ In a view that \\(R(k)\\) and \\(R&#39;(k)\\) are both risk functions, if \\(V(k)\\) decays fast enough compared to \\(U(k)\\), we then have \\(R(k)\\approx R&#39;(k)\\) for large \\(k\\). the asymptotic network independence phenomenon: after a transient, DSGD performs comparably to a centralized stochastic gradient descent method with the same computational power. 7.3 Possible ways to achieve asymptotic network independece Considering nonconvex objective functions(distributed training of deep neural networks); Explore communication reduction techniques that do not sacrifice the asymptotic network independece property; Redcing the transient time; Additionnally, an unsolving question is can distributed methods compete with the centralized ones when the exact gradient is available? We list some big pictures related to the above issues in chapter 8. References "],
["sec-referasymnt.html", "Chapter 8 Some results in asymptotic network independence 8.1 Compressed Communication 8.2 \\(D^2\\)", " Chapter 8 Some results in asymptotic network independence 8.1 Compressed Communication 8.1.1 CHOCO-SGD Koloskova, Stich, and Jaggi (2019) proposed a decentralized stochastic method Choco-SGD(see algorithm 8.1) that converges at rate \\[\\begin{equation} \\mathcal{O}(\\frac{1}{nk}+\\frac{1}{(\\delta^2w^k)^2}) \\end{equation}\\] where \\(\\delta=1-|\\lambda_2(W)|\\) denotes the spectral gap of mixing matrix \\(W\\), \\(w\\leq1\\) is the compression quality factor. This method conserve the asymptotic network independence and can be applied to a network where the nodes compress their model update with quality \\(0&lt;w\\leq1\\). Addtionnally, the noise introduced by compression operator vanishes as \\(k\\to\\infty\\). Different from DSGD, Choco-SGD 8.1 use the averaged iterate \\(x_{\\mathrm{avg}}=\\frac{1}{S}\\sum\\limits_{k=1}^{k_{\\mathrm{stop}}}w_k\\bar x(k)\\), i.e., theorem 8.1, Theorem 8.1 Let assumptions 1.1 and 8.2 hold, algorithm 8.1 with SGD stepsize \\(\\alpha_k=\\frac{4}{\\mu(a+k)}\\), \\(a\\geq\\max\\{\\frac{410}{\\delta^2w},16\\kappa\\}\\) for \\(\\kappa=\\frac{L}{\\mu}\\), and consensus stepsize \\(\\gamma=\\frac{\\delta^{2} \\omega}{16 \\delta+\\delta^{2}+4 \\beta^{2}+2 \\delta \\beta^{2}-8 \\delta \\omega}\\) converges with the rate \\[ \\mathbb{E} \\left[f(x_{\\mathrm{avg}})-f(x^*)\\right]=\\mathcal{O}\\left(\\frac{\\bar{\\sigma}^{2}}{\\mu n T}\\right)+\\mathcal{O}\\left(\\frac{\\kappa G^{2}}{\\mu \\omega^{2} \\delta^{4} T^{2}}\\right)+\\mathcal{O}\\left(\\frac{G^{2}}{\\mu \\omega^{3} \\delta^{6} T^{3}}\\right) \\] where \\(x_{\\mathrm{avg}}=\\frac{1}{S}\\sum\\limits_{k=0}^{k_{\\mathrm{stop}}}w_k\\bar x(k)\\) with weight \\(w_k=(a+k)^2\\) and \\(S=\\sum\\limits_{k=0}^{k_{\\mathrm{stop}}}w_k\\) In the proof of theorem 8.1, the difference is that the author Koloskova, Stich, and Jaggi (2019) deal the term \\[ \\bar x(k)-\\alpha_k h(\\bar x(k))-x^* \\] differently. They estimate \\(\\Vert h(\\bar x(k))\\Vert^2\\) and \\(\\langle\\bar x(k)-x^*,h(\\bar x(k))\\rangle\\)(from lemma 8.1, we have \\(f(\\bar x(k))-f(x^*)\\)), while in DSGD, we use lemma 9.2. Then based on a lemma from Stich, Cordonnier, and Jaggi (2018), they finish the proof. Lemma 8.1 If \\(f\\) has \\(L-\\)Lipschitz gradient with minimizer \\(x^*,s.t.\\nabla f(x^*)=\\mathbf{0}\\), then \\[ \\|\\nabla f(x)\\|^{2}=\\left\\|\\nabla f(x)-\\nabla f\\left(x^{\\star}\\right)\\right\\|^{2} \\leq 2 L\\left(f(x)-f\\left(x^{\\star}\\right)\\right) \\] Let \\(Q(\\cdot):\\mathbb{R}^{p}\\to\\mathbb{R}^p\\) be a specific compression operator, which is known and satisfy assumption 8.1. \\(f_i(x):=E_{\\xi_i\\sim\\mathcal{D}_i} F_i(x,\\xi_i)\\) for a loss function \\(F_i:\\mathcal{R}^p\\times \\Omega_\\boldsymbol\\xi\\), \\(f_i\\) satisfy assumption 1.1 and distribution \\(\\mathcal{D_1},...,\\mathcal{D_n}\\) can be different on every node. Assumption8.1 The compression operator \\(Q(\\cdot):\\mathbb{R}^{p}\\to\\mathbb{R}^p\\) satisfies, \\[ E_{Q}\\|Q(x)-x\\|^{2} \\leq(1-\\omega)\\|x\\|^{2}, x\\in\\mathbb{R}^p, \\] for a parameter \\(w&gt;0\\). \\(E_Q\\) denotes the expectation over the internal randomness of operator \\(Q\\) The CHOCO-SGD method can be seen in algorithm 8.1, Algorithm8.1 (CHOCO-SGD) Initialize \\(x_i(0)\\in \\mathbb{R}^{p}, \\hat x_i(0)=\\mathbf{0}\\in\\mathbb{R}^{p}\\) for \\(i\\in\\mathcal{N}\\), consensus stepsize \\(\\gamma\\), SGD stepsize \\(\\alpha_k\\geq0\\),and mixing matrix \\(W=(w_{ij})\\in\\mathbb{R}^{n\\times n}\\) For \\(k=0,1,...\\) do in parallel for all agents \\(i\\in\\mathcal{N}\\), Sample \\(\\xi_i(k)\\), compute \\(g_i(k)=\\nabla F_i(x_i(k),\\xi_i(k))\\) \\(x_i(k+\\frac{1}{2})=x_i(k)-\\alpha_kg_i(k)\\) (stochastic gradient) \\(q_i(k)=Q(x_i(k)-\\hat x_i(k))\\) (compression operator) For all the neighbor \\(j\\) of agents \\(i\\), i.e., \\((i,j)\\in\\mathcal{E}\\), Send \\(q_i(k)\\) and receive \\(q_j(k)\\) \\(\\hat x_j(k+1)=\\hat x_j(k)+q_j(k)\\) \\(x_i(k+1)=x_i(k+\\frac{1}{2})+\\gamma \\sum_{j:(i,j)\\in\\mathcal{E}} w_{ij}(\\hat x_j(k+1)-\\hat x_i(k+1))\\) When the compression quality \\(w=1\\),i.e. no communication compression, and consensus stepsize \\(\\gamma=1\\), the updation in algorithm 8.1 becomes \\[ x_i(k+1)=\\sum\\limits_{i=1}^nw_{ij}(x_i(k)-\\alpha_kg_i(k)) \\] which is the DSGD algorithm 7.2. From the setting \\[f_i(x):=E_{\\xi_i\\sim\\mathcal{D}_i} F_i(x,\\xi_i)\\] \\(g_i(k)\\) satisify the unbiased property in assumption 4.1 automatically when \\(\\nabla\\) and expectation on \\(F_i\\) can be interchanged. Despite the second property in assumption 4.1, we need to assum the second moment of \\(\\nabla F_i(x,\\xi_i)\\) is finite,i.e., assumption 8.2. A little difference is that \\(\\sigma\\) can be different for each agent. Assumption8.2 \\[\\begin{align} E_{\\xi_{i}}\\left\\|\\nabla F_{i}\\left(x, \\xi_{i}\\right)-\\nabla f_{i}(x)\\right\\|^{2} &amp;\\leq \\sigma_{i}^{2}, \\quad \\forall x \\in \\mathbb{R}^{d}, i \\in\\mathcal{N}\\\\ E_{\\xi_{i}}\\left\\|\\nabla F_{i}\\left(x, \\xi_{i}\\right)\\right\\|^{2} &amp;\\leq G^{2},\\quad\\forall x \\in \\mathbb{R}^{d}, i \\in\\mathcal{N} \\end{align}\\] 8.1.2 Stochastic gradient push The push sum gossip algorithm is robust to stragglers and communication delays. Assran et al. (2018) propose a variant of stochastic gradient push(SGP), called overlap SGP, converges to a stationary point of smooth, non-convex objectives at an \\(\\mathcal{O}(\\frac{1}{\\sqrt{nK}})\\), and that all nodes achieve consensus. Additionally, we use a sequence of mixing matrice \\(W_k\\) here. We uses a different convergence criteria(Lian et al. 2017), i.e., for the number of iterations \\(K\\), \\[\\begin{equation} \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{E}\\left\\|\\nabla f\\left(\\bar{{x}}(k)\\right)\\right\\|^{2} \\leq \\varepsilon, \\forall \\varepsilon \\tag{8.1} \\end{equation}\\] 8.2 \\(D^2\\) Global scheme, \\[ X_1=W(X_0-\\alpha G_0)\\\\ X_{k+1}=W(X_k-\\alpha G_k)+W(X_k-X_{k-1}-\\alpha G_{k-1}) \\] then we have, \\[ \\bar x_{k+1} = \\bar x_k - \\alpha G_k \\] Thus if we assume each \\(f_i\\) is strongly convex, we can still use lemma 9.3. However, for the expected consensus error \\(V(k)=E\\left[\\Vert X_{k}-\\mathbf{1}\\bar x_k\\right]\\), we need to use, \\[\\begin{align} X_{k+1}-\\mathbf{1}\\bar x_{k+1}&amp;= W(2X_k-X_{k-1}-\\alpha G_k+\\alpha G_{k-1})-\\mathbf{1}(\\bar x_k-\\alpha \\bar g_k)\\\\ &amp;=2(WX_{k}-\\mathbf{1}\\bar x_k)-\\alpha (WG_k-\\mathbf{1}\\bar g_k)\\\\ &amp;\\quad -(WX_{k-1}-\\mathbf{1}\\bar x_{k-1}) +\\alpha(WG_{k-1}-\\bar g_{k-1}) \\tag{8.2} \\end{align}\\] then the following steps are similar to those in the proof of lemma 9.4. Then if we can uniformly bound \\(R&#39;(k)\\), we can derive the convergence rate of \\(D^2\\). References "],
["sec-sharp.html", "Chapter 9 A sharp estimate of the transient time of DSGD 9.1 \\(U(k)\\) and \\(V(k)\\) 9.2 Asymptotic network independence of DSGD 9.3 Transient time 9.4 Sharpness 9.5 Summary", " Chapter 9 A sharp estimate of the transient time of DSGD In this chapter, we derive an estimate of transient time \\(K_T\\) of DSGD and then show it is sharp(Pu, Olshevsky, and Paschalidis 2019a). During this, we will prove lemma 7.2 in chapter 7. Still, we set \\(f_i, i\\in\\mathcal{N}\\) are \\(\\mu-\\)strongly convex with \\(L-\\)Lipschitz continuous gradients, the graph \\(\\mathcal{G}=(\\mathcal{N},\\mathcal{E})\\) is connected and undirected, and we are able to obtain “good” gradient estimates \\(g_i(x_i(k),\\xi_i(k))\\), i.e. the assumptions 1.1, 4.1, 4.2,and 4.3 hold. We first derive the recursion of \\(R&#39;(k),U(k),\\) and \\(V(k)\\) defined in chapter 7. 9.1 \\(U(k)\\) and \\(V(k)\\) To keep the consistency in notation, we still use \\(h(X)=\\frac{1}{n}\\mathbf{1}^T\\nabla F(X)\\), which the authors denote as \\(\\bar\\nabla F(X)\\). Let \\(\\bar g(k)=\\frac{1}{n}\\mathbf{1}^TG(X(k),\\boldsymbol\\xi(k))\\)6. The idea is the same as that in (4.3), we have \\[\\begin{align} \\bar x(k+1)-x^*&amp;=\\bar x(k)-\\alpha_k\\left[\\bar g(k)-\\frac{1}{n}\\mathbf{1}^T\\nabla F(X(k))\\right]-\\\\ &amp;\\alpha_k\\left[\\frac{1}{n}\\mathbf{1}^T\\nabla F(X(k))-\\nabla f(\\bar x(k))\\right]-\\alpha_k\\nabla f(\\bar x(k))-x^*\\\\ &amp;:=(\\bar x(k)-\\alpha_k\\nabla f(\\bar x(k))-x^*)-\\alpha_k(\\bar g(k)-h(X(k)))-\\\\ &amp;\\alpha_k(h(X(k))-\\nabla f(\\bar x(k))) \\tag{9.1} \\end{align}\\] Then we can use lemma 4.1 and assumption 4.1. Moreover, we use \\(|\\langle a,b\\rangle|\\leq \\Vert a\\Vert \\cdot\\Vert b\\Vert\\) to deal with \\(&lt;\\bar x(k)-\\alpha_k\\nabla f(\\bar x(k))-x^*,\\nabla f(\\bar x(k))-h(X(k))&gt;\\). Then take expectation conditioned on \\(X(k)\\), we have lemma 9.1. Lemma 9.1 For algorithm 7.1, \\(\\forall k\\geq0\\), we have, \\[\\begin{align} &amp;E\\left[\\left\\|\\bar{x}(k+1)-x^{*}\\right\\|^{2} | X(k)\\right] \\leq\\left\\|\\bar{x}(k)-\\alpha_{k} \\nabla f(\\bar{x}(k))-x^{*}\\right\\|^{2}\\\\ &amp;+\\frac{2 \\alpha_{k} L}{\\sqrt{n}}\\left\\|\\bar{x}(k)-\\alpha_{k} \\nabla f(\\bar{x}(k))-x^{*}\\right\\|\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|+\\frac{\\alpha_{k}^{2} L^{2}}{n}\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|^{2}+\\frac{\\alpha_{k}^{2} \\sigma^{2}}{n} \\end{align}\\] From lemma 9.1, let \\(\\alpha_k=\\frac{1}{\\mu k}&lt;\\frac{2}{\\mu+L}\\), use lemma 3.4, and take full expectation on both sides, we derive lemma 7.2 in chapter 7. \\[\\begin{align} U(k+1)&amp;\\leq (1-\\frac{1}{k})^2 U(k)+\\frac{2L(1-\\frac{1}{k})}{\\mu k\\sqrt{n}}E\\left[\\Vert \\bar x(k)-x^*\\Vert\\cdot \\Vert x(k)-\\mathbf{1}\\bar x(k)\\Vert\\right]+\\\\ &amp;\\frac{L^2}{\\mu^2 k^2n}V(k)+\\frac{\\sigma^2}{\\mu^2k^2n}\\\\ &amp;\\leq (1-\\frac{1}{k})^2 U(k)+\\frac{2L}{\\mu\\sqrt{n}}\\frac{\\sqrt{U(k)V(k)}}{k}+\\frac{L^2}{\\mu^2 k^2n}V(k)+\\frac{\\sigma^2}{\\mu^2k^2n} \\end{align}\\] Where We use Cauchy-Schwartz inequality in the second inequality. We can also separate \\(\\frac{2 \\alpha_{k} L}{\\sqrt{n}}\\left\\|\\bar{x}(k)-\\alpha_{k} \\nabla f(\\bar{x}(k))-x^{*}\\right\\|\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|\\) by \\[\\begin{align} &amp;\\frac{2 \\alpha_{k} L}{\\sqrt{n}}\\left\\|\\bar{x}(k)-\\alpha_{k} \\nabla f(\\bar{x}(k))-x^{*}\\right\\|\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|\\\\ &amp;\\leq \\lambda^2c\\Vert \\bar x(k)-x^*\\Vert + \\frac{L^2}{cn}\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert \\tag{9.2} \\end{align}\\] for an arbitary \\(c&gt;0\\)(in chapter 4, we let \\(c=\\mu\\)). \\(\\lambda\\) comes from lemma 9.2. Comparing lemma 9.2 with lemma 3.4, they only differ with the choice of \\(\\alpha\\). Lemma 9.2 Let assumption 1.1 holds, \\(\\forall x\\in\\mathbb{R}^p\\) and \\(\\alpha\\in(0,2/L)\\), we have, \\[ \\left\\|x-\\alpha \\nabla f(x)-x^{*}\\right\\| \\leq \\lambda\\left\\|x-x^{*}\\right\\| \\] where \\(\\lambda=\\max (|1-\\alpha \\mu|,|1-\\alpha L|)\\) From lemma 9.1 and formula (9.2), take the full expectation on both sides, we have for \\(\\alpha_k\\in(0,2/L)\\), \\[\\begin{align} U(k+1)\\leq \\lambda^2(1+c) U(k)+\\frac{\\alpha_k^2L^2}{cn}(1+\\frac{1}{c})V(k)+\\frac{\\alpha_k\\sigma^2}{n} \\tag{9.3} \\end{align}\\] Take \\(c=\\frac{3}{8}\\alpha_k\\mu\\) and let \\(\\alpha_k\\leq\\min\\{\\frac{1}{L},\\frac{1}{3\\mu}\\}\\) in (9.3), we derive lemma 9.3. \\(\\alpha_k\\leq \\frac{1}{L}\\) is to make \\(\\lambda = 1-\\alpha_k\\mu\\) in lemma 9.2, \\(\\alpha_k\\leq \\frac{1}{3\\mu}\\) is to make \\((1+c)\\lambda^2\\leq 1-\\frac{3}{2}\\alpha_k\\mu\\). Thus we derive lemma 9.3. Todo:why \\(1-\\frac{3}{2}\\alpha_k\\mu\\) Lemma 9.3 Under algorithm 7.1, let \\(\\alpha_k\\leq\\min\\{\\frac{1}{L},\\frac{1}{3\\mu}\\}\\), then \\[ U(k+1) \\leq\\left(1-\\frac{3}{2} \\alpha_{k} \\mu\\right) U(k)+\\frac{3 \\alpha_{k} L^{2}}{n \\mu} V(k)+\\frac{\\alpha_{k}^{2} \\sigma^{2}}{n} \\] For \\(V(k+1)\\), similar to (4.6), we denote \\(G(k):=G(X(k),\\boldsymbol\\xi(k))\\) here, then \\[\\begin{align} &amp;E\\left[\\Vert X(k+1)-\\mathbf{1}\\bar x(k+1)\\Vert^2|X(k)\\right]\\\\ &amp;=E\\left[\\Vert WX(k)-\\alpha_kWG(k)-\\mathbf{1}(\\bar x(k)-\\alpha_k\\bar g(k))\\Vert^2|X(k)\\right]\\\\ &amp;\\leq \\rho_w^2\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert^2+\\alpha_k^2\\rho_w^2E\\left[\\Vert G(k)-\\mathbf{1}\\bar g(k)\\Vert^2|X(k)\\right] -\\\\ &amp;\\quad 2\\alpha_k\\rho_w^2E\\left[\\langle X(k)-\\mathbf{1}\\bar x(k),G(k)-\\mathbf{1}\\bar g(k)\\rangle|X(k)\\right]\\\\ &amp;\\leq \\rho_w^2\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert^2+\\alpha_k^2\\rho_w^2E\\left[\\Vert G(k)-\\mathbf{1}\\bar g(k)\\Vert^2|X(k)\\right] -\\\\ &amp;\\quad 2\\alpha_k\\rho_w^2E\\left[\\langle X(k)-\\mathbf{1}\\bar x(k),\\nabla F(X(k))-\\mathbf{1}h(X(k))\\rangle|X(k)\\right]\\\\ \\tag{9.4} \\end{align}\\] Next, we show \\[\\begin{align} E\\left[\\Vert G(k)-\\mathbf{1}\\bar g(k)\\Vert^2|X(k)\\right] &amp;\\leq\\|\\nabla F(X(k))-\\mathbf{1} h(X(k))\\|^{2}+n \\sigma^{2}\\\\ \\|\\nabla F(X(k))-\\mathbf{1} h(X(k))\\|^{2}&amp;\\leq \\Vert \\nabla F(X(k))\\Vert^2 \\tag{9.5} \\end{align}\\] This is because, \\[\\begin{align} &amp;E\\left[\\Vert G(k)-\\mathbf{1}\\bar g(k)\\Vert^2|X(k)\\right]\\\\ &amp;=E\\left[\\Vert (G(k)-\\nabla F(X(k)))-\\mathbf{1}(\\bar g(k)-h(X(k)))+(\\nabla F(X(k))-\\mathbf{1}h(X(k)))\\Vert^2|X(k)\\right]\\\\ &amp;\\leq E\\left[\\Vert G(k)-\\nabla F(X(k)\\Vert^2|X(k)\\right]-nE\\left[\\Vert \\bar g(k)-h(X(k)) \\Vert^2|X(k)\\right] + \\\\ &amp;\\quad\\Vert \\nabla F(X(k))-\\mathbf{1}h(X(k))\\Vert^2\\\\ &amp;\\leq n \\sigma^{2}+ \\|\\nabla F(X(k))-\\mathbf{1} h(X(k))\\|^{2}\\\\ &amp;\\leq n\\sigma^2 + \\vert \\nabla F(X(k))\\Vert^2 +n\\vert h(x)\\Vert^2 - 2\\langle\\nabla F(X(k)),\\mathbf{1}h(X(k))\\rangle \\\\ &amp;\\leq n\\sigma^2 + \\Vert \\nabla F(X(k))\\Vert^2 \\end{align}\\] The last inequality is from \\(\\langle\\mathbf{A}, \\mathbf{B}\\rangle:=\\sum_{i=1}^{n}\\left\\langle A_{i}, B_{i}\\right\\rangle\\),i.e. \\[\\begin{align} \\langle\\nabla F(X(k)),\\mathbf{1}h(X(k))\\rangle&amp;=\\sum_{i=1}^n\\langle\\nabla f_i(x_i(k)),\\frac{1}{n}\\sum_{j=1}^n\\nabla f_j(x_j(k))\\rangle\\\\ &amp;=n\\langle \\frac{1}{n}\\sum_{i=1}^n \\nabla f_i(x_i(k)),\\frac{1}{n}\\sum_{j=1}^n\\nabla f_j(x_j(k))\\rangle\\\\ &amp;=n\\Vert h(X(k))\\Vert^2 \\end{align}\\] Next, we bound \\(\\vert \\nabla F(X(k))\\Vert^2\\). Recall \\(\\nabla f\\) is \\(L-\\)Lipschitz continuous, and we need \\(X(k)-\\mathbf{1}\\bar x(k)\\) as well as \\(\\bar x(k)-x^*\\), so we have, \\[\\begin{align} &amp;\\Vert \\nabla F(X(k))\\Vert^2\\\\ &amp;= \\Vert \\nabla F(X(k))-\\nabla F(\\mathbf{1}\\bar x(k))+\\nabla F(\\mathbf{1}\\bar x(k))-\\nabla F(\\mathbf{1}x^*)+\\nabla F(\\mathbf{1}x^*)\\Vert^2\\\\ &amp;\\leq\\left(L\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|+\\sqrt{n} L\\left\\|\\bar{x}(k)-x^{*}\\right\\|+\\left\\|\\nabla F\\left(\\mathbf{1} x^{*}\\right)\\right\\|\\right)^{2}\\\\ &amp;\\stackrel{?}\\leq 2 L^{2}\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|^{2}+4 n L^{2}\\left\\|\\bar{x}(k)-x^{*}\\right\\|^{2}+4\\left\\|\\nabla F\\left(\\mathbf{1} x^{*}\\right)\\right\\|^{2} \\tag{9.6} \\end{align}\\] Use the two inequalities (9.5) and (9.6) in (9.4), we have \\[\\begin{align} &amp;\\frac{1}{\\rho_w^2}E\\left[\\Vert X(k+1)-\\mathbf{1}\\bar x(k+1)\\Vert^2|X(k)\\right]-\\alpha_k^2n\\sigma^2\\\\ &amp;\\leq \\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert^2 + \\alpha_k^2 \\Vert \\nabla F(X(k))\\Vert^2 + 2\\alpha_k\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert\\cdot \\Vert \\nabla F(X(k))\\Vert\\\\ \\end{align}\\] For the last term, from (9.6), \\[\\begin{align} &amp;2\\alpha_k\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert\\cdot \\Vert \\nabla F(X(k))\\Vert\\\\ &amp;\\leq2\\alpha_k \\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert\\left(L\\|X(k)-\\mathbf{1} \\bar{x}(k)\\|+\\sqrt{n} L\\left\\|\\bar{x}(k)-x^{*}\\right\\|+\\left\\|\\nabla F\\left(\\mathbf{1} x^{*}\\right)\\right\\|\\right)\\\\ &amp;\\leq 2\\alpha_kL\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert^2 + \\left[c\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert^2+\\frac{\\alpha_k^2}{c}(\\sqrt{n} L\\left\\|\\bar{x}(k)-x^{*}\\right\\|+\\| \\nabla F\\left(\\mathbf{1} x^{*}\\right)^2)\\right]\\\\ &amp;\\leq (2\\alpha_kL+c)\\Vert X(k)-\\mathbf{1}\\bar x(k)\\Vert^2 + \\frac{\\alpha_k}{c}\\left(2 n L^{2}\\left\\|\\bar{x}(k)-x^{*}\\right\\|^{2}+2\\left\\|\\nabla F\\left(\\mathbf{1} x^{*}\\right)\\right\\|^{2}\\right) \\end{align}\\] For \\(\\forall c&gt;0\\), the last inequality uses \\((a+b)^2\\leq 2(a^2+b^2)\\). Let \\(c=\\frac{1-\\rho_w^2}{2}\\), the same as that in (4.6) in chapter 4, then we have lemma 9.4. Lemma 9.4 Under algorithm 7.1, \\(\\forall k\\geq0\\), \\[\\begin{align} V(k+1)&amp;\\leq \\rho_{w}^{2}\\left(\\frac{3-\\rho_{w}^{2}}{2}+2 \\alpha_{k} \\rho_{w}^{2} L+2 \\alpha_{k}^{2} \\rho_{w}^{2} L^{2}\\right) V(k) + \\\\ &amp; \\rho_{w}^{2} \\alpha_{k}^{2}\\left[\\frac{8 n L^{2}}{\\left(1-\\rho_{w}^{2}\\right)} U(k)+\\frac{8\\left\\|\\nabla F\\left(\\mathbf{1} x^{*}\\right)\\right\\|^{2}}{\\left(1-\\rho_{w}^{2}\\right)}+n \\sigma^{2}\\right] \\end{align}\\] 9.2 Asymptotic network independence of DSGD In this section, we first show for algorithm 7.1, \\(U(k)=\\mathcal O(\\frac{1}{k})\\) and \\(V(k)=\\mathcal O(\\frac{1}{k^2})\\), i.e. algorithm 7.1 enjoys the sublinear convergence rate. More specifically, we show that \\(\\exists N, s.t. k&gt;N,\\) \\[\\begin{equation} U(k)\\leq \\frac{\\hat W(1-\\rho_w^2)}{\\tilde k},\\quad V(k)\\leq \\frac{\\hat V((1-\\rho_w^2,\\hat W))}{\\tilde k^2} \\tag{9.7} \\end{equation}\\] where \\(\\tilde k\\) is some shift of \\(k\\), \\(\\hat W(\\cdot)\\) and \\(\\hat V(\\cdot)\\) are functions. The goal is to show that asymptotically, \\(\\frac{1}{n}\\sum\\limits_{i=1}^nE\\left[\\Vert x_i(k)-x^*\\Vert^2\\right]=R&#39;(k)=U(k)+\\frac{1}{n}V(k)\\) has the same convergence rate with \\(R(k)\\) in SGD. Notice \\(V(k)\\) can be shown to decay faster than \\(U(k)\\), so if we can bound \\(\\hat W(1-\\rho_w^2)\\) by another quantity \\(C\\) which does not depende on \\(\\rho_w^2\\), i.e. does not depende on the network, then we can have \\[\\begin{equation} R&#39;(k)\\leq\\frac{C}{\\tilde k}+\\frac{1}{n} \\frac{V(1-\\rho_w^2)}{\\tilde k^2} \\tag{9.8} \\end{equation}\\] which shows the asymptotic newwork independence property of DSGD. Then by (9.8), we can obtain the transient time for DSGD to reach the asymptotic convergence rate. We first give a uniform bound for \\[\\begin{align} E\\left[\\Vert X(k)-\\mathbf{1}x^*\\Vert^2\\right]&amp;=E\\left[\\sum_{i=1}^n\\Vert x_i^T(k)-x^*\\Vert^2\\right]\\\\ &amp;=\\sum_{i=1}^n E\\left[\\Vert x_i^T(k)-x^*\\right]\\\\ &amp;=nR&#39;(k) \\end{align}\\] Lemma 9.5 For algorithm 7.1, \\(\\forall k\\geq0\\), \\[ E\\left[\\left\\|X(k)-1 x^{*}\\right\\|^{2}\\right] \\leq \\hat{X}:=\\max \\left\\{\\left\\|X(0)-1 x^{*}\\right\\|^{2}, \\frac{9 \\sum_{i=1}^{n}\\left\\|\\nabla f_{i}\\left(x^{*}\\right)\\right\\|^{2}}{\\mu^{2}}+\\frac{n \\sigma^{2}}{L^{2}}\\right\\} \\] Remark. \\ \\(X(k)-\\mathbf{1}x^*=W^k(X(0)-\\mathbf{1}x^*)-\\sum\\limits_{i+j=k}W^i\\alpha_jG(j)\\leq W^k(X(0)-\\mathbf{1}x^*)\\) ?The author derive the second part in the \\(\\max\\{\\cdot\\}\\) by \\(E\\left[\\|X(k)\\|^{2}\\right] \\leq \\max \\left\\{\\|X(0)\\|^{2}, \\sum_{i=1}^{n} R_{i}\\right\\}\\) 9.2.1 Sublinear rate Recall \\(R&#39;(k)=U(k)+\\frac{1}{n}V(k)\\), hence we introduce \\(W(k)\\) as \\[\\begin{equation} W(k):=U(k)+\\omega(k)V(k),\\quad \\forall k\\geq0 \\tag{9.9} \\end{equation}\\] where \\(\\omega(k)&gt;0\\) is to be determined later. (9.9) is called the Lyapunov function. From lemma 9.5, we have a uniform bound for \\(R&#39;(k)\\leq \\frac{\\hat X}{n}\\), we also want such a property on \\(W(k)\\),i.e. \\(W(k)\\leq\\frac{\\hat X}{n}\\). This is how we determine \\(\\omega(k)\\). From lemma 9.3 and 9.4, we further establish a recursion of \\(W(k)\\). By induction, it will have a term of \\(\\prod\\limits_{t=a}^{k-1}(1-\\frac{\\gamma}{t})\\). Lemma 9.6 leads us to bound such a term. Then \\(U(k)\\) is bounded from \\(U(k)\\leq W(k)\\). \\(V(k)\\) is bound from lemma 9.4 and the bound for \\(U(k)\\). Lemma 9.6 \\(\\forall 1&lt;a&lt;k(a\\in\\mathbb{N})\\) and \\(1&lt;\\gamma&lt;a/2\\), \\[ \\frac{a^{2 \\gamma}}{k^{2 \\gamma}} \\leq \\prod_{t=a}^{k-1}\\left(1-\\frac{\\gamma}{t}\\right) \\leq \\frac{a^{\\gamma}}{k^{\\gamma}} \\] Lemma 9.7 shows the algorithm 7.1 with the stepsize policy being \\[ \\alpha_k=\\frac{\\theta}{\\mu(k+K)},K:=\\left\\lceil\\frac{2 \\theta L^{2}}{\\mu^{2}}\\right\\rceil \\] enjoys sublinear rate. Lemma 9.7 (Sublinear rate of DSGD) For algorithm 7.1,let \\[\\begin{equation*} K_{1}:=\\left\\lceil\\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}\\right\\rceil \\end{equation*}\\] \\(\\forall k\\geq K_1-K\\), we have \\[\\begin{equation*} U(k)\\leq \\frac{\\hat W}{\\tilde k},\\quad V(k)\\leq \\frac{\\hat V}{\\tilde k^2} \\end{equation*}\\] where, \\[ \\hat{W}:=\\frac{K_{1} \\hat{X}}{n}+\\frac{3}{(4 \\theta-3)}\\left(\\frac{\\sigma^{2} \\theta^{2}}{n \\mu^{2}}+\\frac{\\sigma^{2} \\rho_{w}^{2} \\theta^{2}}{2 \\mu^{2}}\\right)+\\frac{12\\left\\|\\nabla F\\left(1 x^{*}\\right)\\right\\|^{2} \\rho_{w}^{2} \\theta^{2}}{(4 \\theta-3) n \\mu^{2}\\left(1-\\rho_{w}^{2}\\right)} \\] \\[ \\hat{V}:=\\max \\left\\{K_{1}^{2} \\hat{X}, \\frac{8 \\theta^{2} \\rho_{w}^{2}}{\\mu^{2}\\left(1-\\rho_{w}^{2}\\right)}\\left[\\frac{4\\left\\|\\nabla F\\left(\\mathbf{1} x^{*}\\right)\\right\\|^{2}}{\\left(1-\\rho_{w}^{2}\\right)}+n \\sigma^{2}+\\frac{4 n L^{2} \\hat{W}}{\\left(1-\\rho_{w}^{2}\\right) K_{1}}\\right]\\right\\} \\] \\[ \\tilde k=k+K \\] Remark. \\(\\omega(k)=\\frac{12 \\alpha_{k} L^{2}}{n \\mu\\left(1-\\rho_{w}^{2}\\right)}=\\frac{f(a_k)}{n(1-\\rho_w^2)}\\leq \\frac{1}{n}\\) so that \\(W(k)\\leq \\frac{\\hat X}{n}\\). This requires \\(f(a_k)=\\frac{12\\alpha_kL^2}{\\mu}\\leq 1-\\rho_w^2\\), which is satisfied for the choice of \\(K_1=\\left\\lceil\\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}\\right\\rceil\\geq \\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}\\), i.e., \\[\\begin{align} f(a_k)&amp;=\\frac{12\\alpha_kL^2}{\\mu}\\stackrel{k\\geq K_1-K}\\leq \\frac{12L^2}{\\mu}\\frac{\\theta}{\\mu K_1}\\\\ &amp;\\stackrel{K_1\\geq \\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}}\\leq \\frac{1-\\rho_w^2}{2} \\end{align}\\] We introduce \\(\\tilde k\\) is based on \\(\\alpha_k=\\frac{c}{k+K}\\). Moreover, we introduce the following shift of \\(U(k),V(k)\\), and \\(W(k)\\) for simplicity. \\[\\begin{equation} \\tilde{U}(k):=U(k-K), \\quad \\tilde{V}(k):=V(k-K), \\quad \\tilde{W}(k):=W(k-K), \\quad \\forall k \\geq K \\tag{9.10} \\end{equation}\\] The uniform bound of \\(R&#39;(k)\\) (lemma 9.5) gives bound for the above quantities. \\(\\tilde U(k)\\leq \\frac{\\hat X}{n}, \\tilde V(k)\\leq \\hat X\\), and \\(\\tilde W(k)\\leq\\frac{\\hat X}{n}\\). This can also be seen from the definition in (9.10), which moves \\(U(k),V(k)\\) and \\(W(k)\\) horizontally. 9.2.2 Asymptotic network independence In this section, we show that the asymptotic network independence of algorithm 7.1 with the stepsize policy being \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\). That is, although \\(R&#39;(k)=U(k)+\\frac{1}{n}V(k)\\) depends on the network involving the term of \\(1-\\rho_w^2\\), we show that part will decay faster. Then after some iterations (\\(\\exists K_0\\), when \\(k\\geq K_0\\)), \\(R(k)\\leq \\frac{C}{\\tilde k}, \\exists C\\). From lemma 9.3, substitute \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\) and let \\(k&#39;=k+K\\), then \\[\\begin{equation} \\tilde{U}(k&#39;-K+1) \\leq\\left(1-\\frac{3 \\theta}{2 k&#39;}\\right) \\tilde{U}(k&#39;-K)+\\frac{3 \\theta L^{2}}{n \\mu^{2}} \\frac{\\tilde{V}(k&#39;-K)}{k&#39;}+\\frac{\\theta^{2} \\sigma^{2}}{n \\mu^{2}} \\frac{1}{k&#39;^{2}}, \\quad \\forall k&#39; \\geq K_{1} \\end{equation}\\] Then from (9.10), we simplify the above as \\[\\begin{equation} \\tilde{U}(k+1) \\leq\\left(1-\\frac{3 \\theta}{2 k}\\right) \\tilde{U}(k)+\\frac{3 \\theta L^{2}}{n \\mu^{2}} \\frac{\\tilde{V}(k)}{k}+\\frac{\\theta^{2} \\sigma^{2}}{n \\mu^{2}} \\frac{1}{k^{2}}, \\quad \\forall k \\geq K_{1} \\tag{9.11} \\end{equation}\\] By induction and lemma 9.6, we bound \\(U(k)\\) with the network dependent term decaying faster, i.e. theorem 9.1. Additionally, from lemma 9.7, \\(\\tilde V(k)=V(k-K)\\leq \\frac{\\hat V}{k^2}\\), (9.11) becomes \\[\\begin{align} \\tilde U(k)\\leq \\frac{K_{1}^{1.5 \\theta}}{k^{1.5 \\theta}} \\tilde{U}\\left(K_{1}\\right)+\\sum_{t=K_{1}}^{k-1} \\frac{(t+1)^{1.5 \\theta}}{k^{1.5 \\theta}}\\left(\\frac{\\theta^{2} \\sigma^{2}}{n \\mu^{2} t^{2}}+\\frac{3 \\theta L^{2}}{n \\mu^{2}} \\frac{\\hat V}{t^3}\\right) \\tag{9.12} \\end{align}\\] The inequality holds for \\(1&lt;\\frac{3\\theta}{2}\\leq \\frac{K_1}{2}\\), where \\(K_1:=\\left\\lceil\\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}\\right\\rceil\\). To simplify (9.12), we claim that \\[ \\sum_{t=K_1}^{k-1}\\frac{(t+1)^{1.5\\theta}}{t^2}\\leq \\frac{b^{1.5 \\theta-1}}{1.5 \\theta-1}+\\frac{3 b^{1.5 \\theta-2}}{1.5 \\theta-2}+3 b^{1.5 \\theta-2} \\] and \\[ \\sum_{a}^{b} \\frac{(t+1)^{1.5 \\theta}}{t^{3}} \\leq \\int_{a}^{b} t^{1.5 \\theta-3} d t \\leq \\frac{2 b^{1.5 \\theta-2}}{1.5 \\theta-2} \\] Then, \\[\\begin{align} \\tilde{U}(k) &amp;\\leq \\frac{\\theta^{2} \\sigma^{2}}{(1.5 \\theta-1) n \\mu^{2} k}+\\frac{3 \\theta^{2}(1.5 \\theta-1) \\sigma^{2}}{(1.5 \\theta-2) n \\mu^{2}} \\frac{1}{k^{2}}+\\frac{K_{1}^{1.5 \\theta}}{k^{1.5 \\theta}} \\tilde{U}\\left(K_{1}\\right)+\\frac{6 \\theta L^{2} \\hat{V}}{(1.5 \\theta-2) n \\mu^{2}} \\frac{1}{k^{2}}\\\\ &amp;\\leq \\frac{\\theta^{2} \\sigma^{2}}{(1.5 \\theta-1) n \\mu^{2} \\tilde{k}}+\\left[\\frac{3 \\theta^{2}(1.5 \\theta-1) \\sigma^{2}}{(1.5 \\theta-2) n \\mu^{2}}+\\frac{6 \\theta L^{2} \\hat{V}}{(1.5 \\theta-2) n \\mu^{2}}\\right] \\frac{1}{\\tilde{k}^{2}} \\\\ &amp;\\quad +\\frac{K_1^{1.5\\theta}\\hat X}{n}\\frac{1}{\\tilde k^3},\\forall k\\geq K_1-K \\tag{9.13} \\end{align}\\] Remark. The last inequality in (9.13) holds for \\(\\theta &gt;2\\), we also use \\(\\tilde U(K_1)\\leq \\frac{\\hat X}{n}\\), i.e. lemma 9.7 How does it yield theorem 9.1? Theorem 9.1 Under algorithm 7.1 with \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\), let \\(\\theta&gt;2, K:=\\left\\lceil\\frac{2 \\theta L^{2}}{\\mu^{2}}\\right\\rceil\\), and \\(K_{1}:=\\left\\lceil\\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}\\right\\rceil\\), we have \\[ U(k) \\leq \\frac{\\theta^{2} \\sigma^{2}}{(1.5 \\theta-1) n \\mu^{2} \\tilde{k}}+\\left[\\frac{3 \\theta^{2}(1.5 \\theta-1) \\sigma^{2}}{(1.5 \\theta-2) n \\mu^{2}}+\\frac{6 \\theta L^{2} \\hat{V}}{(1.5 \\theta-2) n \\mu^{2}}\\right] \\frac{1}{\\tilde{k}^{2}}, \\quad \\forall k \\geq K_{1}-K \\] Where \\(\\hat V=\\mathcal{O}(\\frac{n}{(1-\\rho_w)^2})\\) with some constraints on \\(\\Vert X(0)-\\mathbf{1}x^*\\Vert^2\\) and \\(\\Vert \\nabla F(\\mathbf{1}x^*)\\Vert^2\\) according to lemma 9.8. Lemma 9.8 Suppose \\(\\sum\\limits_{i=1}^{n}\\left\\|x_{i}(0)-x^{*}\\right\\|^{2}=\\mathcal{O}(n) \\text { and } \\sum\\limits_{i=1}^{n}\\left\\|\\nabla f_{i}\\left(x^{*}\\right)\\right\\|^{2}=\\mathcal{O}(n)\\), then \\[ \\hat V=\\mathcal{O}(\\frac{n}{(1-\\rho_w^2)^2}) \\] This is because given such conditions on \\(\\Vert X(0)-\\mathbf{1}x^*\\Vert^2\\) and \\(\\Vert \\nabla F(\\mathbf{1}x^*)\\Vert^2\\), \\(\\hat X=\\mathcal{O}(n)\\) and from lemma 9.7, \\(\\hat W=\\mathcal{O}(\\frac{1}{1-\\rho_w^2})\\). For \\(\\hat V\\), noticing \\(K_1=\\left\\lceil\\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}\\right\\rceil\\leq \\frac{24 L^{2} \\theta}{\\left(1-\\rho_{w}^{2}\\right) \\mu^{2}}+1\\), then \\[\\begin{align} \\hat V&amp;=\\max \\left\\{K_{1}^{2} \\hat{X}, \\frac{8 \\theta^{2} \\rho_{w}^{2}}{\\mu^{2}\\left(1-\\rho_{w}^{2}\\right)}\\left[\\frac{4\\left\\|\\nabla F\\left(1 x^{*}\\right)\\right\\|^{2}}{\\left(1-\\rho_{w}^{2}\\right)}+n \\sigma^{2}+\\frac{4 n L^{2} \\hat{W}}{\\left(1-\\rho_{w}^{2}\\right) K_{1}}\\right]\\right\\}\\\\ &amp;=\\max\\left\\{C_1\\frac{n}{(1-\\rho_w^2)^2}, C_2\\frac{n\\rho_w^2}{(1-\\rho_w^2)^2}+C_2\\frac{n}{1-\\rho_w^2}+C_3\\frac{n\\rho_w^2}{(1-\\rho_w^2)^2}\\right\\}\\\\ &amp;=\\mathcal{O}(\\frac{n}{(1-\\rho_w^2)^2}) \\end{align}\\] Recall \\(R&#39;(k)=U(k)+\\frac{1}{n}V(k)\\), from theorem 9.1, lemma 9.7, and lemma 9.8, we show \\[\\begin{equation} R&#39;(k)\\leq \\frac{\\theta^{2} \\sigma^{2}}{(1.5 \\theta-1) n \\mu^{2}} \\frac{1}{\\tilde{k}}+\\mathcal{O}\\left(\\frac{1}{\\left(1-\\rho_{w}^2\\right)^{2}}\\right) \\frac{1}{\\tilde{k}^{2}} \\tag{9.14} \\end{equation}\\] Next we improve the bound in theorem 9.1 9.2.3 Improved Bound In the derivation of theorem 9.1, we start from lemma 9.3, which is based on lemma 9.1. From lemma 9.1 to lemma 9.3, Cauchy-Schwartz inequality is used twice. Now we start directly from lemma 9.1 and do not introduce an arbitary \\(c&gt;0\\)(see (9.2)). Moreover, we consider the situation where \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\) and \\(k\\geq K_1-K\\). Then we have \\[\\begin{equation} \\tilde{U}(k+1) \\leq\\left(1-\\frac{2 \\theta}{k}\\right) \\tilde{U}(k)+\\frac{\\theta^{2} \\tilde{U}(k)}{k^{2}}+\\frac{2 \\theta L}{\\sqrt{n} \\mu} \\frac{\\sqrt{\\tilde{U}(k) \\tilde{V}(k)}}{k}+\\frac{\\theta^{2} L^{2}}{n \\mu^{2}} \\frac{\\tilde{V}(k)}{k^{2}}+\\frac{\\theta^{2} \\sigma^{2}}{n \\mu^{2}} \\frac{1}{k^{2}} \\end{equation}\\] We expand \\((1-\\frac{\\theta}{k})^2\\) to see the power of \\(\\frac{1}{k}\\) clearly. Then by induction, lemma 9.6, lemma 9.7, and similar bounding for the sums \\(\\sum\\limits_{t=K_1}^{k-1}\\frac{(t+1)^b}{t^a}\\), we have improved results for \\(R&#39;(k)=\\frac{1}{n} \\sum\\limits_{i=1}^{n} E\\left[\\left\\|x_{i}(k)-x^{*}\\right\\|^{2}\\right]\\). Theorem 9.2 For algorithm 7.1 with \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\), suppose \\(\\theta&gt;2\\), \\(\\sum\\limits_{i=1}^{n}\\left\\|x_{i}(0)-x^{*}\\right\\|^{2}=\\mathcal{O}(n) \\text { and } \\sum\\limits_{i=1}^{n}\\left\\|\\nabla f_{i}\\left(x^{*}\\right)\\right\\|^{2}=\\mathcal{O}(n)\\), then for \\(k\\geq K_1-K\\), \\[\\begin{align} R&#39;(k)\\leq \\frac{\\theta^{2} \\sigma^{2}}{(2 \\theta-1) n \\mu^{2} \\tilde{k}}+\\mathcal{O}\\left(\\frac{1}{\\sqrt{n}\\left(1-\\rho_{w}\\right)}\\right) \\frac{1}{\\tilde{k}^{1.5}}+\\mathcal{O}\\left(\\frac{1}{\\left(1-\\rho_{w}\\right)^{2}}\\right) \\frac{1}{\\tilde{k}^{2}} \\end{align}\\] 9.3 Transient time First we derive the convergence rate of centralized gradient descent 7.2. Similarly, we use lemma 9.2 and assumption 4.1, then \\[\\begin{align} &amp;E\\left[\\Vert x(k+1)-x^*\\Vert^2|x(k) \\right]\\\\ &amp;\\quad=E\\left[\\Vert x(k)-\\alpha_k\\nabla f(x(k))-x^*-\\alpha_k (\\tilde g(k)-\\alpha_k\\nabla f(x(k)))\\Vert^2-|x(k) \\right]\\\\ &amp;\\quad\\leq (1-\\alpha_k\\mu)^2\\Vert x(k)-x^*\\Vert^2+\\frac{\\alpha_k^2}{n^2}\\sum_{i=1}^nE\\left[\\Vert \\nabla f_i(x(k))-g_i(k)\\Vert^2|X(k)\\right]\\\\ &amp;\\quad\\leq (1-\\alpha_k\\mu)^2\\Vert x(k)-x^*\\Vert^2+\\frac{\\alpha_k^2\\sigma^2}{n} \\tag{9.15} \\end{align}\\] Take the full expetation on both sides in (9.15), we prove lemma 7.1 in chapter 7. Substitute \\(\\alpha=\\frac{1}{\\mu k}\\) in (9.15) and take full expetation on both sides, we have, \\[\\begin{equation} R(k+1) = \\left(1-\\frac{2 \\theta}{k}\\right)\\left\\|x(k)-x^{*}\\right\\|^{2}+\\frac{\\theta^{2}}{k^{2}}\\left\\|x(k)-x^{*}\\right\\|^{2}+\\frac{\\theta^{2} \\sigma^{2}}{n \\mu^{2}} \\frac{1}{k^{2}} \\end{equation}\\] First we show \\(\\exists c_3=\\mathcal{O}(\\frac{1}{n}),s.t. E\\left[\\Vert x(k)-x^*\\Vert^2\\right]\\leq \\frac{c_3}{k},\\forall k\\geq K_2:=\\left\\lceil\\frac{\\theta L}{\\mu}\\right\\rceil\\). Then by induction, lemma 9.6 and bound for the sums, we have the convergence rate for algorithm 7.2. Theorem 9.3 Under algorithm 7.2, suppose \\(k\\geq K_2\\), we have \\[ E\\left[\\left\\|x(k)-x^{*}\\right\\|^{2}\\right] \\leq \\frac{\\theta^{2} \\sigma^{2}}{(2 \\theta-1) n \\mu^{2} k}+\\mathcal{O}\\left(\\frac{1}{n}\\right) \\frac{1}{k^{2}} \\] Compare theorem 9.3 and theorem 9.2(or formula (9.14)), we derive the transient time \\(K_T=\\mathcal{O}(\\frac{n}{(1-\\rho_w^2)^2})\\) Corollary 9.1 (Transient Time) It takes \\(K_T=\\mathcal{O}(\\frac{n}{(1-\\rho_w^2)^2})\\) for algorithm 7.1 with \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)}\\) to reach the aymptotic rate of convergence of algorithm 7.2,i.e. when \\(k\\geq K_T\\), we have \\(\\frac{1}{n} \\sum_{i=1}^{n} E\\left[\\left\\|x_{i}(k)-x^{*}\\right\\|^{2}\\right] \\leq \\frac{\\theta^{2} \\sigma^{2}}{(2 \\theta-1) n \\mu^{2 k}} \\mathcal{O}(1)\\). Remark. From formula (9.14), we have \\[ R&#39;(k)\\leq \\frac{\\theta^{2} \\sigma^{2}}{ (2\\theta-1)n \\mu^{2}\\tilde k}\\left[\\frac{2\\theta-1}{1.5\\theta-1}+\\mathcal{O}\\left(\\frac{n}{\\left(1-\\rho_{w}^2\\right)^{2}}\\right) \\frac{1}{\\tilde{k}}\\right] \\] \\(\\theta&gt;2\\) is a constant, let \\[ \\mathcal{O}\\left(\\frac{n}{\\left(1-\\rho_{w}^2\\right)^{2}}\\right) \\frac{1}{K_T}=\\mathcal{O}(1) \\] we have \\[ K_T=\\mathcal{O}\\left(\\frac{n}{(1-\\rho_w^2)^2}\\right) \\] The above can also begin with theorem 9.2 Remark. \\[\\begin{align} \\frac{1}{(1-\\rho_w)^2} / \\frac{1}{(1-\\rho_w^2)^2}&amp;=\\left(\\frac{1-\\rho_w^2}{1-\\rho_w}\\right)^2\\\\ &amp;=(1+\\rho_w)^2 \\end{align}\\] where \\(\\rho_w&lt;1\\). Hence \\(\\mathcal{O}(\\frac{1}{(1-\\rho_w^2)^2})\\) and \\(\\mathcal{O}(\\frac{1}{(1-\\rho_w)^2})\\) have the same order. 9.4 Sharpness From wiki,the constraint is sharp (sometimes optimal) if it cannot be made more restrictive without failing in some cases. We show the transient time for DGS to reach the asymptotic convergence rate is lower bounded by \\(K_T=\\mathcal{O}\\left(\\frac{n}{(1-\\rho_w^2)^2}\\right)\\). 9.5 Summary Recall in chapter 7, we have (7.1), i.e. \\[\\begin{equation} \\text { Time }_{n, \\varepsilon} \\text { (decentralized) } \\leq p(\\mathcal{G}) \\text { Time }_{n, \\varepsilon} \\text { (centralized) } \\end{equation}\\] The corallary 9.1 indicates that for DSGD with \\(\\alpha_k=\\frac{\\theta}{\\mu(k+K)},\\theta&gt;2\\), when \\(k\\geq K_T\\), \\(p(\\mathcal{G})=\\mathcal{O}(1)\\), this is what we call asymptotic network independence. References "],
["comparison.html", "Chapter 10 comparison 10.1 Assumptions of different schemes 10.2 Convergence rate", " Chapter 10 comparison We consider DSGT(Pu and Nedić 2018), DSGD(Pu, Olshevsky, and Paschalidis 2019a), DGD, EXTRA(Shi et al. 2015), D-PSGD(Lian et al. 2017) and \\(D^2\\)(Tang et al. 2018) here. Generally, EXTRA, DSGT, and \\(D^2\\) achieve better convergence properties because of adding some correction terms. The following table lists the schemes of these algorithms. Name Scheme c-SGD \\(x_{k+1}=x_k-\\alpha_k\\tilde g(k)\\) DGD \\(X_{k+1}=WX_k-\\alpha_k\\nabla f(X_k)\\) D-PSGD \\(X_{k+1}=WX_{k}-\\alpha G_k\\) EXTRA \\(X_{k+1}=WX_k-\\alpha \\nabla f(X_k)+\\sum\\limits_{t=0}^{k-1}(W-\\tilde W)X_t\\) DSGD \\(X_{k+1}=W(X_k-\\alpha_{k}G_k)\\) DSGT \\[X_{k+1}=W(X_k-\\alpha_k Y_k)\\\\Y_{k+1}=WY_k+G_{k+1}-G_k\\] \\(D^2\\) \\[X_1=W(X_0-\\alpha G_0)\\\\X_{k+1}=W(X_k-\\alpha G_k)+W(X_k-X_{k-1}-\\alpha G_{k-1})\\] To see the influence of the correction term \\(H\\), suppose we have a scheme, \\[\\begin{equation} X_{k+1}=W(X_k-\\alpha_k G_k+H) \\tag{10.1} \\end{equation}\\] We assume \\(X_k\\) has achieved the optimum \\(X_k=\\mathbf{1}{x^*}\\), then from \\(W\\mathbf{1}=\\mathbf{1}\\), we have \\[\\begin{align} X_{k+1}=\\mathbf{1}x^*-\\alpha_kWG_k+WH \\end{align}\\] Thus \\(nR&#39;(k+1)=E\\left[\\Vert X_{k+1}-\\mathbf{1}x^*\\Vert^2\\right]\\) is affected by \\[ E\\left[\\Vert H-\\alpha_k G_k\\Vert^2\\right] \\] Similar for DSGD, we have \\(nR&#39;(k+1)\\) is affected by \\[ E\\left[\\Vert\\alpha_k G_k\\Vert^2 \\right]=\\alpha_k E\\left[\\Vert G_k\\Vert^2 \\right] \\] We can see that a sequence of dimishing \\(\\alpha_k\\) can decrease \\(E\\left[\\Vert G_k\\Vert^2 \\right]\\) as \\(k\\) gets large, which explains why dimishing stepsizes can improve fixed stepsize scheme to an exact convergence. On the other hand, we can also design a distributed algorithm \\(s.t.\\) \\[\\begin{equation} E\\left[\\Vert H-\\alpha_k G_k\\Vert^2\\right]\\leq \\left[\\Vert\\alpha_k G_k\\Vert^2 \\right] \\tag{10.2} \\end{equation}\\] and conserve the consensus property. 10.1 Assumptions of different schemes The following table summarizes the assumptions needed for each schemes. The column of \\(\\sigma^2\\) and \\(\\zeta^2\\) denote \\[ E_{\\xi }\\left\\|g_{i}(x ; \\xi)-\\nabla f_{i}(x)\\right\\|^{2} \\leqslant \\sigma^{2}, \\quad \\forall i, \\forall x \\] and \\[ \\frac{1}{n} \\sum_{i=1}^{n}\\left\\|\\nabla f_{i}(x)-\\nabla f(x)\\right\\|^{2} \\leqslant \\zeta^{2}, \\quad \\forall i, \\forall x \\] respectively. \\(\\zeta_0=\\frac{1}{n} \\sum\\limits_{i=1}^{n}\\left\\|\\nabla f_{i}(\\mathbf{0})-\\nabla f(\\mathbf{0})\\right\\|^{2}\\); \\(\\rho_w\\) is the spectral norm of \\(W-\\frac{\\mathbf{1}\\mathbf{1}^T}{n}\\) Name \\(f_i(x)\\) \\(\\nabla f_i(x)\\) \\(W\\) Spectral gap \\(\\sigma^2\\) \\(\\zeta^2\\) c-SGD Lipschitz continuous \\(\\backslash\\) \\(\\backslash\\) \\(\\backslash\\) \\(\\backslash\\) DGD Lipschitz continuous Sym and \\(W\\mathbf{1}=\\mathbf{1}\\) \\(\\rho_w&lt;1\\) \\(\\backslash\\) \\(\\backslash\\) D-PSGD Lipschitz continuous Sym and doubly stochastic \\(\\lambda_2^2&lt;1\\) Y Y EXTRA convex (\\(f\\) strongly convex leads to better rate) Lipschitz continuous Sym and \\(W\\mathbf{1}=\\mathbf{1}\\) \\(\\lambda_\\min(W)\\geq0\\) \\(\\backslash\\) \\(\\backslash\\) DSGD strongly convex Lipschitz continuous Sym and doubly stochastic \\(\\rho_w\\) Y N DSGT strongly convex Lipschitz continuous doubly stochastic \\(\\rho_w\\) Y N \\(D^2\\) Lipschitz continuous Sym and \\(W\\mathbf{1}=\\mathbf{1}\\) \\(\\lambda_2&lt;1,\\lambda_\\min\\geq-\\frac{1}{3}\\) Y \\(\\zeta_0\\) Remark. \\ EXTRA assumes a less restrictive assumption on \\(W\\) which leads to \\(W\\mathbf{1}=\\mathbf{1}\\) and \\(\\lambda(W)\\in(-1, 1]\\); In EXTRA, if \\(\\lambda_{\\min}(W)&lt;0\\), we can replace \\(W\\) by \\(\\frac{I+W}{2}\\); In EXTRA, if we assume \\(g(x)=\\frac{1}{n}\\sum\\limits_{i=1}^n f_i(x) + \\frac{1}{4\\alpha}\\Vert x\\Vert_{\\tilde{W}-W}\\) is restricted strongly convex w.r.t. \\(x^*\\), we can derive a convergence rate \\(\\mathcal{O}(1+\\delta)^{-k}\\). This conditon does not require all \\(f_i\\) to be individually restricted strongly convex, which is less restrictive to that in DSGT and DSGD. DSGD addtionally assume \\(\\sum\\limits_{i=1}^{n}\\left\\|x_{i}(0)-x^{*}\\right\\|^{2}=\\mathcal{O}(n)\\) and \\(\\sum\\limits_{i=1}^{n}\\left\\|\\nabla f_{i}\\left(x^{*}\\right)\\right\\|^{2}=\\mathcal{O}(n)\\); \\(D^2\\) is less senstive to the data variance across workers compared to D-PSGD options: What is the convergence rate when assuming \\(f_i\\) to be strongly convex in \\(D^2\\)? Li, Shi, and Yan (2019) assume a sturcture of \\(f_i(x)=s_i(x)+r_i(x)\\) on the objective function, where \\(s_i\\) is differentiable and has a Lipschitz continuous gradient with parameter \\(L\\) and \\(r_i\\) is proximable. They improve The PG-EXTRA in the speed and the dependency of convergence over networks. If we assume the same structure on DSGT or DSGD, what is the convergence rate? 10.2 Convergence rate The following table lists the convergence rate of the above algorithms. Name nonconvex convex strongly convex c-SGD \\(\\mathcal{O}(\\frac{1}{\\sqrt{nT}}+\\frac{1}{T})\\) \\(\\mathcal{O}(\\frac{1}{nk}+\\frac{1}{k^2})\\) DGD \\(\\mathcal{O}\\left(\\frac{\\ln k}{\\sqrt{k}}\\right)\\) D-PSGD \\(\\mathcal{O}\\left(\\frac{\\sigma}{\\sqrt{n T}}+\\frac{n^{\\frac{1}{4}} \\zeta^{\\frac{2}{3}}}{T^{\\frac{2}{3}}}+\\frac{1}{T}\\right)\\) EXTRA \\(\\mathcal{O}(\\frac{1}{k})\\) \\(\\mathcal{O}((1+\\delta)^{-k})\\) DSGD \\(\\mathcal{O}\\left(\\frac{1}{nk}+\\frac{1}{k^{1.5}}+\\frac{1}{k^2}\\right)\\) DSGT \\(\\mathcal{O}\\left(\\frac{1}{nk} +\\frac{1}{k^{\\theta\\mu}}+\\frac{1}{k^2} \\right)\\) \\(D^2\\) \\(\\mathcal{O}\\left(\\frac{\\sigma}{\\sqrt{n T}}+\\frac{1}{T}+\\frac{\\zeta_{0}^{2}}{T+\\sigma^{2} T^{2}}+\\frac{\\sigma^2}{1+\\sigma^2T}\\right)\\) DSGT converges to the neighborhood of \\(x^*\\) at the linear rate of \\(\\rho(A)^k\\) when choosing fixed \\(\\alpha\\) and converges to \\(x^*\\) when choosing \\(\\alpha_k=\\frac{\\theta}{m+k}\\). This implies us to choose stepsize adaptively. References "],
["sec-ediff.html", "Chapter 11 Exact diffusion 11.1 Decreasing stepsize", " Chapter 11 Exact diffusion Consider the following problem, \\[\\begin{equation} x^*=\\underset{x\\in\\mathbb{R}^p}{\\arg\\min}\\sum_{i=1}^nf_i(x)\\left(=E_{\\xi_i}Q(x,\\xi_i)\\right) \\tag{11.1} \\end{equation}\\] The noisy gradient \\(\\nabla Q(x_{i,k},\\xi_{i,k})\\) is more concrete than the \\(g(x_{i,k},\\xi_{i,k})\\) we use in the previous chapters, like chapter 4. In the following, we use \\(g(x_{i,k},\\xi_{i,k})=\\nabla Q(x_{i,k},\\xi_{i,k})\\). We focus on the class of diffusion strategies here. The exact diffusion and the traditional diffusion strategy(take adapt-then-conbine formulartion of diffusion as an example) can be seen in the following table, Name Scheme adapt-then-combine of diffusion \\[X_{k+\\frac{1}{2}}=X_{k}-\\alpha\\nabla G(X_k,\\boldsymbol\\xi_k)(\\text{adaptation})\\\\X_{k+1}=WX_{k+\\frac{1}{2}}(\\text{combination})\\] exact diffusion(stochastic version) \\[X_{k+\\frac{1}{3}}=X_{k}-\\alpha G(X_k,\\boldsymbol\\xi_k)(\\text{adaptation})\\\\X_{k+\\frac{2}{3}}=X_{k+\\frac{1}{3}}+X_k-X_{k-1+\\frac{1}{3}}(\\text{correction})\\\\X_{k+1}=WX_{k+\\frac{2}{3}}(\\text{combination})\\] The performance of bias-correction methods under stochastic and adaptive settings remain unclear. Yuan et al. (2019) show that the correction-step in exact diffusion leads to better standy-state performance under stochastic scenarios. The exact diffusion assume each \\(f_i\\) to be differentiable and \\(\\mu-\\)strongly convex. Under sufficiently small step sizes \\(\\alpha\\), the exact diffusion converges exponentially at the rate \\(1-\\mathcal{O}(\\alpha\\mu)\\) to a neiborhood of \\(x^*\\), which can be characterized as \\[\\begin{equation} \\underset{k\\to \\infty}{\\lim\\sup}\\frac{1}{n}E\\left[\\Vert X_k-\\mathbf{1}x^*\\Vert^2\\right]_{ed} =\\mathcal{O}\\left(\\frac{\\alpha\\bar\\sigma^2}{n\\mu}+\\frac{\\delta^2}{n\\mu^2}\\cdot\\frac{\\alpha^2\\bar\\sigma^2}{1-\\lambda}\\right) \\tag{11.2} \\end{equation}\\] In comparison, the traditional diffusion strategy converges at the similar rate to the following neighborhood of \\(x^*\\), \\[\\begin{equation} \\underset{k\\to \\infty}{\\lim\\sup}\\frac{1}{n}E\\left[\\Vert X_k-\\mathbf{1}x^*\\Vert^2\\right]_{d} =\\mathcal{O}\\left(\\frac{\\alpha\\bar\\sigma^2}{n\\mu}+\\frac{\\delta^2}{n\\mu^2}\\cdot(\\frac{\\alpha^2\\bar\\sigma^2}{1-\\lambda}+ \\frac{\\alpha^2b^2}{(1-\\lambda)^2})\\right) \\tag{11.3} \\end{equation}\\] where \\(\\bar\\sigma^2\\) measures the size of gradient noise,\\(\\delta\\) bounds the hessian matrix of \\(f_i\\), \\(b^2=\\sum\\limits_{i=1}^n\\Vert \\nabla f_i(x^*)\\Vert^2\\), and \\(\\lambda=\\max\\{|\\lambda_2(W)|,|\\lambda_n(W)|\\}\\in(0,1)\\) stands for the spectral gap. Assumption11.1 Each \\(f_i\\) is \\(\\mu-\\)strongly convex and twice differentiable, and \\[ \\mu I_p\\leq\\nabla^2 f_i(x)\\leq\\delta I_p \\] We have a more smooth function \\(f_i\\) here compared to assuming \\(\\nabla f_i\\) is \\(L-\\)Lipschitz continuous. Assumption11.2 The network is undirected and stronly connected, and the mixing matrix \\(W\\) is symmetric and doubly-stochastic For the noisy gradient, we assume differently compared to assumption 4.1, where awe assume the variance of the noisy gradient can be bound be a uniform \\(\\sigma^2\\). Assumption11.3 Each agent \\(i\\) and the iteration step \\(k\\), we have, \\[\\begin{align} E\\left[\\nabla g(x_{i,k},\\xi_{i,k})|\\mathcal{F}_{k-1}\\right]&amp;=\\nabla f_i(x_{i,k})\\\\ E\\left[\\Vert \\nabla g(x_{i,k},\\xi_{i,k})-\\nabla f_i(x_{i,k})\\Vert^2|\\mathcal{F}_{k-1}\\right]&amp;\\leq \\beta_i\\Vert x_{i,k-1}-x^*\\Vert^2 + \\sigma^2_i \\end{align}\\] \\(\\bar\\sigma^2=\\frac{1}{n}\\sum_{i=1}^n\\sigma_i^2\\) Compare the two characterization (11.2) and (11.3), we see that the exact diffusion outperforms the traditional diffusion strategy in the following, The exact diffusion removes the bias \\(\\frac{\\alpha^2b^2}{(1-\\lambda^2)}\\) When we can obtain the exact gradient(deterministic setting), i.e. \\(\\sigma_i^2=0,i=1,2,...,n\\), the exact diffusion converge exactly to \\(x^*\\). When the bias \\(\\frac{\\alpha^2b^2}{(1-\\lambda^2)}\\) is significant, i.e. \\(b^2\\) is large or the network is badly-connected(i.e. \\(\\lambda\\) is close to 1), and the step size is not sufficiently small(\\(\\alpha\\leq d_3(1-\\lambda)^{(2+y)},y&gt;0\\)), the exact diffusion outperforms the traditional one. 11.1 Decreasing stepsize Here we can derive the information of Hessian matrices of \\(f_i,i=1,2,...,n\\), then let \\(\\tilde x_{i,k}=x^*-x_{i,k}\\) we have, \\[\\begin{equation} \\nabla f_i(x_{i,k})-\\nabla f_i(x^*)=-H_{i,k}\\tilde x_{i,k} \\end{equation}\\] where \\[\\begin{equation} H_{i,k}=\\int_{0}^1\\nabla^2 f_i(x^*-r\\tilde x_{i,k})dr\\in\\mathbb{R}^{p\\times p} \\end{equation}\\] then we can denote \\[\\begin{equation} \\nabla F(X_k)-\\nabla F(\\mathbf{1}x^*):= -\\left( \\begin{array}{c} (H_{1,k}\\tilde x_{1,k})^T\\\\ \\vdots\\\\ (H_{n,k}\\tilde x_{n,k})^T \\end{array}\\right) \\in\\mathbb{R}^{n,p} \\end{equation}\\] However, this notation cannot have the form of \\(\\mathcal{H}_k\\tilde X_k\\), which helps us to separate the Hessian matrices and the iterated values. To ensure such an advantage, we stack the local vairables of different agents as a long vector, i.e., \\[\\begin{equation} \\mathcal{X}_k = \\left( \\begin{array}{c} x_{1,k}\\\\ x_{2,k}\\\\ \\vdots\\\\ x_{n,k} \\end{array}\\right):=\\mathrm{col}\\{x_{1,k},...,x_{n,k}\\}\\in\\mathbb{R}^{np} \\end{equation}\\] Similarly, we denote \\(\\mathcal{G}_k:=\\mathrm{col}\\{g_1(x_{1,k},\\xi_{1,k}),...,g_n(x_{n,k},\\xi_{n,k})\\}\\). Then the exact diffusion with decreasing stepsize \\(\\alpha_k\\) can be rewritten globally as the following, \\[\\begin{align} \\mathcal{X}_{k+1} &amp;= \\overline{\\mathcal{W}} (2 \\mathcal{X}_k-\\mathcal{X}_{k-1}-\\alpha_k\\mathcal{G}_k+\\alpha_{k-1}\\mathcal{G}_{k-1})\\\\ \\mathcal{X}_1&amp;=\\overline{\\mathcal{W}} (\\mathcal{X}_0-\\alpha_0\\mathcal{G}_0),\\mathcal{X}_0=\\mathbf{0} \\tag{11.4} \\end{align}\\] where \\(\\overline{\\mathcal{W}}=(\\mathcal{W}+I_{np})/2\\), \\(\\mathcal{W}=W\\otimes I_{p}\\in\\mathbb{R}^{np\\times np}\\). Essentially, exact diffusion is a primal-dual method. Since \\(W\\) is symmetric and doubly-stochastic, then so does \\(\\overline W\\), thus \\(I_n-\\overline W\\) is positive semi-definite(p.s.d.) and symmetric, we have spectral decomposition \\(I_n-\\overline W = U\\Sigma U^T:=V^2\\). Let \\(\\mathcal{V}=V\\otimes I_p\\), then \\(\\mathcal{V}^2=I_{np}-\\overline{\\mathcal{W}}\\), we have the primal-dual version of exact diffusion (11.5). \\[\\begin{equation} \\begin{cases} \\mathcal{X}_{k+1}=\\overline{\\mathcal{W}}\\left(\\mathcal{X}_k-\\alpha_k\\mathcal{G}_k\\right)-\\mathcal{V}\\mathcal{Y}_k\\\\ \\mathcal{Y}_{k+1}=\\mathcal{Y}_k+\\mathcal{V}\\mathcal{X}_{k+1} \\end{cases} \\tag{11.5} \\end{equation}\\] This is because, \\[\\begin{align} \\mathcal{X}_{k+1}-\\mathcal{X}_{k}&amp;=\\overline{\\mathcal{W}}\\left(\\mathcal{X}_{k}-\\mathcal{X}_{k-1}-\\alpha_k\\mathcal{G}_k +\\alpha_{k-1}\\mathcal{G}_{k-1}\\right)-\\mathcal{V}\\mathcal{Y}_k+\\mathcal{V}\\mathcal{Y}_{k-1}\\\\ &amp;=\\overline{\\mathcal{W}}\\left(\\mathcal{X}_{k}-\\mathcal{X}_{k-1}-\\alpha_k\\mathcal{G}_k +\\alpha_{k-1}\\mathcal{G}_{k-1}\\right)-\\mathcal{V}(\\mathcal{Y}_{k-1}+\\mathcal{V}\\mathcal{X}_k)+\\mathcal{V}\\mathcal{Y}_{k-1}\\\\ &amp;=\\overline{\\mathcal{W}} (2 \\mathcal{X}_k-\\mathcal{X}_{k-1}-\\alpha_k\\mathcal{G}_k+\\alpha_{k-1}\\mathcal{G}_{k-1})-\\mathcal{X}_{k} \\end{align}\\] We can also have \\(\\mathcal{Y}_k=\\mathcal{Y}_0+\\mathcal{V}\\sum\\limits_{i=1}^k \\mathcal{X}_i\\). Let \\(\\nabla\\mathcal{J}(\\mathcal{X}_k):=\\mathrm{col}\\{\\nabla f_1(x_{1,k}),...,\\nabla f_n(x_{n,k})\\}\\), then lemma 11.1 states the optimality condition for problem (11.1). Lemma 11.1 Under assumption 11.1, if some vectors \\((\\mathcal{X}^*,\\mathcal{Y}^*)\\) exist that satisfy: \\[\\begin{align} \\alpha_k\\overline{\\mathcal{W}}\\nabla J(\\mathcal{X}^*)+\\mathcal{V}\\mathcal{Y}^*&amp;=\\mathbf{0}\\\\ \\mathcal{V}\\mathcal{X}^*=\\mathbf{0} \\end{align}\\] where\\(\\mathcal{X}^*=\\mathrm{\\{x_1^*,...,x_n^*\\}}\\), then it holds that \\[ x_1^*=x_2^*=\\cdots=x_n^*=x^* \\] where the \\(x^*\\) is the unique solution to problem (11.1). We follow the proof in (Yuan et al. 2018), where the authors prove the situation with different stepsizes for each agents and the objective function is a weighted average of \\(f_i\\). First, according to \\(\\mathrm{null}(\\mathcal{V})=\\mathrm{span}\\{\\mathbf{1}_n\\otimes I_p\\}\\), \\[\\begin{align} 0=\\mathcal{V}\\mathcal{X}^*\\Longleftrightarrow \\mathcal{X}^*\\in\\mathrm{null}(\\mathcal{V}) \\end{align}\\] so, \\(x_1^*=x_2^*=\\cdots=x_n^*\\). Additionally, let \\(\\mathcal{I}=\\mathbf{1}_n\\otimes I_p\\) and multiply \\(\\mathcal{I}^T\\) on both sides of \\(\\alpha_k\\overline{\\mathcal{W}}\\nabla J(\\mathcal{X}^*)+\\mathcal{V}\\mathcal{Y}^*=\\mathbf{0}\\). Since \\(\\mathcal{V}\\) is symmetric and \\(\\mathcal{V}\\mathcal{I}=\\mathbf{0}\\), we have \\[\\begin{align} \\alpha_k\\mathcal{I}^T\\overline{\\mathcal{W}}\\nabla J(\\mathcal{X}^*)&amp;=\\alpha_k(\\mathbf{1}_n\\otimes I_p)^T(\\overline{W}\\otimes I_p)\\nabla J(\\mathcal{X}^*)\\\\ &amp;=\\alpha_k(\\mathbf{1}^T\\otimes I_p)(\\overline{W}\\otimes I_p)\\nabla J(\\mathcal{X}^*)\\\\ &amp;=\\alpha_k(\\mathbf{1}_n\\overline{W})\\otimes (I_pI_p)\\nabla J(\\mathcal{X}^*)\\\\ &amp;=\\alpha_k(\\mathbf{1}_n^T\\otimes I_p)\\nabla J(\\mathcal{X}^*)\\\\ &amp;=\\alpha_k\\sum_{i=1}^n\\nabla f_i(x_i^*)\\\\ &amp;=0 \\end{align}\\] where we use the column stochastic property of \\(\\overline W\\). \\(\\sum\\limits_{i=1}^n\\nabla f_i(x_i^*)=0\\) implies that \\(x_1^*=\\cdots=x_n^*\\) must coincide with the minimizer \\(x^*\\) of problem (11.1). We can also see from the above proof that changing the stepsize from fixed \\(\\alpha\\) to decreasing \\(\\alpha_k\\) does not violate too much(will condtions in lemma 11.1 requires too much?). From lemma 11.1, we have the following error dynamics, \\[\\begin{equation} \\begin{cases} \\tilde{\\mathcal{X}}_{k+1}=\\overline{\\mathcal{W}}\\left[\\tilde{\\mathcal{X}_{k}}+\\alpha_k(\\nabla \\mathcal{J}(\\mathcal{X}_k)-\\nabla \\mathcal{J}(\\mathcal{X}^*))\\right]-\\mathcal{V}\\tilde{\\mathcal{Y}_k}+\\alpha_k\\overline{\\mathcal{W}}\\mathcal{S}_k(\\mathcal{X}_k)\\\\ \\tilde{\\mathcal{Y}}_{k+1}=\\tilde{\\mathcal{Y}_{k}}+\\mathcal{V}\\tilde{\\mathcal{X}}_{k+1} \\end{cases} \\tag{11.6} \\end{equation}\\] Where \\(\\mathcal{S}_k(\\mathcal{X}_k)=\\mathcal{G}_k-\\nabla \\mathcal{J}(\\mathcal{X}_k)\\), \\(\\tilde{\\mathcal{X}}_k:=\\mathcal{X}^*-\\mathcal{X}_k\\), and \\(\\tilde{\\mathcal{Y}}_k:=\\mathcal{Y}^*-\\mathcal{Y}_k\\). Proof. From \\(\\mathcal{V}\\mathcal{X}^*=0\\), we have \\(0=\\mathcal{V}^2\\mathcal{X}^*=(I_{np}-\\overline{\\mathcal{W}})\\mathcal{X}^*\\), hence \\(\\mathcal{X}^*=\\overline{\\mathcal{W}}\\mathcal{X}^*\\), then \\[\\begin{align} \\tilde{\\mathcal{X}}_{k+1}&amp;=\\mathcal{X}^*-\\mathcal{X}_{k+1}\\\\ &amp;=\\overline{\\mathcal{W}}\\mathcal{X}^*-\\overline{\\mathcal{W}}\\left(\\mathcal{X}_k-\\alpha_k\\mathcal{G}_k\\right)+\\mathcal{V}\\mathcal{Y}_k\\\\ &amp;=\\overline{\\mathcal{W}}\\left[\\tilde{\\mathcal{X}}_{k}+\\alpha_k(\\nabla\\mathcal{J}(\\mathcal{X}_k)-\\nabla \\mathcal{J}(\\mathcal{X}^*))\\right]+\\alpha_k\\overline{\\mathcal{W}}\\mathcal{S}_k(\\mathcal{X}_k)+\\alpha_k\\overline{\\mathcal{W}}\\nabla \\mathcal{J}(\\mathcal{X}^*)+\\mathcal{V}\\mathcal{Y}_k\\\\ &amp;=\\overline{\\mathcal{W}}\\left[\\tilde{\\mathcal{X}}_{k}+\\alpha_k(\\nabla\\mathcal{J}(\\mathcal{X}_k)-\\nabla \\mathcal{J}(\\mathcal{X}^*))\\right]-\\mathcal{V}\\tilde{\\mathcal{Y}_k}+\\alpha_k\\overline{\\mathcal{W}}\\mathcal{S}_k(\\mathcal{X}_k) \\end{align}\\] Remark. In the above proof, we use the condition \\(\\alpha_k\\overline{\\mathcal{W}}\\nabla J(\\mathcal{X}^*)+\\mathcal{V}\\mathcal{Y}^*=\\mathbf{0}\\) in lemma 11.1 so that we can have \\(\\alpha_k\\overline{\\mathcal{W}}\\nabla \\mathcal{J}(\\mathcal{X}^*)=-mathcal{V}\\mathcal{Y}^*\\). On the other hand, if requiring the condtions in lemma 11.1 are satisfied for each \\(k\\in\\mathbb{N}\\) is too strong, we may instead require \\(\\overline{\\mathcal{W}}\\nabla J(\\mathcal{X}^*)+\\mathcal{V}\\mathcal{Y}^*=\\mathbf{0}\\\\ \\mathcal{V}\\mathcal{X}^*=\\mathbf{0}\\), which also leads to \\(\\sum\\limits_{i=1}^n\\nabla f_i(x_i^*)=0\\). Then the error dynamics should be \\[\\begin{align} \\tilde{\\mathcal{X}}_{k+1}&amp;=\\overline{\\mathcal{W}}\\left[\\tilde{\\mathcal{X}}_{k}+\\alpha_k(\\nabla \\mathcal{J}(\\mathcal{X}_k)-\\nabla \\mathcal{J}(\\mathcal{X}^*))\\right]-\\mathcal{V}\\tilde{\\mathcal{Y}_k}+\\alpha_k\\overline{\\mathcal{W}}\\mathcal{S}_k(\\mathcal{X}_k)+(1-\\alpha_k)\\mathcal{V}\\mathcal{Y}^*\\\\ &amp;=\\overline{\\mathcal{W}}\\left[\\tilde{\\mathcal{X}}_{k}+\\alpha_k(\\nabla \\mathcal{J}(\\mathcal{X}_k)-\\nabla \\mathcal{J}(\\mathcal{X}^*))\\right]-\\mathcal{V}\\tilde{\\mathcal{Y}_k}+\\alpha_k\\overline{\\mathcal{W}}\\mathcal{S}_k(\\mathcal{X}_k)-(1-\\alpha_k)\\overline{W}\\nabla \\mathcal{J}(\\mathcal{X}^*) \\end{align}\\] Then we can see a nice property of using the above notation as we have mentioned at the beginning. Let \\[\\begin{equation} \\mathcal{H}_k=\\mathrm{diag}\\{H_{1,k},...,H_{n,k}\\}\\in\\mathbb{R}^{np\\times np} \\end{equation}\\] Then \\(\\nabla \\mathcal{J}(\\mathcal{X}_k)-\\nabla \\mathcal{J}(\\mathcal{X}^*)=-\\mathcal{H}_k\\tilde{\\mathcal{X}}_k\\), the error dynamics (11.6) become \\[\\begin{equation} \\begin{cases} \\tilde{\\mathcal{X}}_{k+1}=\\overline{\\mathcal{W}}\\left(\\tilde{\\mathcal{X}_{k}}-\\alpha_k\\mathcal{H}_k\\tilde{\\mathcal{X}_k}\\right)-\\mathcal{V}\\tilde{\\mathcal{Y}_k}+\\alpha_k\\overline{\\mathcal{W}}\\mathcal{S}_k(\\mathcal{X}_k)\\\\ \\tilde{\\mathcal{Y}}_{k+1}=\\tilde{\\mathcal{Y}_{k}}+\\mathcal{V}\\tilde{\\mathcal{X}}_{k+1} \\end{cases} \\tag{11.7} \\end{equation}\\] We can further write the above (11.7) as the matrix form, \\[\\begin{align} \\left( \\begin{array}{c} \\tilde{\\mathcal{X}_{k+1}}\\\\ \\tilde{\\mathcal{Y}_{k+1}}\\\\ \\end{array} \\right) &amp;= \\left(\\begin{array}{cc} \\overline{\\mathcal{W}}&amp;-\\mathcal{V}\\\\ \\mathcal{V}\\overline{\\mathcal{W}}&amp;\\overline{\\mathcal{W}} \\end{array} \\right) \\left[ \\left(\\begin{array}{cc} I_{np}&amp;0\\\\ 0&amp;I_{np} \\end{array} \\right) - \\alpha_k\\left(\\begin{array}{cc} \\mathcal{H}_k&amp;0\\\\ 0&amp;0 \\end{array} \\right) \\right] \\left( \\begin{array}{c} \\tilde{\\mathcal{X}_{k}}\\\\ \\tilde{\\mathcal{Y}_{k}}\\\\ \\end{array} \\right) +\\alpha_k \\left( \\begin{array}{c} \\overline{\\mathcal{W}}\\\\ \\mathcal{V}\\overline{\\mathcal{W}}\\\\ \\end{array} \\right) \\mathcal{S}_k(\\mathcal{X}_k) \\\\ &amp;:=\\mathcal{B}(I_{2np}-\\alpha_k\\mathcal{T}_k) \\left( \\begin{array}{c} \\tilde{\\mathcal{X}_{k}}\\\\ \\tilde{\\mathcal{Y}_{k}}\\\\ \\end{array} \\right) +\\alpha_k \\mathcal{B}_l \\mathcal{S}_k(\\mathcal{X}_k) \\tag{11.8} \\end{align}\\] Note that \\[\\begin{equation}\\mathcal{B}_l=\\mathcal{B}\\left( \\begin{array}{c} I_{np}\\\\ I_{np} \\end{array} \\right) \\end{equation}\\] and for \\(\\mathcal{B}\\) we have the following decomposition(see (Yuan et al. 2018)). In general, the following decomposition is a eigendecomposition. Lemma 11.2 Under assumptions 11.1 and 11.2, the matrix \\(\\mathcal{B}\\) can be decomposed as \\[\\begin{align} \\mathcal{B}&amp;= \\left(\\mathcal{R}_1,\\mathcal{R}_2,c\\mathcal{K}_R\\right)\\mathrm{diag}(I_p,I_p,\\mathcal{D}_1) \\left( \\begin{array}{c} \\mathcal{L}_1^T\\\\ \\mathcal{L}_2^T\\\\ \\frac{1}{c}\\mathcal{K}_L \\end{array} \\right)\\\\ &amp;:=\\mathcal{K}\\mathcal{D}\\mathcal{K}^{-1} \\end{align}\\] \\(\\forall c&gt;0\\), and \\[\\begin{align} &amp;\\mathcal{R}_{1}=\\left(\\begin{array}{l} \\mathcal{I} \\\\ 0 \\end{array}\\right) \\in \\mathbb{R}^{2 n p \\times p}, \\quad \\mathcal{R}_{2}=\\left(\\begin{array}{l} 0 \\\\ \\mathcal{I} \\end{array}\\right) \\in \\mathbb{R}^{2 n p \\times p}\\\\ &amp;\\mathcal{L}_{1}=\\left(\\begin{array}{c} \\frac{1}{n} \\mathcal{I} \\\\ 0 \\end{array}\\right) \\in \\mathbb{R}^{2 n p \\times p},\\quad \\mathcal{L}_{2}=\\left(\\begin{array}{c} 0 \\\\ \\frac{1}{n} \\mathcal{I} \\end{array}\\right) \\in \\mathbb{R}^{2 n p\\times p}\\\\ &amp;\\mathcal{K}_R= \\left( \\begin{array}{c} \\mathcal{K}_{R,u}\\\\ \\mathcal{K}_{R,l} \\end{array} \\right)\\in\\mathbb{R}^{2np\\times 2(n-1)p},\\\\ &amp;\\mathcal{K}_L=(\\mathcal{K}_{L,l},\\mathcal{K}_{L,r})\\in\\mathbb{R}^{2(n-1)p\\times 2np} \\end{align}\\] where \\(\\mathcal{I}=\\mathbf{1}_n\\otimes I_p\\in\\mathbb{R}^{np\\times p}\\) From the error dynamics (11.8) and the decomposition of \\(\\mathcal{B}\\), multiply \\(\\mathcal{K}^{-1}\\) on the both sides of (11.8), we have, \\[\\begin{align} \\mathcal{K}^{-1} \\left( \\begin{array}{c} \\tilde{\\mathcal{X}_{k+1}}\\\\ \\tilde{\\mathcal{Y}_{k+1}}\\\\ \\end{array} \\right)&amp;:= \\left( \\begin{array}{c} \\bar z_{k+1}\\\\ \\hat z_{k+1}\\\\ \\check z_{k+1} \\end{array} \\right)\\\\ &amp;= \\mathcal{D}(\\mathcal{K}^{-1}I_{2np}\\mathcal{K}-\\alpha_k\\mathcal{K}^{-1}\\mathcal{T}_k\\mathcal{K})\\mathcal{K}^{-1} \\left( \\begin{array}{c} \\tilde{\\mathcal{X}_{k}}\\\\ \\tilde{\\mathcal{Y}_{k}}\\\\ \\end{array} \\right) + \\alpha_k\\mathcal{K}^{-1}\\mathcal{B}_l\\mathcal{S}_k(\\mathcal{X}_k)\\\\ &amp;= \\mathcal{D}(I_{2np}-\\alpha_k\\mathcal{K}^{-1}\\mathcal{T}_k\\mathcal{K}) \\left( \\begin{array}{c} \\bar z_{k}\\\\ \\hat z_{k}\\\\ \\check z_{k} \\end{array} \\right) + \\alpha_k\\mathcal{K}^{-1}\\mathcal{B}_l\\mathcal{S}_k(\\mathcal{X}_k) \\end{align}\\] Moreover, \\[\\begin{align} \\mathcal{K}^{-1}\\mathcal{T}_k\\mathcal{K}&amp;= \\left( \\begin{array}{cc} \\frac{1}{n}\\mathcal{I}^T&amp;0\\\\ 0&amp;\\frac{1}{n}\\mathcal{I}^T\\\\ \\frac{1}{c}\\mathcal{K}_{L,l}&amp;\\frac{1}{c}\\mathcal{K}_{L,r} \\end{array} \\right) \\left( \\begin{array}{cc} \\mathcal{H}_k&amp;0\\\\ 0&amp;0 \\end{array} \\right) \\left( \\begin{array}{ccc} \\mathcal{I}&amp;0&amp;c\\mathcal{K}_{R,u}\\\\ 0&amp;\\mathcal{I}&amp;c\\mathcal{K}_{R,l} \\end{array} \\right)\\\\ &amp;=\\left(\\begin{array}{ccc} \\frac{1}{n} \\mathcal{I}^T \\mathcal{H}_{k}\\mathcal{I} &amp; 0 &amp; \\frac{c}{n} \\mathcal{I}^T\\mathcal{H}_k\\mathcal{K}_{R,u} \\\\ 0 &amp; 0 &amp; 0 \\\\ \\frac{1}{c} \\mathcal{K}_{L, l} \\mathcal{H}_{k}\\mathcal{I} &amp; 0 &amp; \\mathcal{K}_{L, l} \\mathcal{H}_{k} \\mathcal{K}_{R,u} \\end{array}\\right) \\end{align}\\] We can see that, for \\(\\hat z_k\\), we have \\[\\begin{equation} \\hat z_{k+1} = \\hat z_k+\\alpha_k\\sum_{i=1}^n (\\nabla f_i(x_{i,k})-g(x_{i,k},\\xi_{i,k})) \\end{equation}\\] From assumption 11.3, \\(E[\\Vert \\hat z_{k}\\Vert^2]\\) will stat at \\(0\\) if the initial value \\(\\hat z_0=0\\). Hence we only check \\((\\bar z_k,\\check z_k)^T\\) in the following. References "],
["sec-PUDA.html", "Chapter 12 Decentralized Proximal Gradient Algorithms with Linear Convergence Rates 12.1 UDA 12.2 PUDA", " Chapter 12 Decentralized Proximal Gradient Algorithms with Linear Convergence Rates Alghunaim et al. (2019) propose a general primal-dual algorithmic framework that deals with the problem \\[\\begin{equation} x^* = \\underset{x\\in\\mathbb{R}^p}{\\arg\\min} \\frac{1}{n}\\sum_{i=1}^nf_i+R(x) \\tag{12.1} \\end{equation}\\] where \\(R(x):\\mathbb{R}^p\\to\\mathbb{R}\\cup\\{+\\infty\\}\\) is a common convex nonsmooth function across all agents. Whether it can be relaxed to be \\(R_i(x)\\) is not explicitly answered. However, if we restrict it to be the scenario where each agent can compute one gradient and one proximal mapping per iteration for the smooth and non-smooth part, respectively and unlimited communication per iteration, then the linear convergence rate to the exact \\(x^*\\in\\mathbb{R}^p\\) cannot be achieved. \\(f_i\\), which is only known to agent \\(i\\), is \\(\\mu-\\)strongly convex and has \\(L-\\)Lipschitz continuous gradient, and \\(\\mu\\leq L\\). Instead of stacking the local variable \\(x_i\\in\\mathbb{R}^p\\) to become a maxtrix, we use vectorized notation here to best fit the setting in (Alghunaim et al. 2019). \\[\\begin{equation} \\mathcal{X} := \\left(\\begin{array}{c} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{array} \\right) \\end{equation}\\] Then \\(\\mathcal{X}\\in\\mathbb{R}^{np}\\), denote \\(J(\\mathcal{X}):=\\sum\\limits_{i=1}^nf_i(x_i)\\). Let \\(B,C\\in\\mathbb{R}^{np\\times np}\\) be two general symmetric matrices satisfying \\[\\begin{align} B\\mathcal{X}=0&amp;\\Longleftrightarrow\\quad x_1=\\cdot=x_n\\\\ C=0\\text{ or } C\\mathcal{X}=0 &amp;\\Longleftrightarrow B\\mathcal{X}=0 \\tag{12.2} \\end{align}\\] 12.1 UDA First we consider \\(R(x)=0\\), where problem (12.1) reduces to be problem (1.1). We have the following unified decentralized algorithm(UDA). The network is assumed to be connected and undirected, the mixing matrix \\(A\\) is symmetric, doubly-stochastic, and primitive,i.e. \\(\\exists j\\in\\mathbb{N}^+\\quad s.t.\\) all entries of \\(A^j\\) are positive. Algorithm12.1 (UDA) * Initialize \\(y_0 = 0\\in\\mathbb{R}^{np}\\) and \\(\\mathcal{X}\\) to be arbitary value, set step size \\(\\alpha\\), \\(\\overline{\\mathcal{A}}\\) For k = 1, 2, …, T \\(z_{k+1} = (I - C)\\mathcal{X}_k - \\alpha\\nabla J(\\mathcal{X}_k) - By_k\\) (primal-descent) \\(y_{k+1} = y_k + Bz_{k+1}\\) (dual-ascent) \\(\\mathcal{x}_{k+1} = \\overline{\\mathcal{A}}z_{k+1}\\) (combine) Output \\(\\frac{1}{n}\\sum\\limits_{i=1}^nx_{i,T}\\) Remark. Algorithm 12.1 provides a general framework, \\(\\overline{\\mathcal{A}}\\) should be specified. It is corresponding to the mixing matrix \\(A\\)(network combination matrix). From \\(z_{k+1}-z_k\\) and \\(y_{k+1}-y_k=Bz_{k+1}\\), we can eliminating \\(y_k\\) and have, \\[\\begin{equation} z_{k+1} = (I-B^2)z_k + (I-C)(x_k-x_{k-1}) - \\alpha (\\nabla J(\\mathcal{X}_{k}) - \\nabla J(\\mathcal{X}_{k-1})) \\tag{12.3} \\end{equation}\\] Choosing different \\(\\{\\overline{\\mathcal{A}}, B, C\\}\\) leads to many state of art algorithms. 12.2 PUDA When \\(R(x)\\not=0\\), we can extend UDA 12.1 to a proximal unified decentralized algorithm(PUDA). Let \\[\\begin{equation} \\mathcal{R}(\\mathcal{X}):=\\frac{1}{n}\\sum_{i=1}^n R(x_i) \\tag{12.4} \\end{equation}\\] and define the proximal operator \\(\\mathrm{prox_{\\alpha f}(\\cdot)}\\) \\[\\begin{equation} \\mathrm{prox}_{\\alpha f}(x)=\\underset{z}{\\arg \\min } f(z)+\\frac{1}{2 \\mu}\\|z-x\\|^{2} \\end{equation}\\] then we have, Algorithm12.2 (PUDA) * Initialize \\(y_0 = 0\\in\\mathbb{R}^{np}\\) and \\(\\mathcal{X}\\) to be arbitary value, set step size \\(\\alpha\\), \\(\\overline{\\mathcal{A}}\\) For k = 1, 2, …, T \\(z_{k+1} = (I - C)\\mathcal{X}_k - \\alpha\\nabla J(\\mathcal{X}_k) - By_k\\) (primal-descent) \\(y_{k+1} = y_k + Bz_{k+1}\\) (dual-ascent) \\(\\mathcal{x}_{k+1} = \\mathrm{prox}_{\\alpha \\mathcal{R}}\\overline{\\mathcal{A}}z_{k+1}\\) (combine) Output \\(\\frac{1}{n}\\sum\\limits_{i=1}^nx_{i,T}\\) Remark. The network quantity \\(\\mathcal{R}(\\mathcal{X})\\) is not \\(R(\\bar x)\\) For PUDA 12.2, a unique fixed point \\((\\mathcal{X}^*, y^*, z^*)\\) exists. Moreover, under some conditions, PUDA 12.2 converges at the linear rate to that point with a fixed step size \\(\\mathcal{O}(\\frac{1}{L})\\). Assumption12.1 Assume matrices \\(B,C\\in\\mathbb{R}^{np\\times np}\\) satisfy (12.2) and the following \\[ \\overline{\\mathcal{A}}^{2} \\leq I-B^{2} \\text { and } 0 \\leq C&lt;2 I \\] Theorem 12.1 Let \\(f_i\\) be \\(\\mu-\\)strongly convex and has \\(L-\\)Lipschitz continuous gradient and assumption 12.1 hold, if \\(y_1=0\\) and step size \\(\\alpha&lt;\\frac{2-\\sigma_{\\max}(C)}{L}\\), then \\[ \\Vert \\mathcal{X}_{k+1}-\\mathcal{X}^*\\Vert^2 + \\Vert y_{k+1}-y_b^*\\Vert^2 \\leq \\gamma (\\Vert \\mathcal{X}_{k}-\\mathcal{X}^*\\Vert^2 + \\Vert y_{k}-y^*\\Vert^2) \\] where \\(\\gamma = \\max\\{1-\\alpha\\mu(2-\\sigma_\\max(C)-\\alpha L), 1- \\underline{\\sigma}(B)\\}\\) References "],
["nids.html", "Chapter 13 NIDS", " Chapter 13 NIDS A network independent step-size(NIDS) algorithm 13.1(Li, Shi, and Yan 2019) can deal with the problem \\[\\begin{equation} \\underset{x\\in\\mathbb{R}^p}{\\min}f(x):= \\frac{1}{n}\\sum_{i=1}^n(s_i(x)+r_i(x)) \\tag{13.1} \\end{equation}\\] where \\(s_{i}: \\mathbb{R}^{p} \\rightarrow \\mathbb{R} \\text { and } r_{i}: \\mathbb{R}^{p} \\rightarrow \\mathbb{R} \\cup\\{+\\infty\\}\\) both are known by agent \\(i\\) only. \\(s_i\\) is differentable and has a Lipschitz continuous gradient, and \\(r_i\\) is proximable, i.e. its proximal mapping \\[ \\operatorname{prox}_{\\lambda r_{i}}(y)=\\underset{x \\in \\mathbb{R}^{p}}{\\arg \\min }\\quad \\lambda r_{i}(x)+\\frac{1}{2}\\|x-y\\|^{2} \\] has a closed-form or can be computed easily. By allowing the exchanges of gradient adapted estimations, NIDS achieves the network independent step-size. NIDS also obtains sublinear convergence rate for the convexity assumption and linear convergence rate for strongly convexity assumption. The author claims they have reached the best possible performance of first-order algorithms for distributed optimization without acceleration and further improvements can be obtained by incorpporating Nesterov’s techniques. Algorithm13.1 (NIDS) Input mixing matrix \\(W\\), each agent initize its own step-size \\(\\alpha_i&gt;0\\), \\(x_{i,0}\\in\\mathbb{R}^p\\), and the same parameter \\(c\\). Each agent sets its mixing value \\(\\tilde w_{ij}:=c\\alpha_iw_{ij}\\), and \\(\\tilde w_{ii}=1-c\\alpha_i+c\\alpha_iw_{ii}\\) for k = 0, 1, 2, … if k = 0 each agent i performs \\(z_{i,1} = x_{i,0}-\\alpha_i\\nabla s_i(x_{i,0})\\) \\(x_{i,1} = \\mathrm{prox}_{\\alpha_ir_i}(z_{i,1})\\) else each agent i performs \\(z_{i, k+1} = z_{i,k}-x_{i,k}+\\sum_{j=1}^n \\tilde w_{ij}(2x_{j,k}-x_{j,k-1}-\\alpha_j\\nabla s_j(x_{j,k})+\\alpha_j\\nabla s_{j}(x_{j,k-1}))\\) \\(x_{i,k+1} = \\mathrm{prox}_{\\alpha_ir_i}(z_{i,k+1})\\) When we choose \\(C=0, B^{2}=c(I-\\mathcal{A})(c \\in \\mathbb{R}), \\text { and } \\overline{\\mathcal{A}}=I-B^{2}\\) in formula (12.3) in chapter 12, we obtain the above algorithm 13.1. Moreover, let the parameter \\(c=0.5\\), NIDS is identical to the exact diffusion in chapter 11. Let \\(\\Lambda=\\mathrm{diag}(\\alpha_1,...,\\alpha_n)\\), \\(X_{k},Z_{k}\\in\\mathbb{R}^{n\\times p}\\), and \\(\\tilde W=I - c\\Lambda(I-W)\\), where \\(c\\) is chosen so that \\(\\Lambda^{-\\frac{1}{2}}\\tilde W\\Lambda^{\\frac{1}{2}}\\) is positive semidefinite, i.e. \\(\\Lambda^{-\\frac{1}{2}}\\tilde W\\Lambda^{\\frac{1}{2}}\\succcurlyeq \\mathbf{0}\\). Then the NIDS can be expressed as \\[\\begin{align} Z_{k+1} &amp;= Z_k-X_k+\\tilde W(2X_k-X_{k-1}-\\Lambda \\nabla s(X_k)+\\lambda \\nabla s(X_{k-1}))\\\\ X_{k+1} &amp;= \\underset{X \\in \\mathbb{R}^{n \\times p}}{\\arg \\min } r(X)+\\frac{1}{2}\\left\\|X-Z_{k+1}\\right\\|_{\\Lambda-1}^{2} \\tag{13.2} \\end{align}\\] where the matrix norm for \\(X\\in\\mathbb{R}^{n\\times p}\\), \\(\\Vert X\\Vert^2_Q:=\\mathrm{tr}(X^TQX)\\) for any given symmetric matrix \\(Q\\in\\mathbb{R}^{n\\times n}\\). References "],
["final-words.html", "Chapter 14 Final Words", " Chapter 14 Final Words "],
["references.html", "References", " References "]
]
